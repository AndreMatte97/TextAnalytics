{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "path = r'C:\\Users\\chiar\\Documents\\Università\\Text analytics\\Data'\n",
    "#path = r'D:\\tirocinioLC\\tirocinioLC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Json and select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37693 entries, 1 to 54718\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype              \n",
      "---  ------   --------------  -----              \n",
      " 0   ID       37693 non-null  int64              \n",
      " 1   Title    37690 non-null  object             \n",
      " 2   Rating   37693 non-null  object             \n",
      " 3   Author   37693 non-null  object             \n",
      " 4   Date     37693 non-null  datetime64[ns, UTC]\n",
      " 5   Chapter  37693 non-null  int64              \n",
      " 6   Text     37693 non-null  object             \n",
      " 7   N_Rev    37693 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(3), object(4)\n",
      "memory usage: 2.6+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Text</th>\n",
       "      <th>N_Rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2909917</td>\n",
       "      <td>Rilassati! Hai tutta la morte davanti!</td>\n",
       "      <td>verde</td>\n",
       "      <td>Tonks98</td>\n",
       "      <td>2014-11-15 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Zi zieda, prego. Allora, quale ezzere zuo  \"B...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1390250</td>\n",
       "      <td>Episodi della Old Generation 1.</td>\n",
       "      <td>verde</td>\n",
       "      <td>mrsreg</td>\n",
       "      <td>2012-11-17 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduzione.     Personaggi:     Argus Gazza:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1143283</td>\n",
       "      <td>In Noctem</td>\n",
       "      <td>verde</td>\n",
       "      <td>LilacLilium</td>\n",
       "      <td>2012-04-07 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Questo mio piccolo lavoretto è ispirato a una ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>917615</td>\n",
       "      <td>Dirty flower.</td>\n",
       "      <td>verde</td>\n",
       "      <td>Rue</td>\n",
       "      <td>2012-07-01 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>DIRTY FLOWER.     Lo hai sempre saputo, Lily. ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>917635</td>\n",
       "      <td>Hawthorn and Unicorn Air</td>\n",
       "      <td>giallo</td>\n",
       "      <td>Tonna</td>\n",
       "      <td>2012-08-01 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Before you read:     Bentro...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                   Title  Rating       Author  \\\n",
       "1  2909917  Rilassati! Hai tutta la morte davanti!   verde      Tonks98   \n",
       "4  1390250         Episodi della Old Generation 1.   verde       mrsreg   \n",
       "5  1143283                               In Noctem   verde  LilacLilium   \n",
       "7   917615                           Dirty flower.   verde          Rue   \n",
       "8   917635                Hawthorn and Unicorn Air  giallo        Tonna   \n",
       "\n",
       "                       Date  Chapter  \\\n",
       "1 2014-11-15 00:00:00+00:00        1   \n",
       "4 2012-11-17 00:00:00+00:00        1   \n",
       "5 2012-04-07 00:00:00+00:00        1   \n",
       "7 2012-07-01 00:00:00+00:00        1   \n",
       "8 2012-08-01 00:00:00+00:00        1   \n",
       "\n",
       "                                                Text  N_Rev  \n",
       "1  \"Zi zieda, prego. Allora, quale ezzere zuo  \"B...      3  \n",
       "4  Introduzione.     Personaggi:     Argus Gazza:...      0  \n",
       "5  Questo mio piccolo lavoretto è ispirato a una ...      2  \n",
       "7  DIRTY FLOWER.     Lo hai sempre saputo, Lily. ...      3  \n",
       "8                     Before you read:     Bentro...      4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(path+'\\df_final.json')\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Rating.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verde        26104\n",
       "giallo        6927\n",
       "arancione     2623\n",
       "rosso         2039\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Text</th>\n",
       "      <th>N_Rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2909917</td>\n",
       "      <td>Rilassati! Hai tutta la morte davanti!</td>\n",
       "      <td>verde</td>\n",
       "      <td>Tonks98</td>\n",
       "      <td>2014-11-15 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Zi zieda, prego. Allora, quale ezzere zuo  \"B...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1390250</td>\n",
       "      <td>Episodi della Old Generation 1.</td>\n",
       "      <td>verde</td>\n",
       "      <td>mrsreg</td>\n",
       "      <td>2012-11-17 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduzione.     Personaggi:     Argus Gazza:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1143283</td>\n",
       "      <td>In Noctem</td>\n",
       "      <td>verde</td>\n",
       "      <td>LilacLilium</td>\n",
       "      <td>2012-04-07 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Questo mio piccolo lavoretto è ispirato a una ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>917615</td>\n",
       "      <td>Dirty flower.</td>\n",
       "      <td>verde</td>\n",
       "      <td>Rue</td>\n",
       "      <td>2012-07-01 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>DIRTY FLOWER.     Lo hai sempre saputo, Lily. ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>917635</td>\n",
       "      <td>Hawthorn and Unicorn Air</td>\n",
       "      <td>verde</td>\n",
       "      <td>Tonna</td>\n",
       "      <td>2012-08-01 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Before you read:     Bentro...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                   Title Rating       Author  \\\n",
       "1  2909917  Rilassati! Hai tutta la morte davanti!  verde      Tonks98   \n",
       "4  1390250         Episodi della Old Generation 1.  verde       mrsreg   \n",
       "5  1143283                               In Noctem  verde  LilacLilium   \n",
       "7   917615                           Dirty flower.  verde          Rue   \n",
       "8   917635                Hawthorn and Unicorn Air  verde        Tonna   \n",
       "\n",
       "                       Date  Chapter  \\\n",
       "1 2014-11-15 00:00:00+00:00        1   \n",
       "4 2012-11-17 00:00:00+00:00        1   \n",
       "5 2012-04-07 00:00:00+00:00        1   \n",
       "7 2012-07-01 00:00:00+00:00        1   \n",
       "8 2012-08-01 00:00:00+00:00        1   \n",
       "\n",
       "                                                Text  N_Rev  \n",
       "1  \"Zi zieda, prego. Allora, quale ezzere zuo  \"B...      3  \n",
       "4  Introduzione.     Personaggi:     Argus Gazza:...      0  \n",
       "5  Questo mio piccolo lavoretto è ispirato a una ...      2  \n",
       "7  DIRTY FLOWER.     Lo hai sempre saputo, Lily. ...      3  \n",
       "8                     Before you read:     Bentro...      4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col         = 'Rating'\n",
    "conditions  = [ (df[col] == 'rosso') | (df[col] == 'arancione'), (df[col] == 'giallo') | (df[col] == 'verde')]\n",
    "choices     = [ 'rosso', 'verde' ] \n",
    "    \n",
    "df[col] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Rating.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verde    33031\n",
       "rosso     4662\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[['Rating']]\n",
    "del df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RepeatedKFold\n",
    "\n",
    "#split on train-test \n",
    "x_train, x_test, y_train, y_test = train_test_split(df, target, test_size=0.30, random_state=42, stratify=target, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 26385\n",
      "Test set size: 11308\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set size: {len(x_train)}\\nTest set size: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes distributionCounter({'verde': 23122, 'rosso': 3263})\n"
     ]
    }
   ],
   "source": [
    "print('Train classes distribution%s' % Counter(y_train.Rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction with nltk and spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download it_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load('it_core_news_sm')\n",
    "\n",
    "doc_counter = 0\n",
    "def reset_counter():\n",
    "  global doc_counter\n",
    "  doc_counter = 0\n",
    "\n",
    "def increase_counter():\n",
    "  global doc_counter\n",
    "  doc_counter += 1\n",
    "  if doc_counter % 100 == 0:\n",
    "    print(doc_counter)\n",
    "\n",
    "def spacy_nlp_tokenizer(text):\n",
    "    increase_counter()\n",
    "\n",
    "    # substituting all space characters with a single space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "\n",
    "    # we use spacy for main nlp tasks\n",
    "    doc = nlp(text)\n",
    "    # lemmatized tokens, skipping stopwords\n",
    "    lemmas = ['LEMMA_'+token.lemma_ for token in doc if not token.is_stop]\n",
    "    # entity_types\n",
    "    entity_types = ['NER_'+token.ent_type_ for token in doc if token.ent_type_]\n",
    "\n",
    "    # in case an entity linker is available, we can use it do put actual entities as\n",
    "    # features, e.g. Queen Elizabeth, Elizabeth II, Her Majesty -> KB2912\n",
    "    # see https://spacy.io/usage/training#entity-linker\n",
    "    # entities = ['ENT_'+token.ent_kb_id_ for token in doc if token.ent_kb_id_]\n",
    "\n",
    "    # we use a simple nltk function to create ngrams\n",
    "    lemma_bigrams = ['BI_'+p1+'_'+p2 for p1,p2 in nltk.ngrams(lemmas,2)]\n",
    "    lemma_trigrams = ['TRI_'+p1+'_'+p2+'_'+p3 for p1,p2,p3 in nltk.ngrams(lemmas,3)]\n",
    "\n",
    "    all_tokens = list()\n",
    "    all_tokens.extend(lemmas)\n",
    "    all_tokens.extend(lemma_bigrams)\n",
    "    all_tokens.extend(lemma_trigrams)\n",
    "    all_tokens.extend(entity_types)\n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vect = CountVectorizer(analyzer=spacy_nlp_tokenizer, min_df=5)  \n",
    "#reset_counter()\n",
    "#X_train_tok = vect.fit_transform(x_train.Racconto_Text_Only)\n",
    "#reset_counter()\n",
    "#X_test_tok = vect.transform(x_test.Racconto_Text_Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(path+r'\\Rating\\vg_vs_ar\\x_train_tok.pkl','wb') as outfile:\n",
    "#    pickle.dump(X_train_tok,outfile)\n",
    "#with open(path+r'\\Rating\\vg_vs_ar\\x_test_tok.pkl','wb') as outfile:\n",
    "#    pickle.dump(X_test_tok,outfile)\n",
    "#with open(path+r'\\Rating\\vg_vs_ar\\vect.pkl','wb') as outfile:\n",
    "#    pickle.dump(vect,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(path+r\"\\Rating\\vg_vs_ar\\x_train_tok.pkl\", \"rb\")\n",
    "X_train_tok = pickle.load(a_file)\n",
    "\n",
    "b_file = open(path+r\"\\Rating\\vg_vs_ar\\x_test_tok.pkl\", \"rb\")\n",
    "X_test_tok = pickle.load(b_file)\n",
    "\n",
    "c_file = open(path+r\"\\Rating\\vg_vs_ar\\vect.pkl\", \"rb\")\n",
    "vect = pickle.load(c_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lunghezza del vocabolario: 911443\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lunghezza del vocabolario: {len(vect.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect.inverse_transform(X_train_tok[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiar\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "rating_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2, k=5000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LinearSVC())  # learning algorithm \n",
    "])\n",
    "\n",
    "#class_weight = {'rosso':10, 'verde': 5} - inversamente proporzionale: try 9:1\n",
    "#oversampling \n",
    "#normalizzare lunghezza documenti\n",
    "#(nel caso) tentare verde/giallo/rosso&arancione\n",
    "\n",
    "reset_counter()\n",
    "rating_pipeline.fit(X_train_tok, y_train)\n",
    "\n",
    "reset_counter()\n",
    "rating_predictions = rating_pipeline.predict(X_test_tok)\n",
    "\n",
    "rating_correct = 0\n",
    "rating_true_labels = [x[0] for x in y_test.values]\n",
    "\n",
    "for prediction,true_label in zip(rating_predictions, rating_true_labels):\n",
    "    if prediction==true_label:\n",
    "        rating_correct += 1\n",
    "        \n",
    "print(f\"Accuracy: {(rating_correct/len(rating_predictions)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       rosso       0.85      0.37      0.52      1399\n",
      "       verde       0.92      0.99      0.95      9909\n",
      "\n",
      "    accuracy                           0.91     11308\n",
      "   macro avg       0.89      0.68      0.74     11308\n",
      "weighted avg       0.91      0.91      0.90     11308\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 524  875]\n",
      " [  90 9819]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, rating_predictions))\n",
    "print('Confusion matrix:')\n",
    "rating_cm = confusion_matrix(y_test, rating_predictions)\n",
    "print(rating_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'sel__k': [10000, 100000, 250000, 500000, 'all'],\n",
    "                 'learner':[MultinomialNB()],\n",
    "                 'learner__alpha': [1e-3, 1e-2, 0.1, 1.0, 10.0],\n",
    "                 'learner__fit_prior':[True, False]}, \n",
    "                {'sel__k': [10000, 100000, 250000, 500000, 'all'],\n",
    "                 'learner':[LinearSVC()],\n",
    "                 'learner__C': [0.01, 0.1, 1, 10, 100]},\n",
    "                {'sel__k': [10000, 100000, 250000, 500000, 'all'], \n",
    "                 'learner':[LogisticRegression()],\n",
    "                 'learner__solver':[\"liblinear\"],\n",
    "                 'learner__penalty' : ['l1', 'l2'],\n",
    "                 'learner__C': [0.01, 0.1, 1, 10, 100]} \n",
    "               ]\n",
    "\n",
    "rating_opt_pipeline = Pipeline([\n",
    "#    ('vect', CountVectorizer()),  # feature extraction\n",
    "    ('sel', SelectKBest(chi2)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LinearSVC())  # learning algorithm\n",
    "])\n",
    "\n",
    "scoring = make_scorer(f1_score, greater_is_better=True, pos_label='rosso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_opt_search = GridSearchCV(rating_opt_pipeline,\n",
    "                                 search_space,\n",
    "                                 scoring = scoring,\n",
    "                                 cv=3, n_jobs = -1, \n",
    "                                 verbose=True).fit(X_train_tok,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       " 'learner__C': 10,\n",
       " 'learner__penalty': 'l1',\n",
       " 'learner__solver': 'liblinear',\n",
       " 'sel__k': 'all'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_opt_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  5.50078424,   7.13442206,   9.74158486,  14.60891136,\n",
       "         21.39884297,   7.77886438,   8.02120248,  10.21145105,\n",
       "         14.95896475,  19.28075711,   6.99922546,   7.00643174,\n",
       "          9.94244035,  13.56615973,  19.33290728,   6.47033676,\n",
       "          7.68188079,   9.53716262,  13.04458769,  18.86332631,\n",
       "          6.51566188,   7.26254018,   9.61450545,  13.08881052,\n",
       "         19.20187902,   6.43723194,   7.54131325,   9.16397786,\n",
       "         13.64159282,  18.44697674,   6.56073356,   7.04083737,\n",
       "          9.486039  ,  13.17730832,  18.94711987,   6.49846005,\n",
       "          7.19908611,   9.04209916,  13.41846999,  18.56237857,\n",
       "          6.41919653,   7.21794271,   9.53336088,  13.57595309,\n",
       "         19.09750017,   6.71879959,   7.82156452,   9.17661468,\n",
       "         13.50198523,  17.81698219,   7.03633308,   8.34577958,\n",
       "         10.84301146,  17.89437906,  26.06436062,   8.37206181,\n",
       "         10.12753709,  12.52579705,  20.16267093,  27.86237899,\n",
       "         11.05699468,  13.05130553,  20.2281297 ,  34.7352922 ,\n",
       "         46.25396593,  26.90422583,  43.01635321,  95.12838133,\n",
       "        158.27885063, 240.47864676,  60.84967558, 146.61842895,\n",
       "        307.61706924, 511.25590873, 681.29569141,  11.21666288,\n",
       "         17.25306257,  24.89435641,  34.31807931,  45.27060358,\n",
       "         12.19302853,  16.76136144,  22.80805071,  34.49095805,\n",
       "         47.83664028,  12.45894003,  16.69884928,  25.3630832 ,\n",
       "         37.99070462,  53.44302336,  11.28046552,  15.61708856,\n",
       "         26.67366664,  43.48460937,  57.77830672,  14.72510076,\n",
       "         17.90069079,  21.88141346,  25.7859656 ,  31.46327082,\n",
       "          9.92490745,  14.01769368,  28.22527774,  60.18145259,\n",
       "         81.48588713,  48.97683295,  27.59824101,  25.88012346,\n",
       "         28.72268573,  38.03924775,  11.77799233,  22.27669136,\n",
       "         53.5739309 , 112.46029886, 142.10356752, 104.78744698,\n",
       "         39.5264856 ,  28.22712477,  34.01372099,  46.66144872,\n",
       "         19.75973376,  28.23839275,  76.66686416, 137.41918127,\n",
       "        148.129342  ]),\n",
       " 'std_fit_time': array([3.74125256e-01, 9.02751357e-01, 7.40202920e-01, 7.75640573e-01,\n",
       "        3.00516444e-01, 1.65754698e-01, 3.43269755e-01, 8.55983803e-01,\n",
       "        6.09827217e-01, 6.78440813e-01, 2.17385813e-01, 1.24174389e-02,\n",
       "        5.70459886e-01, 9.18220214e-01, 8.95918786e-01, 4.72155922e-01,\n",
       "        4.84795759e-01, 3.90446469e-01, 3.67716384e-01, 2.02502116e-01,\n",
       "        2.69429631e-01, 1.18997720e-01, 2.83440735e-01, 8.68202942e-01,\n",
       "        5.91594231e-01, 4.58823540e-01, 1.40708492e-01, 1.16064432e-01,\n",
       "        6.63196171e-01, 2.55325680e-01, 2.42524637e-01, 2.71143546e-01,\n",
       "        1.87292334e-01, 7.60747164e-01, 6.51356313e-01, 4.22040653e-01,\n",
       "        5.93692991e-02, 2.70724521e-01, 3.62028784e-01, 1.98608333e-01,\n",
       "        2.12601284e-01, 2.62068910e-01, 4.49231926e-01, 6.63175876e-01,\n",
       "        7.05302558e-01, 1.94143435e-01, 4.57273898e-01, 1.01888060e+00,\n",
       "        6.21594159e-01, 3.29098728e-01, 2.22738790e-01, 2.90943673e-01,\n",
       "        5.25626664e-01, 5.56053237e-01, 4.00889110e-01, 4.95448180e-01,\n",
       "        6.06575513e-01, 1.89915756e-01, 2.53151507e-01, 1.66910973e-01,\n",
       "        9.01749584e-01, 8.19994231e-01, 1.87284645e+00, 9.63963089e-01,\n",
       "        1.31088049e+00, 2.99907146e+00, 5.38708896e+00, 1.04056133e+01,\n",
       "        1.45123520e+01, 3.26261857e+01, 1.91375763e+00, 5.41697828e+00,\n",
       "        2.14422467e+01, 1.10766396e+01, 2.32556963e+01, 2.80838900e-02,\n",
       "        2.44947291e-01, 2.05424821e-01, 4.89390136e-01, 1.65838284e+00,\n",
       "        5.94830811e-01, 4.77159477e-01, 9.80167248e-01, 3.47238698e-01,\n",
       "        2.52464879e+00, 7.57940082e-01, 1.26712748e+00, 3.75545923e+00,\n",
       "        2.82991978e+00, 4.61970010e+00, 9.11771724e-01, 5.53215351e-01,\n",
       "        2.02416048e+00, 8.01187827e-01, 1.28358034e+00, 6.31132397e-01,\n",
       "        9.36842318e-01, 7.74348788e-01, 3.60737665e-01, 1.71872597e+00,\n",
       "        1.18818474e+00, 1.44181657e+00, 5.25763445e+00, 1.06720397e+00,\n",
       "        2.03068802e+00, 8.28373469e+00, 2.92648489e+00, 1.68048541e-01,\n",
       "        1.63367778e+00, 1.48985378e+00, 3.62679699e-01, 1.47243279e+00,\n",
       "        5.98051512e+00, 1.71104234e+00, 8.97658112e+00, 1.56610266e+01,\n",
       "        7.85426714e+00, 5.27538292e-01, 1.92746854e+00, 1.88909157e+00,\n",
       "        2.44286165e+00, 2.84820187e+00, 1.47887216e+01, 7.51644211e+00,\n",
       "        1.49886943e+01]),\n",
       " 'mean_score_time': array([ 0.88266611,  2.20199426,  3.04540348,  6.68233728,  6.60216657,\n",
       "         1.52432267,  2.30584725,  3.3271788 ,  6.43300152,  6.10909796,\n",
       "         1.24551328,  2.15979664,  2.66441838,  5.78149144,  5.65861456,\n",
       "         1.50260409,  2.19344505,  2.83340724,  6.01845495,  5.93609564,\n",
       "         1.31619867,  2.0364635 ,  3.14368232,  5.82950966,  6.00652496,\n",
       "         1.30065759,  1.94509991,  3.08947444,  5.94976838,  5.88498322,\n",
       "         1.21644568,  1.91632215,  3.01634534,  5.92361991,  6.02960014,\n",
       "         1.10312112,  2.14631518,  3.13246425,  5.76525148,  5.8186721 ,\n",
       "         1.30556456,  1.91048471,  3.10913785,  5.7863179 ,  6.04721204,\n",
       "         1.08232983,  2.16840418,  3.07973115,  5.55671032,  5.80809251,\n",
       "         2.32309397,  1.71881557,  3.76358422,  6.09449005,  5.74261896,\n",
       "         1.42082763,  2.03930767,  3.75926375,  5.97535753,  5.50713921,\n",
       "         1.29492211,  1.64173961,  4.80141354,  6.40845807,  5.15644598,\n",
       "         1.09649626,  2.95732093,  5.81658745,  7.34777252,  9.56024424,\n",
       "         1.86576962,  3.38470713,  6.26957591,  9.60463134,  7.98586281,\n",
       "         2.05648979,  3.81488609,  6.40554214,  8.86531345, 11.98769156,\n",
       "         2.10445015,  3.07748588,  4.94124826,  7.98060433,  8.32063794,\n",
       "         1.90508064,  2.84861422,  4.87629382,  6.53066373,  7.23748295,\n",
       "         1.59845591,  2.5312465 ,  5.30977511,  7.63819114,  7.81654278,\n",
       "         1.7068634 ,  2.50055981,  3.3525424 ,  4.55143587,  5.48649987,\n",
       "         1.1418368 ,  2.23476394,  4.69685411,  5.84458335,  4.71878521,\n",
       "         1.03425241,  1.60117833,  2.68365375,  3.42102472,  5.89882835,\n",
       "         1.02576804,  1.97860972,  5.22538837,  5.69550792,  4.54275695,\n",
       "         0.92383949,  1.38158655,  2.05967657,  4.90494839,  6.21425327,\n",
       "         0.94922765,  1.88543463,  5.51776878,  4.61027153,  2.75182764]),\n",
       " 'std_score_time': array([0.07411726, 0.08107938, 0.05036521, 0.12420165, 0.58396021,\n",
       "        0.06681812, 0.14780494, 1.07739176, 0.28800961, 0.28156417,\n",
       "        0.08660689, 0.13420581, 0.6919398 , 0.37473042, 0.27506531,\n",
       "        0.04605394, 0.08729605, 0.72639307, 0.11917583, 0.14835239,\n",
       "        0.07935692, 0.12893572, 0.55500128, 0.21276361, 0.24453187,\n",
       "        0.16882958, 0.19016297, 0.74987376, 0.15492643, 0.24278612,\n",
       "        0.1388655 , 0.20764623, 0.59032407, 0.11052147, 0.05676225,\n",
       "        0.17101211, 0.01813193, 0.87785805, 0.27191237, 0.04651663,\n",
       "        0.13203073, 0.08410557, 0.39311819, 0.44374463, 0.38920534,\n",
       "        0.09361523, 0.0576131 , 0.65984953, 0.09524917, 0.15201555,\n",
       "        1.30486719, 0.07506441, 0.77819615, 0.13415288, 0.13214514,\n",
       "        0.27028641, 0.19064212, 0.88193159, 0.09106372, 0.24296453,\n",
       "        0.25146478, 0.28995892, 0.25945164, 0.29372129, 0.85477999,\n",
       "        0.14327635, 0.35744765, 0.29969603, 0.69291691, 3.08841088,\n",
       "        0.09498944, 0.29367388, 0.31402137, 1.98920231, 1.22989412,\n",
       "        0.04207871, 0.0609952 , 0.14678293, 0.55923229, 0.65719603,\n",
       "        0.02394768, 0.28346613, 0.32432332, 0.5187627 , 0.6016924 ,\n",
       "        0.09698464, 0.30489205, 0.93068648, 0.93830188, 0.88765868,\n",
       "        0.1535258 , 0.28807616, 0.297825  , 0.13011325, 0.92651291,\n",
       "        0.05789274, 0.14517063, 0.51339454, 0.21432144, 0.28408685,\n",
       "        0.18387093, 0.02272428, 0.700453  , 0.16525746, 0.29795573,\n",
       "        0.11238365, 0.24626289, 0.07379429, 0.24947393, 1.60188879,\n",
       "        0.12956594, 0.18787495, 0.13719591, 0.18881932, 0.14740735,\n",
       "        0.07496668, 0.1275512 , 0.03506979, 0.41848829, 0.78980355,\n",
       "        0.09365303, 0.4763431 , 0.09570256, 0.82477008, 0.74288402]),\n",
       " 'param_learner': masked_array(data=[MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), MultinomialNB(),\n",
       "                    MultinomialNB(), MultinomialNB(), LinearSVC(),\n",
       "                    LinearSVC(), LinearSVC(), LinearSVC(), LinearSVC(),\n",
       "                    LinearSVC(), LinearSVC(), LinearSVC(), LinearSVC(),\n",
       "                    LinearSVC(), LinearSVC(), LinearSVC(), LinearSVC(),\n",
       "                    LinearSVC(), LinearSVC(), LinearSVC(), LinearSVC(),\n",
       "                    LinearSVC(), LinearSVC(), LinearSVC(), LinearSVC(),\n",
       "                    LinearSVC(), LinearSVC(), LinearSVC(), LinearSVC(),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "                    LogisticRegression(C=10, penalty='l1', solver='liblinear')],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__alpha': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0,\n",
       "                    10.0, 10.0, 10.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__fit_prior': masked_array(data=[True, True, True, True, True, False, False, False,\n",
       "                    False, False, True, True, True, True, True, False,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    True, False, False, False, False, False, True, True,\n",
       "                    True, True, True, False, False, False, False, False,\n",
       "                    True, True, True, True, True, False, False, False,\n",
       "                    False, False, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_sel__k': masked_array(data=[10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all', 10000,\n",
       "                    100000, 250000, 500000, 'all', 10000, 100000, 250000,\n",
       "                    500000, 'all', 10000, 100000, 250000, 500000, 'all',\n",
       "                    10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all', 10000,\n",
       "                    100000, 250000, 500000, 'all', 10000, 100000, 250000,\n",
       "                    500000, 'all', 10000, 100000, 250000, 500000, 'all',\n",
       "                    10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all', 10000,\n",
       "                    100000, 250000, 500000, 'all', 10000, 100000, 250000,\n",
       "                    500000, 'all', 10000, 100000, 250000, 500000, 'all',\n",
       "                    10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__C': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 100, 100, 100, 100, 100, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__penalty': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'l1', 'l1', 'l1', 'l1', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__solver': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.01, 'sel__k': 10000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.01, 'sel__k': 100000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.01, 'sel__k': 250000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.01, 'sel__k': 500000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.01, 'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.1, 'sel__k': 10000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.1, 'sel__k': 100000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.1, 'sel__k': 250000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.1, 'sel__k': 500000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.1, 'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(), 'learner__C': 1, 'sel__k': 10000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 1, 'sel__k': 100000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 1, 'sel__k': 250000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 1, 'sel__k': 500000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 1, 'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(), 'learner__C': 10, 'sel__k': 10000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 10, 'sel__k': 100000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 10, 'sel__k': 250000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 10, 'sel__k': 500000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 10, 'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(), 'learner__C': 100, 'sel__k': 10000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 100, 'sel__k': 100000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 100, 'sel__k': 250000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 100, 'sel__k': 500000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 100, 'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'}],\n",
       " 'split0_test_score': array([0.49120521, 0.5520362 , 0.55217391, 0.49402891, 0.39572954,\n",
       "        0.5238829 , 0.49839801, 0.49931034, 0.52678133, 0.46125   ,\n",
       "        0.47694335, 0.53422168, 0.52435358, 0.53325554, 0.53531157,\n",
       "        0.52373541, 0.51485944, 0.51398881, 0.52695582, 0.51988029,\n",
       "        0.45652174, 0.39479393, 0.29173167, 0.21732026, 0.1369863 ,\n",
       "        0.53333333, 0.50351288, 0.40553633, 0.34099333, 0.24900872,\n",
       "        0.31076923, 0.00367309, 0.        , 0.        , 0.        ,\n",
       "        0.47688564, 0.01634877, 0.00182983, 0.00183318, 0.00183318,\n",
       "        0.00183824, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0199456 , 0.0018315 , 0.0018315 , 0.00183318, 0.00183318,\n",
       "        0.00915751, 0.00183824, 0.00183824, 0.00183824, 0.00183824,\n",
       "        0.38123167, 0.36146378, 0.34789157, 0.35037594, 0.34116755,\n",
       "        0.52450668, 0.51298701, 0.51692708, 0.52446184, 0.52162516,\n",
       "        0.52006253, 0.54069767, 0.5429757 , 0.55774985, 0.56146789,\n",
       "        0.46638298, 0.52398922, 0.54320988, 0.55768116, 0.55733809,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.03423423, 0.01637853, 0.01096892, 0.0199637 , 0.03065825,\n",
       "        0.02003643, 0.00550459, 0.00183824, 0.00183824, 0.00550459,\n",
       "        0.48620237, 0.47984137, 0.48042468, 0.49605263, 0.49966865,\n",
       "        0.39855072, 0.38207201, 0.36309524, 0.37343173, 0.36873156,\n",
       "        0.55628415, 0.56056491, 0.5664488 , 0.56567915, 0.57078398,\n",
       "        0.53225806, 0.52207294, 0.5208467 , 0.52427184, 0.51827676,\n",
       "        0.480322  , 0.5337904 , 0.53019146, 0.54416244, 0.55648536,\n",
       "        0.53148346, 0.54326923, 0.54911531, 0.5519802 , 0.54556882]),\n",
       " 'split1_test_score': array([0.49677419, 0.54891001, 0.54865311, 0.50158328, 0.41222459,\n",
       "        0.52126414, 0.50344577, 0.50035486, 0.53622474, 0.46976448,\n",
       "        0.4875817 , 0.52997602, 0.52298507, 0.52872216, 0.52318668,\n",
       "        0.51901743, 0.53104575, 0.53092995, 0.51791531, 0.52799311,\n",
       "        0.45706558, 0.40629471, 0.28571429, 0.21164889, 0.13036021,\n",
       "        0.52386988, 0.51398601, 0.41164241, 0.35181079, 0.25198098,\n",
       "        0.31772832, 0.00183655, 0.        , 0.        , 0.        ,\n",
       "        0.48915663, 0.02350814, 0.00182983, 0.00182983, 0.00182983,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0198915 , 0.00182983, 0.00182983, 0.00182983, 0.00182983,\n",
       "        0.00914913, 0.00183655, 0.00183655, 0.00549954, 0.00549954,\n",
       "        0.37426036, 0.35435435, 0.3343465 , 0.33511043, 0.32977099,\n",
       "        0.51058371, 0.50198675, 0.49667111, 0.50797872, 0.50432468,\n",
       "        0.52916225, 0.53649852, 0.54909091, 0.55342804, 0.55625   ,\n",
       "        0.48049101, 0.52596315, 0.54113557, 0.55160142, 0.55360388,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.06028369, 0.02712477, 0.02177858, 0.03408072, 0.04955752,\n",
       "        0.02181818, 0.01278539, 0.00732601, 0.00732601, 0.01278539,\n",
       "        0.47343645, 0.47708895, 0.47875927, 0.48767488, 0.49238915,\n",
       "        0.3916185 , 0.36900369, 0.35329341, 0.3598513 , 0.35092937,\n",
       "        0.53888889, 0.53068182, 0.5347654 , 0.54825814, 0.56389685,\n",
       "        0.52157598, 0.50651042, 0.50230112, 0.50526316, 0.50165453,\n",
       "        0.48083942, 0.52315522, 0.51945427, 0.54123711, 0.55649419,\n",
       "        0.53544166, 0.5403423 , 0.53725736, 0.54361568, 0.54198473]),\n",
       " 'split2_test_score': array([0.48620237, 0.54808806, 0.55505618, 0.5       , 0.38367931,\n",
       "        0.51442118, 0.50655977, 0.5106383 , 0.51976285, 0.47395172,\n",
       "        0.47480106, 0.52328431, 0.51628765, 0.53309693, 0.518429  ,\n",
       "        0.51798561, 0.52854812, 0.5276526 , 0.5177706 , 0.52060738,\n",
       "        0.45156889, 0.39396118, 0.26635146, 0.19423868, 0.12714777,\n",
       "        0.52649428, 0.49970256, 0.40444753, 0.32392273, 0.2208    ,\n",
       "        0.2996139 , 0.00183486, 0.        , 0.        , 0.        ,\n",
       "        0.47387606, 0.0181653 , 0.0018315 , 0.00183318, 0.00183318,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01634877, 0.00183318, 0.00183318, 0.00183318, 0.00183318,\n",
       "        0.00732601, 0.00183655, 0.        , 0.        , 0.        ,\n",
       "        0.36309524, 0.34065102, 0.33333333, 0.32874618, 0.32465544,\n",
       "        0.51088348, 0.50263158, 0.50592885, 0.50760079, 0.50996016,\n",
       "        0.51871376, 0.54146919, 0.55126659, 0.55548743, 0.55520898,\n",
       "        0.45960035, 0.53074792, 0.5483871 , 0.55967078, 0.55172414,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04480287, 0.01636364, 0.01455869, 0.01813237, 0.048     ,\n",
       "        0.01819836, 0.00366972, 0.00183655, 0.00366972, 0.00914913,\n",
       "        0.464     , 0.45864156, 0.46411804, 0.47466667, 0.47957133,\n",
       "        0.37837838, 0.36350148, 0.35522388, 0.35443038, 0.34750186,\n",
       "        0.53135314, 0.54924029, 0.55827175, 0.56701031, 0.57142857,\n",
       "        0.52631579, 0.51298701, 0.51308901, 0.51376147, 0.50165893,\n",
       "        0.47873303, 0.51670823, 0.52668681, 0.54219949, 0.54449153,\n",
       "        0.52722372, 0.54423429, 0.54228856, 0.55799373, 0.53145058]),\n",
       " 'mean_test_score': array([0.49139392, 0.54967809, 0.55196107, 0.4985374 , 0.39721115,\n",
       "        0.51985607, 0.50280118, 0.5034345 , 0.52758964, 0.46832207,\n",
       "        0.47977537, 0.52916067, 0.52120877, 0.53169154, 0.52564242,\n",
       "        0.52024615, 0.52481777, 0.52419045, 0.52088057, 0.52282693,\n",
       "        0.45505207, 0.39834994, 0.2812658 , 0.20773595, 0.13149809,\n",
       "        0.52789916, 0.50573382, 0.40720876, 0.33890895, 0.24059657,\n",
       "        0.30937048, 0.00244817, 0.        , 0.        , 0.        ,\n",
       "        0.47997278, 0.01934074, 0.00183038, 0.00183206, 0.00183206,\n",
       "        0.00061275, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01872863, 0.0018315 , 0.0018315 , 0.00183206, 0.00183206,\n",
       "        0.00854422, 0.00183711, 0.00122493, 0.00244593, 0.00244593,\n",
       "        0.37286242, 0.35215639, 0.3385238 , 0.33807752, 0.33186466,\n",
       "        0.51532462, 0.50586845, 0.50650901, 0.51334712, 0.51197   ,\n",
       "        0.52264618, 0.53955513, 0.54777773, 0.55555511, 0.55764229,\n",
       "        0.46882478, 0.5269001 , 0.54424418, 0.55631779, 0.55422203,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04644026, 0.01995565, 0.01576873, 0.02405893, 0.04273859,\n",
       "        0.02001766, 0.0073199 , 0.00366693, 0.00427799, 0.00914637,\n",
       "        0.47454627, 0.47185729, 0.474434  , 0.48613139, 0.49054304,\n",
       "        0.38951587, 0.37152573, 0.35720418, 0.36257114, 0.35572093,\n",
       "        0.54217539, 0.54682901, 0.55316198, 0.56031587, 0.56870313,\n",
       "        0.52671661, 0.51385679, 0.51207894, 0.51443216, 0.50719674,\n",
       "        0.47996482, 0.52455128, 0.52544418, 0.54253301, 0.55249036,\n",
       "        0.53138295, 0.54261527, 0.54288708, 0.55119653, 0.53966805]),\n",
       " 'std_test_score': array([4.31799314e-03, 1.70086370e-03, 2.61837302e-03, 3.25284724e-03,\n",
       "        1.17005586e-02, 3.98898745e-03, 3.36305486e-03, 5.11167071e-03,\n",
       "        6.74480172e-03, 5.28480940e-03, 5.58876507e-03, 4.50222976e-03,\n",
       "        3.52432198e-03, 2.10067059e-03, 7.10766124e-03, 2.50297862e-03,\n",
       "        7.11504690e-03, 7.33668383e-03, 4.29625112e-03, 3.66508371e-03,\n",
       "        2.47296568e-03, 5.62807768e-03, 1.08283739e-02, 9.82083428e-03,\n",
       "        4.09636264e-03, 3.98911239e-03, 6.03896787e-03, 3.16642049e-03,\n",
       "        1.14802555e-02, 1.40507812e-02, 7.46102856e-03, 8.66154105e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.60917031e-03,\n",
       "        3.03867910e-03, 7.89916051e-07, 1.58128016e-06, 1.58128016e-06,\n",
       "        8.66552428e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.68295446e-03, 1.36942898e-06, 1.36942898e-06,\n",
       "        1.58128016e-06, 1.58128016e-06, 8.61410244e-04, 7.95732257e-07,\n",
       "        8.66154836e-04, 2.28592876e-03, 2.28592876e-03, 7.46986025e-03,\n",
       "        8.63774720e-03, 6.63691159e-03, 9.07613509e-03, 6.90169382e-03,\n",
       "        6.49384951e-03, 5.04046392e-03, 8.27963776e-03, 7.86080880e-03,\n",
       "        7.20445476e-03, 4.64034181e-03, 2.18418079e-03, 3.50979975e-03,\n",
       "        1.76501974e-03, 2.73828829e-03, 8.70160012e-03, 2.83765435e-03,\n",
       "        3.04942491e-03, 3.43246480e-03, 2.33319440e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.06974859e-02, 5.06934305e-03, 4.49520893e-03,\n",
       "        7.12580455e-03, 8.56572372e-03, 1.47784480e-03, 3.93661023e-03,\n",
       "        2.58735850e-03, 2.28128613e-03, 2.97237519e-03, 9.09798642e-03,\n",
       "        9.41225048e-03, 7.32610124e-03, 8.79873641e-03, 8.30789403e-03,\n",
       "        8.36845981e-03, 7.78830639e-03, 4.23950659e-03, 7.99212133e-03,\n",
       "        9.30570953e-03, 1.04399789e-02, 1.23182933e-02, 1.34298590e-02,\n",
       "        8.54340271e-03, 3.40873003e-03, 4.37014114e-03, 6.38307082e-03,\n",
       "        7.60481419e-03, 7.77474162e-03, 7.83475898e-03, 8.96251611e-04,\n",
       "        7.04329003e-03, 4.47063739e-03, 1.21732158e-03, 5.65602973e-03,\n",
       "        3.35571184e-03, 1.65482006e-03, 4.85945490e-03, 5.89591415e-03,\n",
       "        5.99202281e-03]),\n",
       " 'rank_test_score': array([ 52,  11,   9,  51,  66,  38,  50,  49,  25,  62,  57,  23,  35,\n",
       "         21,  28,  37,  30,  32,  36,  33,  63,  65,  79,  81,  82,  24,\n",
       "         48,  64,  74,  80,  78,  96, 109, 109, 109,  55,  88, 106, 100,\n",
       "        100, 108, 109, 109, 109, 109,  89, 104, 104, 100, 100,  92,  99,\n",
       "        107,  97,  97,  68,  73,  75,  76,  77,  39,  47,  46,  42,  44,\n",
       "         34,  20,  12,   5,   3,  61,  26,  14,   4,   6, 109, 109, 109,\n",
       "        109, 109, 109, 109, 109, 109, 109,  83,  87,  90,  85,  84,  86,\n",
       "         93,  95,  94,  91,  58,  60,  59,  54,  53,  67,  69,  71,  70,\n",
       "         72,  18,  13,   7,   2,   1,  27,  41,  43,  40,  45,  56,  31,\n",
       "         29,  17,   8,  22,  16,  15,  10,  19])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_opt_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sel',\n",
       "                 SelectKBest(k='all',\n",
       "                             score_func=<function chi2 at 0x00000115020D2C10>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('learner',\n",
       "                 LogisticRegression(C=10, penalty='l1', solver='liblinear'))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_opt_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "rating_opt_predictions = rating_opt_search.best_estimator_.predict(X_test_tok)\n",
    "\n",
    "rating_correct = 0\n",
    "rating_true_labels = [x for x in y_test.Rating]\n",
    "\n",
    "for prediction,rating_true_labels in zip(rating_opt_predictions, rating_true_labels):\n",
    "    if prediction==rating_true_labels:\n",
    "        rating_correct += 1\n",
    "        \n",
    "print(f\"Accuracy: {(rating_correct/len(rating_opt_predictions)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       rosso       0.74      0.48      0.58      1399\n",
      "       verde       0.93      0.98      0.95      9909\n",
      "\n",
      "    accuracy                           0.91     11308\n",
      "   macro avg       0.83      0.73      0.77     11308\n",
      "weighted avg       0.91      0.91      0.91     11308\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 673  726]\n",
      " [ 242 9667]]\n"
     ]
    }
   ],
   "source": [
    "rating_opt_predictions = rating_opt_search.best_estimator_.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, rating_opt_predictions))\n",
    "print('Confusion matrix:')\n",
    "rating_opt_cm = confusion_matrix(y_test, rating_opt_predictions)\n",
    "print(rating_opt_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Class weight optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Weight: 9 vs 1 (GridSearchCV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'sel__k': [10000, 100000, 250000, 500000, 'all'],\n",
    "                 'learner':[MultinomialNB(class_prior = [.9, .1])],\n",
    "                 'learner__alpha': [1e-3, 1e-2, 0.1, 1.0, 10.0],\n",
    "                 'learner__fit_prior':[True, False]}, \n",
    "                {'sel__k': [10000, 100000, 250000, 500000, 'all'],\n",
    "                 'learner':[LinearSVC(class_weight = {'rosso':9, 'verde': 1})],\n",
    "                 'learner__C': [0.01, 0.1, 1, 10, 100]},\n",
    "                {'sel__k': [10000, 100000, 250000, 500000, 'all'], \n",
    "                 'learner':[LogisticRegression(class_weight = {'rosso':9, 'verde': 1})],\n",
    "                 'learner__solver':[\"liblinear\"],\n",
    "                 'learner__penalty' : ['l1', 'l2'],\n",
    "                 'learner__C': [0.01, 0.1, 1, 10, 100]} \n",
    "               ]\n",
    "\n",
    "rating_opt2_pipeline = Pipeline([\n",
    "#    ('vect', CountVectorizer()),  # feature extraction\n",
    "    ('sel', SelectKBest(chi2)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LinearSVC())  # learning algorithm\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 125 candidates, totalling 375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiar\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "rating_opt2_search = GridSearchCV(rating_opt2_pipeline,\n",
    "                                 search_space,\n",
    "                                 scoring = scoring,\n",
    "                                 cv=3, n_jobs = -1, \n",
    "                                 verbose=True).fit(X_train_tok,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       " 'learner__C': 10,\n",
       " 'learner__penalty': 'l2',\n",
       " 'learner__solver': 'liblinear',\n",
       " 'sel__k': 'all'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_opt2_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([   7.4890031 ,   10.23055927,   10.97140169,   22.11648122,\n",
       "          23.78249367,    8.44788639,   10.02125065,   12.02084756,\n",
       "          15.73239573,   21.71476022,    7.65875912,    9.46140957,\n",
       "          12.48510973,   18.11242604,   23.69939001,    7.85046593,\n",
       "           9.62912885,   11.84212963,   16.4920578 ,   22.52606146,\n",
       "           7.59258747,    8.97834516,   10.96797601,   16.30722491,\n",
       "          23.86457348,    8.55665445,    9.8241744 ,   12.76043574,\n",
       "          17.75778874,   24.40364806,    8.24980974,    9.96568418,\n",
       "          13.37281982,   17.84074537,   23.74234549,    8.6766901 ,\n",
       "          10.14422774,   13.60740868,   19.59906189,   26.94123618,\n",
       "           9.2740949 ,   10.98379016,   14.47179111,   18.57835086,\n",
       "          24.13475982,    7.55631097,    8.72146201,   11.59154193,\n",
       "          17.76958847,   22.31434576,    9.24703622,   11.57881562,\n",
       "          15.21128352,   23.01671155,   32.66660873,   12.96241967,\n",
       "          16.12140703,   23.89745053,   41.1117185 ,   53.53639968,\n",
       "          33.65846682,   45.12596027,   96.62499642,  163.56165655,\n",
       "         224.58864212,   91.96037666,  181.24506466,  392.67090789,\n",
       "         654.97665397, 1040.55643868,   93.81013624,  269.2654132 ,\n",
       "         477.33130725,  728.7487092 , 1022.01830769,   17.18003901,\n",
       "          28.91301378,   42.15363963,   70.06357996,   86.75066702,\n",
       "          14.71998914,   24.69510682,   39.97176925,   61.00448497,\n",
       "          80.24730571,   20.7395529 ,   26.66573119,   37.27066453,\n",
       "          52.92853268,   81.06848558,   18.14154919,   30.33007542,\n",
       "          53.88874658,   78.42473014,   85.26681264,   46.5416681 ,\n",
       "          32.4416399 ,   34.46172428,   42.64691051,   48.40302459,\n",
       "          16.46392751,   27.34915884,   66.01721374,  116.93571973,\n",
       "         136.77973668,  111.45327743,   52.3863097 ,   43.20680865,\n",
       "          55.71978498,   63.99346296,   17.69136556,   38.22263797,\n",
       "         117.5399545 ,  193.28073072,  216.94140712,  152.59500233,\n",
       "          46.8142856 ,   33.85945861,   39.34369485,   51.11129443,\n",
       "          36.18443696,   66.03906131,  157.64784328,  256.37219993,\n",
       "         232.42846282]),\n",
       " 'std_fit_time': array([ 0.28660051,  0.52179366,  1.41770391,  0.56693716,  1.68446266,\n",
       "         0.38399727,  0.52098212,  0.28737007,  0.90026449,  0.55558128,\n",
       "         0.14861557,  0.89998157,  1.03092748,  1.71452071,  0.97384115,\n",
       "         0.77517637,  0.25086289,  0.45494351,  0.59394993,  0.38514936,\n",
       "         0.49824503,  0.1607724 ,  0.59471974,  0.51294062,  1.18338122,\n",
       "         0.82930935,  0.31949956,  0.41494752,  0.14616749,  0.91475547,\n",
       "         0.60243027,  1.03598183,  1.02115729,  1.17647229,  0.30143202,\n",
       "         0.14307831,  1.24131893,  0.16718576,  0.19478279,  0.70244035,\n",
       "         0.47339979,  0.71041078,  1.0273209 ,  1.01377421,  0.36558963,\n",
       "         0.04165084,  0.62361059,  0.86234963,  0.91952357,  0.15067507,\n",
       "         0.74661769,  0.65017263,  1.91303442,  0.35024277,  0.3509419 ,\n",
       "         0.80531773,  1.16807994,  1.28824955,  1.52036812,  2.53432795,\n",
       "         4.31675729,  1.84568833,  5.408778  ,  5.39091679, 13.90984023,\n",
       "         4.16301437,  3.19166258, 26.05267645, 37.2739502 ,  9.10856859,\n",
       "         5.19821909,  6.37731979, 20.13733776,  6.7963851 , 12.44125887,\n",
       "         1.13536883,  0.33864498,  1.30893144,  4.68799725,  3.71942225,\n",
       "         0.37979168,  0.38986389,  2.11440539,  1.90191273,  2.82924983,\n",
       "         0.53647141,  0.18731524,  1.45554468,  2.02284377,  3.36372866,\n",
       "         0.65167589,  1.24323875,  5.1271842 ,  3.92965627,  6.13879689,\n",
       "         0.30728703,  1.82825023,  1.17338005,  3.10301567,  1.78306518,\n",
       "         0.73360495,  1.4526689 ,  6.67010619,  2.04214195,  9.75310493,\n",
       "        17.87812155,  3.31524149,  6.91126173,  1.05024682,  1.32425346,\n",
       "         0.88317564,  3.27562835, 16.62728371, 12.8858906 , 15.39632709,\n",
       "        17.51766365,  6.17966996,  5.66476136,  4.7194679 ,  1.55366079,\n",
       "         0.85910772, 29.36995108, 19.30516392,  4.96773642, 33.11414753]),\n",
       " 'mean_score_time': array([ 1.7450033 ,  3.06207077,  4.63747176,  7.46073643,  8.97091198,\n",
       "         1.7470634 ,  2.3967518 ,  4.84206414,  7.11368839,  8.07552767,\n",
       "         1.77607346,  3.1239965 ,  4.910736  ,  6.70624725,  7.71973451,\n",
       "         1.91158827,  2.52640486,  4.06805897,  6.66634695,  7.7852215 ,\n",
       "         1.74044116,  2.28974287,  4.29096731,  8.01718156,  8.22128201,\n",
       "         1.7667582 ,  2.73666485,  4.86140291,  7.5619959 ,  8.39922206,\n",
       "         1.55273112,  2.60869789,  4.8736039 ,  7.46737083,  8.23090053,\n",
       "         1.71114278,  2.7228512 ,  5.14162691,  9.12764756,  8.52266526,\n",
       "         1.97319945,  2.74877445,  3.80273215,  7.16312265,  7.6366423 ,\n",
       "         1.4483405 ,  2.45732649,  3.93410238,  7.10050376,  7.28040314,\n",
       "         1.45691935,  2.48746141,  4.19160835,  6.82305908,  6.50674764,\n",
       "         1.68422564,  2.18430273,  5.23400664,  7.48305074,  6.53398236,\n",
       "         1.27267996,  4.50874837,  7.85882894,  9.76299206,  9.82398804,\n",
       "         2.19348335,  4.800951  ,  9.49387646, 11.10263435, 14.43823369,\n",
       "         3.16858689,  5.72997053,  8.27582741, 11.21784131, 11.94837999,\n",
       "         2.63832943,  5.47913829,  8.61166827, 11.68251093, 12.81793396,\n",
       "         2.48180175,  4.64635976,  7.92685636, 12.32084274, 13.55719868,\n",
       "         2.38098629,  4.49482417,  7.41265472,  9.20942537, 12.22585098,\n",
       "         1.99989971,  4.03381395,  7.87432957, 10.27188166,  8.74828792,\n",
       "         1.85675581,  2.92337966,  4.59268395,  5.0915997 ,  8.38803188,\n",
       "         1.19016099,  2.74807517,  6.58091815,  8.47689207,  6.12912075,\n",
       "         1.30664921,  1.99792552,  3.34184702,  4.48196109,  8.00642776,\n",
       "         1.22891895,  3.48074476,  7.66929499,  8.00010769,  6.45679132,\n",
       "         1.20967166,  2.67178321,  4.35822137,  5.57895025,  6.74391929,\n",
       "         1.33036931,  4.1010313 ,  7.44056853,  7.99254998,  3.80091612]),\n",
       " 'std_score_time': array([0.21439844, 0.12248604, 0.41811894, 0.77663438, 0.37205519,\n",
       "        0.52302292, 0.41061458, 0.59987231, 0.23349316, 0.73266305,\n",
       "        0.5834781 , 0.28194267, 0.90824575, 0.52963446, 0.53745322,\n",
       "        0.26772015, 0.08645268, 0.80283871, 0.14591037, 0.20543096,\n",
       "        0.12458866, 0.28851086, 0.38299154, 0.26891418, 0.17947587,\n",
       "        0.35333447, 0.15175166, 1.07306021, 0.52040465, 0.55080093,\n",
       "        0.07784255, 0.26273189, 0.31842557, 0.60673944, 0.22964068,\n",
       "        0.20622516, 0.17274356, 0.88635302, 1.12891027, 0.90351678,\n",
       "        0.44593684, 0.48202367, 0.25484759, 0.22833637, 0.26392963,\n",
       "        0.23609518, 0.20888511, 0.86193246, 0.29520893, 0.2612763 ,\n",
       "        0.1490543 , 0.10402274, 0.37131818, 0.47003089, 0.1599508 ,\n",
       "        0.21586471, 0.31465397, 0.78082569, 0.32202486, 0.89829447,\n",
       "        0.08475346, 0.78857111, 1.26166212, 1.2078241 , 0.56068186,\n",
       "        0.29479817, 0.11868874, 0.3594316 , 0.66337431, 0.84330469,\n",
       "        0.29000082, 0.57452489, 0.39430146, 0.42663049, 2.65594542,\n",
       "        0.12536719, 0.12462261, 0.38078086, 0.65511877, 0.28979912,\n",
       "        0.20664418, 0.32382855, 0.54248338, 0.3739493 , 0.88787805,\n",
       "        0.08781071, 0.28949744, 0.74877191, 0.94957914, 1.24643778,\n",
       "        0.12701581, 0.08407646, 0.63571301, 1.14751355, 0.54765987,\n",
       "        0.08015729, 0.25468599, 0.15687194, 0.8584601 , 0.34724616,\n",
       "        0.16061471, 0.05563313, 0.08882045, 0.10155114, 1.14951866,\n",
       "        0.11767849, 0.09300127, 0.31807055, 0.32748796, 1.05627472,\n",
       "        0.11976862, 0.63717814, 0.39265713, 0.757808  , 1.00277761,\n",
       "        0.05134837, 0.1765977 , 0.50906855, 1.46044488, 0.72681631,\n",
       "        0.1511745 , 0.79180233, 0.27159541, 0.80767813, 1.02965541]),\n",
       " 'param_learner': masked_array(data=[MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                    solver='liblinear')],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__alpha': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0,\n",
       "                    10.0, 10.0, 10.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__fit_prior': masked_array(data=[True, True, True, True, True, False, False, False,\n",
       "                    False, False, True, True, True, True, True, False,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    True, False, False, False, False, False, True, True,\n",
       "                    True, True, True, False, False, False, False, False,\n",
       "                    True, True, True, True, True, False, False, False,\n",
       "                    False, False, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_sel__k': masked_array(data=[10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all', 10000,\n",
       "                    100000, 250000, 500000, 'all', 10000, 100000, 250000,\n",
       "                    500000, 'all', 10000, 100000, 250000, 500000, 'all',\n",
       "                    10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all', 10000,\n",
       "                    100000, 250000, 500000, 'all', 10000, 100000, 250000,\n",
       "                    500000, 'all', 10000, 100000, 250000, 500000, 'all',\n",
       "                    10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all', 10000,\n",
       "                    100000, 250000, 500000, 'all', 10000, 100000, 250000,\n",
       "                    500000, 'all', 10000, 100000, 250000, 500000, 'all',\n",
       "                    10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__C': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 100, 100, 100, 100, 100, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__penalty': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'l1', 'l1', 'l1', 'l1', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__solver': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[0.9, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 0.01,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 0.01,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 0.01,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 0.01,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 0.01,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 0.1,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 0.1,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 0.1,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 0.1,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 0.1,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 1,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 1,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 1,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 1,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 1,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 10,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 10,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 10,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 10,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 10,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 100,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 100,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 100,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 100,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 9, 'verde': 1}),\n",
       "   'learner__C': 100,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'}],\n",
       " 'split0_test_score': array([0.2219953 , 0.28413641, 0.31223362, 0.43929619, 0.47891284,\n",
       "        0.2219953 , 0.28413641, 0.31223362, 0.43929619, 0.47891284,\n",
       "        0.2221087 , 0.30038818, 0.32975277, 0.37048917, 0.39749048,\n",
       "        0.2221087 , 0.30038818, 0.32975277, 0.37048917, 0.39749048,\n",
       "        0.2247493 , 0.42002782, 0.44939813, 0.43174603, 0.36949783,\n",
       "        0.2247493 , 0.42002782, 0.44939813, 0.43174603, 0.36949783,\n",
       "        0.31923275, 0.08896493, 0.00725295, 0.00181818, 0.00181818,\n",
       "        0.31923275, 0.08896493, 0.00725295, 0.00181818, 0.00181818,\n",
       "        0.13545817, 0.00181324, 0.00361991, 0.00717489, 0.00887311,\n",
       "        0.13545817, 0.00181324, 0.00361991, 0.00717489, 0.00887311,\n",
       "        0.40881388, 0.4090268 , 0.41525626, 0.42229896, 0.41742655,\n",
       "        0.50280374, 0.52751154, 0.5327381 , 0.54328588, 0.55257897,\n",
       "        0.50963597, 0.56096386, 0.57157464, 0.57754011, 0.58517699,\n",
       "        0.47013189, 0.53229167, 0.54039301, 0.55813953, 0.55249267,\n",
       "        0.44357367, 0.49064239, 0.5186722 , 0.5167821 , 0.52341598,\n",
       "        0.23382572, 0.23094894, 0.2262492 , 0.25102459, 0.27219482,\n",
       "        0.28688645, 0.27378965, 0.26973326, 0.28822915, 0.30169995,\n",
       "        0.42625443, 0.41456166, 0.41096567, 0.41303807, 0.41519879,\n",
       "        0.41333649, 0.41638716, 0.41747573, 0.42612367, 0.42290076,\n",
       "        0.50206546, 0.50797703, 0.50696203, 0.51403061, 0.51712993,\n",
       "        0.50465549, 0.52842105, 0.53025303, 0.54586808, 0.5519685 ,\n",
       "        0.49159021, 0.52184666, 0.52657807, 0.54506621, 0.55648352,\n",
       "        0.51724138, 0.56438356, 0.56707897, 0.59032577, 0.5922528 ,\n",
       "        0.43873371, 0.4921466 , 0.48606557, 0.49895178, 0.51041667,\n",
       "        0.49027237, 0.54973052, 0.55846774, 0.57905759, 0.57719585]),\n",
       " 'split1_test_score': array([0.22370858, 0.28402033, 0.31244004, 0.45010364, 0.48568702,\n",
       "        0.22370858, 0.28402033, 0.31244004, 0.45010364, 0.48568702,\n",
       "        0.22389289, 0.29934461, 0.3304073 , 0.36245164, 0.38862344,\n",
       "        0.22389289, 0.29934461, 0.3304073 , 0.36245164, 0.38862344,\n",
       "        0.22658453, 0.42187938, 0.47349177, 0.44612886, 0.40024707,\n",
       "        0.22658453, 0.42187938, 0.47349177, 0.44612886, 0.40024707,\n",
       "        0.31859331, 0.08717949, 0.01444043, 0.00363636, 0.00543971,\n",
       "        0.31859331, 0.08717949, 0.01444043, 0.00363636, 0.00543971,\n",
       "        0.1414791 , 0.00543971, 0.00542986, 0.00541516, 0.00533808,\n",
       "        0.1414791 , 0.00543971, 0.00542986, 0.00541516, 0.00533808,\n",
       "        0.40738007, 0.4056014 , 0.40929763, 0.41906704, 0.41780999,\n",
       "        0.50158328, 0.53303965, 0.53887195, 0.55035129, 0.55303644,\n",
       "        0.51881622, 0.56207234, 0.5824233 , 0.58140785, 0.5869446 ,\n",
       "        0.48374306, 0.52880991, 0.54330709, 0.55356109, 0.55568862,\n",
       "        0.45654786, 0.50710153, 0.51290323, 0.51904244, 0.52045455,\n",
       "        0.2325953 , 0.23016138, 0.22521944, 0.24924412, 0.27008547,\n",
       "        0.2889188 , 0.27912276, 0.2764977 , 0.28736506, 0.29955216,\n",
       "        0.41948154, 0.40504375, 0.40931436, 0.4173913 , 0.41904277,\n",
       "        0.4095073 , 0.41003548, 0.41418006, 0.42363261, 0.42203742,\n",
       "        0.5064433 , 0.51502423, 0.50318878, 0.51219512, 0.51481959,\n",
       "        0.5014209 , 0.53188406, 0.53730219, 0.54074638, 0.54760031,\n",
       "        0.48316366, 0.5174946 , 0.52393162, 0.5425486 , 0.55964126,\n",
       "        0.52021858, 0.57579972, 0.58817782, 0.58894472, 0.59498208,\n",
       "        0.4464148 , 0.48140231, 0.49036044, 0.49680443, 0.51550044,\n",
       "        0.49960412, 0.55594232, 0.57157785, 0.57925846, 0.5876516 ]),\n",
       " 'split2_test_score': array([0.22306665, 0.28639618, 0.31993464, 0.43609898, 0.47709924,\n",
       "        0.22306665, 0.28639618, 0.31993464, 0.43609898, 0.47709924,\n",
       "        0.22283894, 0.30113723, 0.33534851, 0.36279257, 0.38695061,\n",
       "        0.22283894, 0.30113723, 0.33534851, 0.36279257, 0.38695061,\n",
       "        0.22557486, 0.42313198, 0.46966188, 0.45043103, 0.36260265,\n",
       "        0.22557486, 0.42313198, 0.46966188, 0.45043103, 0.36260265,\n",
       "        0.3192536 , 0.08517888, 0.00363967, 0.00181818, 0.00182149,\n",
       "        0.3192536 , 0.08517888, 0.00363967, 0.00181818, 0.00182149,\n",
       "        0.13687601, 0.00180995, 0.00361664, 0.00359712, 0.00356824,\n",
       "        0.13687601, 0.00180995, 0.00361664, 0.00359712, 0.00356824,\n",
       "        0.41134046, 0.41610403, 0.41970344, 0.42360756, 0.4193038 ,\n",
       "        0.49329073, 0.53007656, 0.54752852, 0.55091689, 0.55928046,\n",
       "        0.51963303, 0.57889546, 0.57889237, 0.58912224, 0.58147321,\n",
       "        0.47765915, 0.53582888, 0.5491297 , 0.56649396, 0.55933214,\n",
       "        0.44134078, 0.50078247, 0.51984774, 0.5273743 , 0.53009259,\n",
       "        0.23276836, 0.22862148, 0.22473812, 0.25068618, 0.27566895,\n",
       "        0.28648005, 0.27791914, 0.27552584, 0.2871764 , 0.30444887,\n",
       "        0.42044257, 0.41629899, 0.41647242, 0.42042509, 0.41545643,\n",
       "        0.41531148, 0.41921618, 0.42512077, 0.42849768, 0.42091365,\n",
       "        0.50097466, 0.51370757, 0.50869285, 0.51892239, 0.52066385,\n",
       "        0.49747155, 0.5268082 , 0.54272864, 0.55198777, 0.55081706,\n",
       "        0.48715953, 0.52910959, 0.53586498, 0.55028298, 0.56681614,\n",
       "        0.52116305, 0.5882904 , 0.59638848, 0.59680639, 0.59565667,\n",
       "        0.43835616, 0.47639123, 0.49450549, 0.50129646, 0.51295564,\n",
       "        0.49842271, 0.55516373, 0.56666667, 0.57988166, 0.58342541]),\n",
       " 'mean_test_score': array([0.22292351, 0.28485097, 0.31486943, 0.44183294, 0.48056637,\n",
       "        0.22292351, 0.28485097, 0.31486943, 0.44183294, 0.48056637,\n",
       "        0.22294684, 0.30029   , 0.33183619, 0.36524446, 0.39102151,\n",
       "        0.22294684, 0.30029   , 0.33183619, 0.36524446, 0.39102151,\n",
       "        0.22563623, 0.42167973, 0.46418393, 0.44276864, 0.37744918,\n",
       "        0.22563623, 0.42167973, 0.46418393, 0.44276864, 0.37744918,\n",
       "        0.31902655, 0.08710776, 0.00844435, 0.00242424, 0.00302646,\n",
       "        0.31902655, 0.08710776, 0.00844435, 0.00242424, 0.00302646,\n",
       "        0.13793776, 0.00302097, 0.00422214, 0.00539572, 0.00592648,\n",
       "        0.13793776, 0.00302097, 0.00422214, 0.00539572, 0.00592648,\n",
       "        0.40917814, 0.41024407, 0.41475244, 0.42165786, 0.41818011,\n",
       "        0.49922592, 0.53020925, 0.53971285, 0.54818469, 0.55496529,\n",
       "        0.51602841, 0.56731055, 0.5776301 , 0.58269006, 0.5845316 ,\n",
       "        0.47717803, 0.53231015, 0.5442766 , 0.55939819, 0.55583781,\n",
       "        0.4471541 , 0.4995088 , 0.51714106, 0.52106628, 0.52465437,\n",
       "        0.23306313, 0.2299106 , 0.22540225, 0.2503183 , 0.27264975,\n",
       "        0.28742843, 0.27694385, 0.27391893, 0.2875902 , 0.30190033,\n",
       "        0.42205952, 0.41196813, 0.41225082, 0.41695149, 0.416566  ,\n",
       "        0.41271842, 0.41521294, 0.41892552, 0.42608465, 0.42195061,\n",
       "        0.50316114, 0.51223628, 0.50628122, 0.51504937, 0.51753779,\n",
       "        0.50118265, 0.52903777, 0.53676128, 0.54620074, 0.55012863,\n",
       "        0.48730447, 0.52281695, 0.52879156, 0.54596593, 0.56098031,\n",
       "        0.519541  , 0.57615789, 0.58388176, 0.59202563, 0.59429718,\n",
       "        0.44116822, 0.48331338, 0.4903105 , 0.49901756, 0.51295758,\n",
       "        0.49609973, 0.55361219, 0.56557075, 0.57939924, 0.58275762]),\n",
       " 'std_test_score': array([0.00070673, 0.00109366, 0.00358263, 0.00599216, 0.00369578,\n",
       "        0.00070673, 0.00109366, 0.00358263, 0.00599216, 0.00369578,\n",
       "        0.00073238, 0.00073512, 0.00249791, 0.00371118, 0.00462495,\n",
       "        0.00073238, 0.00073512, 0.00249791, 0.00371118, 0.00462495,\n",
       "        0.00075048, 0.00127511, 0.01057141, 0.0079896 , 0.01636446,\n",
       "        0.00075048, 0.00127511, 0.01057141, 0.0079896 , 0.01636446,\n",
       "        0.00030647, 0.00154648, 0.00448915, 0.0008571 , 0.00170642,\n",
       "        0.00030647, 0.00154648, 0.00448915, 0.0008571 , 0.00170642,\n",
       "        0.00257014, 0.00171031, 0.00085399, 0.00146068, 0.00220531,\n",
       "        0.00257014, 0.00171031, 0.00085399, 0.00146068, 0.00220531,\n",
       "        0.00163721, 0.00437322, 0.00426307, 0.00190829, 0.00080984,\n",
       "        0.00422628, 0.00225879, 0.00606737, 0.00347167, 0.003057  ,\n",
       "        0.00453242, 0.00820426, 0.00451799, 0.00481453, 0.00227983,\n",
       "        0.00556714, 0.00286551, 0.00363202, 0.00535431, 0.00279419,\n",
       "        0.00670465, 0.0067795 , 0.00303479, 0.0045549 , 0.00403098,\n",
       "        0.00054384, 0.00096658, 0.00063029, 0.00077202, 0.00230203,\n",
       "        0.00106683, 0.00228384, 0.00298619, 0.00045832, 0.00200409,\n",
       "        0.00299209, 0.00494738, 0.0030603 , 0.00303173, 0.0017545 ,\n",
       "        0.00240951, 0.00383887, 0.00458267, 0.00198635, 0.00081355,\n",
       "        0.00236317, 0.00305934, 0.00229802, 0.0028393 , 0.00240328,\n",
       "        0.00293767, 0.0021176 , 0.00510749, 0.0045953 , 0.00184855,\n",
       "        0.00344165, 0.00479118, 0.00511702, 0.003221  , 0.00432324,\n",
       "        0.00167117, 0.00976321, 0.01234515, 0.0034272 , 0.0014716 ,\n",
       "        0.00371309, 0.00657252, 0.00344576, 0.00183445, 0.00207544,\n",
       "        0.0041487 , 0.0027631 , 0.00540799, 0.00035084, 0.00429458]),\n",
       " 'rank_test_score': array([106,  93,  86,  56,  48, 106,  93,  86,  56,  48, 104,  89,  82,\n",
       "         80,  76, 104,  89,  82,  80,  76, 101,  62,  51,  54,  78, 101,\n",
       "         62,  51,  54,  78,  84, 110, 112, 124, 120,  84, 110, 112, 124,\n",
       "        120, 108, 122, 118, 116, 114, 108, 122, 118, 116, 114,  75,  74,\n",
       "         70,  64,  66,  42,  25,  22,  18,  15,  34,  10,   8,   6,   3,\n",
       "         50,  24,  21,  13,  14,  53,  41,  33,  30,  28,  99, 100, 103,\n",
       "         98,  97,  92,  95,  96,  91,  88,  60,  73,  72,  67,  68,  71,\n",
       "         69,  65,  59,  61,  39,  37,  38,  35,  32,  40,  26,  23,  19,\n",
       "         17,  46,  29,  27,  20,  12,  31,   9,   4,   2,   1,  58,  47,\n",
       "         45,  43,  36,  44,  16,  11,   7,   5])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_opt2_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sel',\n",
       "                 SelectKBest(k='all',\n",
       "                             score_func=<function chi2 at 0x000001FD63305C10>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('learner',\n",
       "                 LogisticRegression(C=10, class_weight={'rosso': 9, 'verde': 1},\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_opt2_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "rating_opt2_predictions = rating_opt2_search.best_estimator_.predict(X_test_tok)\n",
    "\n",
    "rating_correct = 0\n",
    "rating_true_labels = [x for x in y_test.Rating]\n",
    "\n",
    "for prediction,rating_true_labels in zip(rating_opt2_predictions, rating_true_labels):\n",
    "    if prediction==rating_true_labels:\n",
    "        rating_correct += 1\n",
    "        \n",
    "print(f\"Accuracy: {(rating_correct/len(rating_opt2_predictions)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       rosso       0.67      0.58      0.62      1399\n",
      "       verde       0.94      0.96      0.95      9909\n",
      "\n",
      "    accuracy                           0.91     11308\n",
      "   macro avg       0.81      0.77      0.79     11308\n",
      "weighted avg       0.91      0.91      0.91     11308\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 816  583]\n",
      " [ 397 9512]]\n"
     ]
    }
   ],
   "source": [
    "rating_opt2_predictions = rating_opt2_search.best_estimator_.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, rating_opt2_predictions))\n",
    "print('Confusion matrix:')\n",
    "rating_opt2_cm = confusion_matrix(y_test, rating_opt2_predictions)\n",
    "print(rating_opt2_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Weight 20 vs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2, k='all')),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
    "                    solver='liblinear', penalty='l2'))  # learning algorithm \n",
    "])\n",
    "\n",
    "reset_counter()\n",
    "rating_pipeline.fit(X_train_tok, y_train.values.ravel())\n",
    "\n",
    "reset_counter()\n",
    "rating_predictions = rating_pipeline.predict(X_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       rosso       0.60      0.64      0.62      1399\n",
      "       verde       0.95      0.94      0.94      9909\n",
      "\n",
      "    accuracy                           0.90     11308\n",
      "   macro avg       0.78      0.79      0.78     11308\n",
      "weighted avg       0.91      0.90      0.90     11308\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 889  510]\n",
      " [ 584 9325]]\n"
     ]
    }
   ],
   "source": [
    "print('Classification report:')\n",
    "print(classification_report(y_test, rating_predictions))\n",
    "print('Confusion matrix:')\n",
    "rating_cm = confusion_matrix(y_test, rating_predictions)\n",
    "print(rating_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weight: 20 vs 1 (GridSearchCV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space_opt3 = [{'sel__k': [10000, 100000, 250000, 500000, 'all'],\n",
    "                 'learner':[MultinomialNB(class_prior = [2, .1])],\n",
    "                 'learner__alpha': [1e-3, 1e-2, 0.1, 1.0, 10.0],\n",
    "                 'learner__fit_prior':[True, False]}, \n",
    "                {'sel__k': [10000, 100000, 250000, 500000, 'all'],\n",
    "                 'learner':[LinearSVC(class_weight = {'rosso':20, 'verde': 1})],\n",
    "                 'learner__C': [0.01, 0.1, 1, 10, 100]},\n",
    "                {'sel__k': [10000, 100000, 250000, 500000, 'all'], \n",
    "                 'learner':[LogisticRegression(class_weight = {'rosso':20, 'verde': 1})],\n",
    "                 'learner__solver':[\"liblinear\"],\n",
    "                 'learner__penalty' : ['l1', 'l2'],\n",
    "                 'learner__C': [0.01, 0.1, 1, 10, 100]} \n",
    "               ]\n",
    "\n",
    "rating_opt3_pipeline = Pipeline([\n",
    "#    ('vect', CountVectorizer()),  # feature extraction\n",
    "    ('sel', SelectKBest(chi2)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LinearSVC())  # learning algorithm\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 125 candidates, totalling 375 fits\n"
     ]
    }
   ],
   "source": [
    "rating_opt3_search = GridSearchCV(rating_opt3_pipeline,\n",
    "                                 search_space_opt3,\n",
    "                                 scoring = scoring,\n",
    "                                 cv=3, n_jobs = -1, \n",
    "                                 verbose=True).fit(X_train_tok, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       " 'learner__C': 10,\n",
       " 'learner__penalty': 'l2',\n",
       " 'learner__solver': 'liblinear',\n",
       " 'sel__k': 'all'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_opt3_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  8.28823837,   9.92818077,  12.4100124 ,  14.81506308,\n",
       "         21.77827454,   7.65412958,   9.04591608,  11.71597743,\n",
       "         15.48722521,  21.65498837,   7.74997822,   8.53446062,\n",
       "         10.04583891,  13.9845655 ,  19.13450742,   6.68369635,\n",
       "          7.74186738,   9.37940494,  14.6637373 ,  19.3148466 ,\n",
       "          6.8929139 ,   7.87058489,  10.28275323,  15.25372521,\n",
       "         19.76160431,   6.9887073 ,   8.07735531,  10.06284738,\n",
       "         14.10179853,  19.80658531,   7.42584435,   8.19888663,\n",
       "         10.04642924,  14.43125431,  20.38102055,   7.03331391,\n",
       "          8.7826399 ,  10.5404315 ,  15.51276771,  19.44028616,\n",
       "          7.56138349,   8.16912166,   9.90912636,  15.61493278,\n",
       "         20.02671758,   7.46695566,   8.04331128,  10.93386118,\n",
       "         14.65846014,  20.0833687 ,   8.56924359,  10.7881341 ,\n",
       "         13.40834816,  22.00562557,  30.67778532,  14.85048501,\n",
       "         17.14095283,  30.30790226,  52.72257535,  67.57609614,\n",
       "         48.57072639,  68.86002954, 139.13415917, 225.57363836,\n",
       "        319.52303839,  80.29709625, 162.21136498, 305.76917966,\n",
       "        507.06329672, 763.05059123,  75.2269489 , 198.20180925,\n",
       "        345.96123179, 548.86324199, 786.18565027,  13.87447985,\n",
       "         21.64158742,  33.97305783,  48.3289303 ,  67.65843709,\n",
       "         14.08621113,  21.64435315,  30.96834095,  46.37038771,\n",
       "         63.24401577,  14.34925977,  21.63528673,  28.50969442,\n",
       "         39.50402323,  52.60918307,  15.61408742,  26.66194407,\n",
       "         47.81351376,  70.20751143,  78.9503336 ,  43.76384862,\n",
       "         25.74086388,  24.57891687,  31.02498738,  36.98279881,\n",
       "         12.91363271,  22.30173866,  53.35798597,  97.21124721,\n",
       "        127.94668555,  81.88574044,  35.08942238,  31.02480372,\n",
       "         36.47190372,  46.01997487,  18.85082579,  32.0366408 ,\n",
       "         98.77420608, 152.2004172 , 201.83888046,  95.74145357,\n",
       "         25.69375984,  27.04150796,  32.86792254,  38.24176105,\n",
       "         37.27866181,  55.49224067, 121.78248215, 191.80908561,\n",
       "        200.46602209]),\n",
       " 'std_fit_time': array([ 0.17935877,  0.67060413,  1.02566354,  0.7452321 ,  0.49327414,\n",
       "         0.367284  ,  0.20553778,  0.41752685,  0.94397225,  2.20133364,\n",
       "         0.4813752 ,  0.09954386,  0.42084323,  2.08192068,  0.80396809,\n",
       "         0.49724276,  0.45858413,  0.36856947,  0.83593874,  0.31298349,\n",
       "         0.34992713,  0.31957704,  0.54462027,  0.28636133,  0.82420403,\n",
       "         0.17005984,  0.36141481,  1.16847498,  0.26851168,  0.92633195,\n",
       "         0.2219227 ,  0.13147836,  0.30305981,  1.17759812,  0.13592083,\n",
       "         0.80798183,  0.44594331,  1.12986039,  1.40281241,  1.03177815,\n",
       "         0.47831982,  0.23340067,  0.39301252,  0.13916465,  0.08570338,\n",
       "         0.35140133,  1.25968557,  0.32732366,  1.56629238,  0.55197658,\n",
       "         0.80878201,  0.64892766,  0.76523118,  0.43942715,  0.72346139,\n",
       "         0.62173563,  0.70264992,  2.60179244,  3.2124567 ,  2.95265405,\n",
       "         4.28781027,  7.27244093, 13.17093455,  8.48554148, 14.69307048,\n",
       "         7.49457885,  2.9396753 , 17.21593105,  7.89371675,  9.17841528,\n",
       "         1.72551871,  1.04406471, 12.68422302,  7.31107043,  8.42240943,\n",
       "         0.98367755,  0.3689379 ,  2.50338184,  1.91385161,  1.35017028,\n",
       "         0.13944422,  0.98151224,  0.24294943,  2.33875535,  1.78626722,\n",
       "         0.68811453,  1.49932507,  0.03827625,  3.71656947,  2.78418971,\n",
       "         0.70601925,  0.28778334,  3.72429791,  3.9048023 ,  3.79427063,\n",
       "         1.2187083 ,  3.05895779,  1.31799733,  1.43659515,  1.16963419,\n",
       "         1.07115061,  1.79354469,  7.76741908,  0.21872202, 10.94593532,\n",
       "        12.29370612,  2.67993771,  2.05696432,  0.9652324 ,  0.863385  ,\n",
       "         1.72259817,  2.84940391, 30.1435225 ,  8.82131502, 21.8151017 ,\n",
       "        14.03199538,  2.80915667,  1.28917893,  1.68243691,  2.51401221,\n",
       "         6.40342383, 18.44807475, 31.28823476, 21.12124299, 10.14292284]),\n",
       " 'mean_score_time': array([ 0.74332102,  2.41845433,  3.09142677,  6.73159258,  7.10110521,\n",
       "         1.41755025,  2.51530623,  2.96701018,  6.67417351,  6.66430736,\n",
       "         1.40234296,  2.64367572,  2.93398627,  5.86010337,  6.36200349,\n",
       "         1.57919192,  2.1965131 ,  3.34495417,  5.95786254,  6.49467285,\n",
       "         1.46048427,  2.35008526,  3.20972331,  6.56097881,  6.54215026,\n",
       "         1.33432484,  2.31899818,  2.95726395,  6.32200948,  5.94991302,\n",
       "         1.37614854,  2.37604403,  3.38967125,  6.37184032,  6.97173619,\n",
       "         1.22360293,  2.35855707,  2.76222865,  5.97614566,  6.14319348,\n",
       "         1.41926646,  2.25043861,  3.52493739,  6.15794746,  6.67123318,\n",
       "         1.4607145 ,  2.66305995,  3.32920194,  6.47569068,  6.38418881,\n",
       "         1.68814174,  1.84884508,  4.3026677 ,  6.08153598,  5.96499523,\n",
       "         1.45869446,  2.13692021,  5.81077719,  7.13047409,  5.71689844,\n",
       "         1.13989147,  3.36406096,  6.8293887 ,  7.25808962,  8.27531854,\n",
       "         1.89664896,  3.60824839,  6.32920655,  7.86550872, 10.67268189,\n",
       "         2.24756853,  3.7232062 ,  6.90240971,  8.69460336,  9.00577656,\n",
       "         2.17032091,  3.91724936,  6.46648574,  9.71739666, 10.44662086,\n",
       "         2.09921718,  3.37994075,  6.29103009,  8.64240193, 10.52112675,\n",
       "         2.12371325,  3.55325087,  5.34060542,  7.11377541,  9.50871205,\n",
       "         1.66439255,  3.23885226,  6.38841184,  8.25045109,  7.23648008,\n",
       "         1.32677182,  2.03586396,  3.14932164,  3.84521198,  5.96419144,\n",
       "         1.09126894,  2.39238254,  5.69277573,  6.30024552,  5.49671602,\n",
       "         1.13493355,  2.149839  ,  2.7370557 ,  3.4873205 ,  5.75005619,\n",
       "         1.08328748,  2.41519705,  6.28247873,  6.53793867,  7.56593617,\n",
       "         1.45621912,  2.6356403 ,  4.2549785 ,  5.00213639,  5.5094715 ,\n",
       "         1.03794392,  3.07716656,  5.94438863,  5.20799367,  2.706671  ]),\n",
       " 'std_score_time': array([0.03276647, 0.36195452, 0.36762148, 0.817183  , 0.06149204,\n",
       "        0.02134484, 0.03843099, 1.15256706, 0.04855386, 0.48634094,\n",
       "        0.24025363, 0.06809788, 0.28354213, 0.57901597, 0.31945502,\n",
       "        0.15001503, 0.095439  , 0.66989279, 0.15909468, 0.18611103,\n",
       "        0.15483254, 0.32305601, 0.26187191, 0.25830415, 0.20047492,\n",
       "        0.26662249, 0.30737263, 0.40785203, 0.11016958, 0.02771067,\n",
       "        0.21437128, 0.14536899, 1.02192598, 0.26604793, 0.30511387,\n",
       "        0.12808358, 0.28463051, 0.46500191, 0.92642024, 0.14892238,\n",
       "        0.33372685, 0.16750435, 0.72887679, 0.45203138, 0.49814553,\n",
       "        0.07418554, 0.11120367, 0.25481741, 0.25830846, 0.34857149,\n",
       "        0.14393389, 0.2480855 , 0.47179637, 0.31418709, 0.41759843,\n",
       "        0.22946036, 0.26750397, 0.55533804, 0.69113784, 0.58263284,\n",
       "        0.22271959, 0.51261625, 0.39150454, 0.29349497, 0.40972595,\n",
       "        0.18030831, 0.41126837, 0.23502062, 0.77505384, 0.3297651 ,\n",
       "        0.15555987, 0.27194932, 0.20110276, 0.56731289, 2.380192  ,\n",
       "        0.22054183, 0.15943612, 0.59766024, 0.58850013, 0.57195428,\n",
       "        0.21270037, 0.24552034, 0.14772078, 0.23525319, 1.20778505,\n",
       "        0.10016444, 0.34627764, 0.18258698, 0.1408429 , 0.31133142,\n",
       "        0.09314895, 0.13680497, 0.46156264, 0.60503395, 0.72512922,\n",
       "        0.16572786, 0.23864267, 0.29113403, 0.25474637, 0.17469099,\n",
       "        0.09236321, 0.07203209, 0.25677625, 0.34550297, 0.3929013 ,\n",
       "        0.13513433, 0.27740776, 0.19577046, 0.23364915, 0.23731683,\n",
       "        0.08831869, 0.4669762 , 0.57767943, 0.87750062, 0.460768  ,\n",
       "        0.05117487, 0.24495366, 0.27474878, 0.26246621, 0.840813  ,\n",
       "        0.16997279, 0.42343882, 1.02448632, 1.04739662, 0.73737592]),\n",
       " 'param_learner': masked_array(data=[MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    MultinomialNB(class_prior=[2, 0.1]),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear'),\n",
       "                    LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                    solver='liblinear')],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__alpha': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0,\n",
       "                    10.0, 10.0, 10.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__fit_prior': masked_array(data=[True, True, True, True, True, False, False, False,\n",
       "                    False, False, True, True, True, True, True, False,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    True, False, False, False, False, False, True, True,\n",
       "                    True, True, True, False, False, False, False, False,\n",
       "                    True, True, True, True, True, False, False, False,\n",
       "                    False, False, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_sel__k': masked_array(data=[10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all', 10000,\n",
       "                    100000, 250000, 500000, 'all', 10000, 100000, 250000,\n",
       "                    500000, 'all', 10000, 100000, 250000, 500000, 'all',\n",
       "                    10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all', 10000,\n",
       "                    100000, 250000, 500000, 'all', 10000, 100000, 250000,\n",
       "                    500000, 'all', 10000, 100000, 250000, 500000, 'all',\n",
       "                    10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all', 10000,\n",
       "                    100000, 250000, 500000, 'all', 10000, 100000, 250000,\n",
       "                    500000, 'all', 10000, 100000, 250000, 500000, 'all',\n",
       "                    10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__C': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 100, 100, 100, 100, 100, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__penalty': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'l1', 'l1', 'l1', 'l1', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__solver': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(class_prior=[2, 0.1]),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 0.01,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 0.01,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 0.01,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 0.01,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 0.01,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 0.1,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 0.1,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 0.1,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 0.1,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 0.1,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 1,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 1,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 1,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 1,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 1,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 10,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 10,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 10,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 10,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 10,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 100,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 100,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 100,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 100,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LinearSVC(class_weight={'rosso': 20, 'verde': 1}),\n",
       "   'learner__C': 100,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(C=10, class_weight={'rosso': 20, 'verde': 1},\n",
       "                      solver='liblinear'),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'}],\n",
       " 'split0_test_score': array([0.22001822, 0.2435416 , 0.2698908 , 0.39656816, 0.46674632,\n",
       "        0.22001822, 0.2435416 , 0.2698908 , 0.39656816, 0.46674632,\n",
       "        0.22001822, 0.24947146, 0.27900068, 0.31600898, 0.33948209,\n",
       "        0.22001822, 0.24947146, 0.27900068, 0.31600898, 0.33948209,\n",
       "        0.22006276, 0.34201161, 0.42046205, 0.41312272, 0.38476954,\n",
       "        0.22006276, 0.34201161, 0.42046205, 0.41312272, 0.38476954,\n",
       "        0.23632726, 0.12641815, 0.01427297, 0.00539568, 0.00539568,\n",
       "        0.23632726, 0.12641815, 0.01427297, 0.00539568, 0.00539568,\n",
       "        0.2145749 , 0.00716204, 0.00713649, 0.01385281, 0.01648805,\n",
       "        0.2145749 , 0.00716204, 0.00713649, 0.01385281, 0.01648805,\n",
       "        0.26686846, 0.26962545, 0.26702168, 0.2751281 , 0.29036827,\n",
       "        0.38968601, 0.45577523, 0.47932489, 0.49391511, 0.50496   ,\n",
       "        0.46672744, 0.54058876, 0.56246985, 0.57827639, 0.58512931,\n",
       "        0.45338208, 0.52016129, 0.52604167, 0.52934783, 0.54133635,\n",
       "        0.43568773, 0.48979592, 0.50962513, 0.50990615, 0.51755808,\n",
       "        0.22004049, 0.21999595, 0.21999595, 0.21999595, 0.2208639 ,\n",
       "        0.22104728, 0.22080033, 0.22046446, 0.22033039, 0.22047886,\n",
       "        0.2887521 , 0.28034328, 0.27432217, 0.2810189 , 0.29069103,\n",
       "        0.27786582, 0.27987083, 0.2772885 , 0.28893528, 0.30025294,\n",
       "        0.4316079 , 0.44308943, 0.44239401, 0.45359243, 0.46105757,\n",
       "        0.3908046 , 0.44927903, 0.47252155, 0.48747537, 0.49014925,\n",
       "        0.47248034, 0.50400305, 0.50786344, 0.52589641, 0.54304636,\n",
       "        0.47355769, 0.53944223, 0.55406538, 0.57329843, 0.58375402,\n",
       "        0.43127454, 0.48512939, 0.4873817 , 0.49085123, 0.49219392,\n",
       "        0.46711696, 0.5311943 , 0.55258303, 0.55813953, 0.56387226]),\n",
       " 'split1_test_score': array([0.22026521, 0.24425719, 0.27039136, 0.39749759, 0.47398844,\n",
       "        0.22026521, 0.24425719, 0.27039136, 0.39749759, 0.47398844,\n",
       "        0.22026521, 0.25071839, 0.27773213, 0.31116892, 0.33460768,\n",
       "        0.22026521, 0.25071839, 0.27773213, 0.31116892, 0.33460768,\n",
       "        0.22028751, 0.33434998, 0.43153245, 0.42880933, 0.40163934,\n",
       "        0.22028751, 0.33434998, 0.43153245, 0.42880933, 0.40163934,\n",
       "        0.23877917, 0.11774325, 0.02133333, 0.01078167, 0.00539084,\n",
       "        0.23877917, 0.11774325, 0.02133333, 0.01078167, 0.00539084,\n",
       "        0.23617747, 0.00892857, 0.0088574 , 0.01385281, 0.01986755,\n",
       "        0.23617747, 0.00892857, 0.0088574 , 0.01385281, 0.01986755,\n",
       "        0.27455066, 0.27479717, 0.27146172, 0.28083848, 0.29332561,\n",
       "        0.39904885, 0.45929132, 0.47397499, 0.4902439 , 0.50615684,\n",
       "        0.47368421, 0.56284153, 0.57355865, 0.58453608, 0.59037433,\n",
       "        0.46661665, 0.51840332, 0.52471483, 0.53984287, 0.54895105,\n",
       "        0.45643485, 0.5043837 , 0.51066098, 0.51072961, 0.51684152,\n",
       "        0.22017606, 0.22019834, 0.22017606, 0.22017606, 0.2207686 ,\n",
       "        0.22140673, 0.22066585, 0.2204884 , 0.22021697, 0.22097417,\n",
       "        0.29604978, 0.2854377 , 0.28053564, 0.28323938, 0.28899083,\n",
       "        0.28315217, 0.2853615 , 0.28357396, 0.29096564, 0.30360934,\n",
       "        0.44165814, 0.45361367, 0.44277964, 0.44863732, 0.45726383,\n",
       "        0.40445026, 0.45293963, 0.46350264, 0.48071905, 0.4952959 ,\n",
       "        0.4651841 , 0.50099721, 0.50713154, 0.52593193, 0.54743   ,\n",
       "        0.4802692 , 0.55781759, 0.57155172, 0.58696629, 0.58534323,\n",
       "        0.43893412, 0.4701098 , 0.48019208, 0.4811245 , 0.49315068,\n",
       "        0.48418757, 0.54294901, 0.55635492, 0.5627451 , 0.58448896]),\n",
       " 'split2_test_score': array([0.22044372, 0.24398625, 0.2751365 , 0.39250119, 0.46153846,\n",
       "        0.22044372, 0.24398625, 0.2751365 , 0.39250119, 0.46153846,\n",
       "        0.22039907, 0.25029628, 0.28210468, 0.31573834, 0.34009417,\n",
       "        0.22039907, 0.25029628, 0.28210468, 0.31573834, 0.34009417,\n",
       "        0.22026521, 0.33957978, 0.42191781, 0.43166667, 0.39061703,\n",
       "        0.22026521, 0.33957978, 0.42191781, 0.43166667, 0.39061703,\n",
       "        0.23534616, 0.1352657 , 0.01074306, 0.00358744, 0.0018018 ,\n",
       "        0.23534616, 0.1352657 , 0.01074306, 0.00358744, 0.0018018 ,\n",
       "        0.2100955 , 0.00713649, 0.00534759, 0.00876424, 0.01      ,\n",
       "        0.2100955 , 0.00713649, 0.00534759, 0.00876424, 0.01      ,\n",
       "        0.26881308, 0.2727626 , 0.27138264, 0.27847426, 0.29325681,\n",
       "        0.39716617, 0.46141479, 0.48640833, 0.50122249, 0.50910273,\n",
       "        0.46967341, 0.5687904 , 0.58263027, 0.58561821, 0.58829902,\n",
       "        0.46837349, 0.52160333, 0.53253796, 0.54899777, 0.55477855,\n",
       "        0.43799682, 0.49845201, 0.51581769, 0.51750547, 0.52451539,\n",
       "        0.22017606, 0.22017606, 0.22017606, 0.22017606, 0.22057026,\n",
       "        0.22073307, 0.22060016, 0.22035443, 0.22037675, 0.22113523,\n",
       "        0.29281454, 0.28377092, 0.27924327, 0.28394892, 0.29356471,\n",
       "        0.28112341, 0.28338762, 0.28262339, 0.2907651 , 0.30472168,\n",
       "        0.43668122, 0.45598313, 0.45323741, 0.45696562, 0.46732462,\n",
       "        0.4       , 0.45399738, 0.47486809, 0.4920313 , 0.49632803,\n",
       "        0.46688382, 0.5115354 , 0.52146514, 0.53795918, 0.5511745 ,\n",
       "        0.47195832, 0.56391286, 0.58137511, 0.58733722, 0.59596434,\n",
       "        0.42978253, 0.47886179, 0.48869144, 0.48709677, 0.50020912,\n",
       "        0.48699422, 0.54013921, 0.55485742, 0.57001484, 0.57641026]),\n",
       " 'mean_test_score': array([0.22024238, 0.24392835, 0.27180622, 0.39552231, 0.46742441,\n",
       "        0.22024238, 0.24392835, 0.27180622, 0.39552231, 0.46742441,\n",
       "        0.2202275 , 0.25016204, 0.27961249, 0.31430541, 0.33806131,\n",
       "        0.2202275 , 0.25016204, 0.27961249, 0.31430541, 0.33806131,\n",
       "        0.22020516, 0.33864713, 0.42463743, 0.4245329 , 0.39234197,\n",
       "        0.22020516, 0.33864713, 0.42463743, 0.4245329 , 0.39234197,\n",
       "        0.23681753, 0.1264757 , 0.01544979, 0.00658827, 0.00419611,\n",
       "        0.23681753, 0.1264757 , 0.01544979, 0.00658827, 0.00419611,\n",
       "        0.22028262, 0.00774237, 0.00711382, 0.01215662, 0.01545187,\n",
       "        0.22028262, 0.00774237, 0.00711382, 0.01215662, 0.01545187,\n",
       "        0.2700774 , 0.27239507, 0.26995534, 0.27814695, 0.2923169 ,\n",
       "        0.39530034, 0.45882711, 0.47990274, 0.49512717, 0.50673986,\n",
       "        0.47002835, 0.5574069 , 0.57288626, 0.58281023, 0.58793422,\n",
       "        0.46279074, 0.52005598, 0.52776482, 0.53939616, 0.54835532,\n",
       "        0.44337313, 0.49754388, 0.5120346 , 0.51271375, 0.51963833,\n",
       "        0.22013087, 0.22012345, 0.22011602, 0.22011602, 0.22073425,\n",
       "        0.22106236, 0.22068878, 0.22043576, 0.22030804, 0.22086275,\n",
       "        0.29253881, 0.28318396, 0.27803369, 0.28273573, 0.29108219,\n",
       "        0.2807138 , 0.28287332, 0.28116195, 0.29022201, 0.30286132,\n",
       "        0.43664909, 0.45089541, 0.44613702, 0.45306512, 0.461882  ,\n",
       "        0.39841829, 0.45207201, 0.47029743, 0.48674191, 0.4939244 ,\n",
       "        0.46818276, 0.50551189, 0.51215338, 0.52992918, 0.54721695,\n",
       "        0.47526174, 0.55372423, 0.5689974 , 0.58253398, 0.58835386,\n",
       "        0.4333304 , 0.47803366, 0.48542174, 0.4863575 , 0.49518457,\n",
       "        0.47943291, 0.53809417, 0.55459845, 0.56363316, 0.57492382]),\n",
       " 'std_test_score': array([1.74460823e-04, 2.94994271e-04, 2.36371705e-03, 2.16969551e-03,\n",
       "        5.10524832e-03, 1.74460823e-04, 2.94994271e-04, 2.36371705e-03,\n",
       "        2.16969551e-03, 5.10524832e-03, 1.57751992e-04, 5.17831596e-04,\n",
       "        1.83676182e-03, 2.22058941e-03, 2.45483616e-03, 1.57751992e-04,\n",
       "        5.17831596e-04, 1.83676182e-03, 2.22058941e-03, 2.45483616e-03,\n",
       "        1.01102170e-04, 3.19661683e-03, 4.91160095e-03, 8.15210832e-03,\n",
       "        6.99424261e-03, 1.01102170e-04, 3.19661683e-03, 4.91160095e-03,\n",
       "        8.15210832e-03, 6.99424261e-03, 1.44376113e-03, 7.15362445e-03,\n",
       "        4.40281261e-03, 3.05569594e-03, 1.69303056e-03, 1.44376113e-03,\n",
       "        7.15362445e-03, 4.40281261e-03, 3.05569594e-03, 1.69303056e-03,\n",
       "        1.13871555e-02, 8.38838812e-04, 1.43296039e-03, 2.39877583e-03,\n",
       "        4.09449934e-03, 1.13871555e-02, 8.38838812e-04, 1.43296039e-03,\n",
       "        2.39877583e-03, 4.09449934e-03, 3.26118088e-03, 2.12728129e-03,\n",
       "        2.07466470e-03, 2.34271348e-03, 1.37817399e-03, 4.04365421e-03,\n",
       "        2.32562018e-03, 5.09230711e-03, 4.56319949e-03, 1.74078292e-03,\n",
       "        2.85115874e-03, 1.21376692e-02, 8.24417940e-03, 3.23620289e-03,\n",
       "        2.15675259e-03, 6.69147635e-03, 1.30852075e-03, 3.41831234e-03,\n",
       "        8.02827370e-03, 5.50389956e-03, 9.28401184e-03, 5.98995803e-03,\n",
       "        2.70827094e-03, 3.40489779e-03, 3.46098852e-03, 6.39102299e-05,\n",
       "        9.06128319e-05, 8.49035673e-05, 8.49035673e-05, 1.22309996e-04,\n",
       "        2.75226536e-04, 8.33086096e-05, 5.83344509e-05, 6.71159469e-05,\n",
       "        2.79302954e-04, 2.98563740e-03, 2.12079643e-03, 2.67695345e-03,\n",
       "        1.24806596e-03, 1.88765598e-03, 2.17749339e-03, 2.27086750e-03,\n",
       "        2.76629936e-03, 9.13528734e-04, 1.89948417e-03, 4.10305425e-03,\n",
       "        5.60378248e-03, 5.02319961e-03, 3.42040123e-03, 4.14846672e-03,\n",
       "        5.68198324e-03, 2.02159565e-03, 4.89921376e-03, 4.64723642e-03,\n",
       "        2.70247934e-03, 3.11707087e-03, 4.43251799e-03, 6.59119096e-03,\n",
       "        5.67809170e-03, 3.32171684e-03, 3.60050778e-03, 1.04009513e-02,\n",
       "        1.12945035e-02, 6.53227754e-03, 5.42038797e-03, 4.00897503e-03,\n",
       "        6.15962060e-03, 3.73638673e-03, 4.00518304e-03, 3.57429512e-03,\n",
       "        8.78375160e-03, 5.01198399e-03, 1.55071732e-03, 4.88857387e-03,\n",
       "        8.48210713e-03]),\n",
       " 'rank_test_score': array([100,  88,  82,  56,  39, 100,  88,  82,  56,  39, 102,  86,  77,\n",
       "         65,  63, 102,  86,  77,  65,  63, 104,  61,  51,  53,  59, 104,\n",
       "         61,  51,  53,  59,  90, 110, 114, 122, 124,  90, 110, 114, 122,\n",
       "        124,  98, 118, 120, 116, 112,  98, 118, 120, 116, 112,  84,  81,\n",
       "         85,  79,  69,  58,  43,  32,  27,  23,  37,   9,   6,   3,   2,\n",
       "         41,  18,  17,  14,  12,  48,  25,  22,  20,  19, 106, 107, 108,\n",
       "        108,  94,  92,  95,  96,  97,  93,  68,  72,  80,  74,  70,  76,\n",
       "         73,  75,  71,  67,  49,  46,  47,  44,  42,  55,  45,  36,  29,\n",
       "         28,  38,  24,  21,  16,  13,  35,  11,   7,   4,   1,  50,  34,\n",
       "         31,  30,  26,  33,  15,  10,   8,   5])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_opt3_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sel',\n",
       "                 SelectKBest(k='all',\n",
       "                             score_func=<function chi2 at 0x00000209DFB01700>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('learner',\n",
       "                 LogisticRegression(C=10,\n",
       "                                    class_weight={'rosso': 20, 'verde': 1},\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_opt3_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "rating_opt3_predictions = rating_opt3_search.best_estimator_.predict(X_test_tok)\n",
    "\n",
    "rating_correct = 0\n",
    "rating_true_labels = [x for x in y_test.Rating]\n",
    "\n",
    "for prediction,rating_true_labels in zip(rating_opt3_predictions, rating_true_labels):\n",
    "    if prediction==rating_true_labels:\n",
    "        rating_correct += 1\n",
    "        \n",
    "print(f\"Accuracy: {(rating_correct/len(rating_opt3_predictions)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       rosso       0.60      0.64      0.62      1399\n",
      "       verde       0.95      0.94      0.94      9909\n",
      "\n",
      "    accuracy                           0.90     11308\n",
      "   macro avg       0.78      0.79      0.78     11308\n",
      "weighted avg       0.91      0.90      0.90     11308\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 889  510]\n",
      " [ 584 9325]]\n"
     ]
    }
   ],
   "source": [
    "rating_opt3_predictions = rating_opt3_search.best_estimator_.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, rating_opt3_predictions))\n",
    "print('Confusion matrix:')\n",
    "rating_opt3_cm = confusion_matrix(y_test, rating_opt3_predictions)\n",
    "print(rating_opt3_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define undersample strategy\n",
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'rosso': 3263, 'verde': 3263})\n"
     ]
    }
   ],
   "source": [
    "X_und, y_und = rus.fit_resample(x_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_und.Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vect_und = CountVectorizer(analyzer=spacy_nlp_tokenizer, min_df=5)  \n",
    "#reset_counter()\n",
    "#X_train_und_tok = vect_und.fit_transform(X_und.Racconto_Text_Only)\n",
    "#reset_counter()\n",
    "#X_test_und_tok = vect_und.transform(x_test.Racconto_Text_Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(path+r'\\Rating\\vg_vs_ar\\X_train_und_tok.pkl','wb') as outfile:\n",
    "#    pickle.dump(X_train_und_tok,outfile)\n",
    "#with open(path+r'\\Rating\\vg_vs_ar\\X_test_und_tok.pkl','wb') as outfile:\n",
    "#    pickle.dump(X_test_und_tok,outfile)\n",
    "#with open(path+r'\\Rating\\vg_vs_ar\\vect_und.pkl','wb') as outfile:\n",
    "#    pickle.dump(vect_und,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(path+r\"\\Rating\\vg_vs_ar\\X_train_und_tok.pkl\", \"rb\")\n",
    "X_train_und_tok = pickle.load(a_file)\n",
    "\n",
    "b_file = open(path+r\"\\Rating\\vg_vs_ar\\X_test_und_tok.pkl\", \"rb\")\n",
    "X_test_und_tok = pickle.load(b_file)\n",
    "\n",
    "c_file = open(path+r\"\\Rating\\vg_vs_ar\\vect_und.pkl\", \"rb\")\n",
    "vect_und = pickle.load(c_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_und_opt_pipeline = Pipeline([\n",
    "#    ('vect', CountVectorizer()),  # feature extraction\n",
    "    ('sel', SelectKBest(chi2)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LinearSVC())  # learning algorithm\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 125 candidates, totalling 375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiar\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.73719922 0.73970641 0.74425827        nan 0.7479372  0.7374046\n",
      " 0.73986448 0.74441678        nan 0.74819475 0.73011605 0.76484907\n",
      " 0.75966977        nan 0.75712325 0.73053693 0.7650301  0.75984999\n",
      "        nan 0.75730241 0.7074544  0.67542112 0.74790043        nan\n",
      " 0.75499765 0.7076803  0.67567193 0.74809878        nan 0.75518292\n",
      " 0.61604968 0.7384712  0.72575172        nan 0.71024506 0.61604972\n",
      " 0.73867393 0.72581793        nan 0.71039213 0.69556986 0.72003883\n",
      " 0.67932626        nan 0.6737319  0.69567245 0.7201069  0.67946499\n",
      "        nan 0.67393949 0.69754743 0.70220842 0.68815396        nan\n",
      " 0.68393202 0.73408534 0.73549812 0.73453757        nan 0.73128078\n",
      " 0.75759232 0.77056755 0.76949118        nan 0.76669137 0.74086522\n",
      " 0.76355639 0.77060082        nan 0.76988538 0.72308339 0.74563529\n",
      " 0.75867819        nan 0.76094836 0.66666665 0.66666665 0.66666665\n",
      "        nan 0.66666665 0.67054039 0.68098895 0.68347962        nan\n",
      " 0.67998848 0.60389647 0.61317811 0.62676292        nan 0.63248592\n",
      " 0.70097422 0.70588211 0.69004043        nan 0.68870424 0.72553583\n",
      " 0.72475829 0.72697555        nan 0.73178965 0.73878518 0.7398105\n",
      " 0.73932672        nan 0.73518384 0.74146534 0.75139095 0.75971586\n",
      "        nan 0.76031524 0.76211255 0.76723841 0.76839029        nan\n",
      " 0.7640702  0.72207278 0.73372242 0.74240782        nan 0.74533438\n",
      " 0.75094844 0.76921459 0.7721283         nan 0.77237381]\n",
      "  warnings.warn(\n",
      "C:\\Users\\chiar\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "rating_und_opt_search = GridSearchCV(rating_und_opt_pipeline, \n",
    "                                     search_space, \n",
    "                                     scoring = scoring, \n",
    "                                     cv=3, n_jobs = -1, verbose=True).fit(X_train_und_tok, y_und)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner': LogisticRegression(C=100, solver='liblinear'),\n",
       " 'learner__C': 100,\n",
       " 'learner__penalty': 'l2',\n",
       " 'learner__solver': 'liblinear',\n",
       " 'sel__k': 'all'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_und_opt_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sel',\n",
       "                 SelectKBest(k='all',\n",
       "                             score_func=<function chi2 at 0x00000115020D2C10>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('learner', LogisticRegression(C=100, solver='liblinear'))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_und_opt_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "rating_und_opt_predictions = rating_und_opt_search.best_estimator_.predict(X_test_und_tok)\n",
    "\n",
    "rating_und_correct = 0\n",
    "rating_und_true_labels = [x for x in y_test.Rating]\n",
    "\n",
    "for prediction,rating_und_true_labels in zip(rating_und_opt_predictions, rating_und_true_labels):\n",
    "    if prediction==rating_und_true_labels:\n",
    "        rating_und_correct += 1\n",
    "        \n",
    "print(f\"Accuracy: {(rating_und_correct/len(rating_und_opt_predictions)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       rosso       0.38      0.79      0.51      1399\n",
      "       verde       0.96      0.82      0.88      9909\n",
      "\n",
      "    accuracy                           0.81     11308\n",
      "   macro avg       0.67      0.80      0.70     11308\n",
      "weighted avg       0.89      0.81      0.84     11308\n",
      "\n",
      "Confusion matrix:\n",
      "[[1100  299]\n",
      " [1811 8098]]\n"
     ]
    }
   ],
   "source": [
    "rating_und_opt_predictions = rating_und_opt_search.best_estimator_.predict(X_test_und_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, rating_und_opt_predictions))\n",
    "print('Confusion matrix:')\n",
    "rating_und_opt_cm = confusion_matrix(y_test, rating_und_opt_predictions)\n",
    "print(rating_und_opt_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define undersample strategy\n",
    "rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'verde': 6526, 'rosso': 3263})\n"
     ]
    }
   ],
   "source": [
    "X_und2, y_und2 = rus.fit_resample(x_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_und2.Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vect_und2 = CountVectorizer(analyzer=spacy_nlp_tokenizer, min_df=5)  \n",
    "#reset_counter()\n",
    "#X_train_und2_tok = vect_und2.fit_transform(X_und2.Racconto_Text_Only)\n",
    "#reset_counter()\n",
    "#X_test_und2_tok = vect_und2.transform(x_test.Racconto_Text_Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(path+r'\\Rating\\vg_vs_ar\\X_train_und2_tok.pkl','wb') as outfile:\n",
    "#    pickle.dump(X_train_und2_tok,outfile)\n",
    "#with open(path+r'\\Rating\\vg_vs_ar\\X_test_und2_tok.pkl','wb') as outfile:\n",
    "#    pickle.dump(X_test_und2_tok,outfile)\n",
    "#with open(path+r'\\Rating\\vg_vs_ar\\vect_und2.pkl','wb') as outfile:\n",
    "#    pickle.dump(vect_und2,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(path+r\"\\Rating\\vg_vs_ar\\X_train_und2_tok.pkl\", \"rb\")\n",
    "X_train_und2_tok = pickle.load(a_file)\n",
    "\n",
    "b_file = open(path+r\"\\Rating\\vg_vs_ar\\X_test_und2_tok.pkl\", \"rb\")\n",
    "X_test_und2_tok = pickle.load(b_file)\n",
    "\n",
    "c_file = open(path+r\"\\Rating\\vg_vs_ar\\vect_und2.pkl\", \"rb\")\n",
    "vect_und2 = pickle.load(c_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_und2_opt_pipeline = Pipeline([\n",
    "#    ('vect', CountVectorizer()),  # feature extraction\n",
    "    ('sel', SelectKBest(chi2)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LinearSVC())  # learning algorithm\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 125 candidates, totalling 375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiar\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.62991001 0.67280647 0.6813167         nan 0.67273671 0.66804217\n",
      " 0.63893896 0.67785526        nan 0.67816164 0.62111407 0.67417732\n",
      " 0.67141059        nan 0.67458178 0.66497957 0.6775054  0.68295107\n",
      "        nan 0.68107485 0.58143519 0.49997397 0.51171974        nan\n",
      " 0.54286911 0.65554378 0.57371176 0.58232423        nan 0.60904235\n",
      " 0.38130878 0.03492763 0.01519188        nan 0.0206171  0.50726627\n",
      " 0.07932861 0.05300016        nan 0.06454284 0.         0.\n",
      " 0.                nan 0.         0.01940001 0.00183599 0.00183599\n",
      "        nan 0.00183599 0.2441382  0.19026931 0.22401476        nan\n",
      " 0.2926281  0.57860634 0.57439829 0.57800234        nan 0.58591277\n",
      " 0.66300236 0.6697769  0.66949761        nan 0.66754198 0.65419257\n",
      " 0.67371673 0.68423335        nan 0.68513297 0.6230803  0.65660684\n",
      " 0.67263942        nan 0.67842189 0.         0.         0.\n",
      "        nan 0.         0.         0.         0.                nan\n",
      " 0.         0.2085516  0.16247407 0.20697841        nan 0.30410698\n",
      " 0.29870805 0.24445061 0.27620765        nan 0.34600523 0.62154852\n",
      " 0.61737771 0.62091569        nan 0.62504005 0.59322805 0.58970517\n",
      " 0.5925041         nan 0.59368408 0.65909638 0.66650277 0.68134716\n",
      "        nan 0.68336267 0.66623803 0.66873934 0.66570103        nan\n",
      " 0.6644769  0.62936512 0.65104321 0.6612198         nan 0.66356822\n",
      " 0.66209245 0.67836546 0.68337242        nan 0.67835624]\n",
      "  warnings.warn(\n",
      "C:\\Users\\chiar\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "rating_und2_opt_search = GridSearchCV(rating_und2_opt_pipeline, \n",
    "                                      search_space, \n",
    "                                      scoring = scoring,\n",
    "                                      cv=3, n_jobs = -1, verbose=True).fit(X_train_und2_tok, y_und2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner': LinearSVC(C=10), 'learner__C': 10, 'sel__k': 'all'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_und2_opt_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sel',\n",
       "                 SelectKBest(k='all',\n",
       "                             score_func=<function chi2 at 0x00000115020D2C10>)),\n",
       "                ('tfidf', TfidfTransformer()), ('learner', LinearSVC(C=10))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_und2_opt_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "rating_und2_opt_predictions = rating_und2_opt_search.best_estimator_.predict(X_test_und2_tok)\n",
    "\n",
    "rating_und2_correct = 0\n",
    "rating_und2_true_labels = [x for x in y_test.Rating]\n",
    "\n",
    "for prediction,rating_und2_true_labels in zip(rating_und2_opt_predictions, rating_und2_true_labels):\n",
    "    if prediction==rating_und2_true_labels:\n",
    "        rating_und2_correct += 1\n",
    "        \n",
    "print(f\"Accuracy: {(rating_und2_correct/len(rating_und2_opt_predictions)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       rosso       0.55      0.65      0.60      1399\n",
      "       verde       0.95      0.92      0.94      9909\n",
      "\n",
      "    accuracy                           0.89     11308\n",
      "   macro avg       0.75      0.79      0.77     11308\n",
      "weighted avg       0.90      0.89      0.89     11308\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 914  485]\n",
      " [ 759 9150]]\n"
     ]
    }
   ],
   "source": [
    "rating_und2_opt_predictions = rating_und2_opt_search.best_estimator_.predict(X_test_und2_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, rating_und2_opt_predictions))\n",
    "print('Confusion matrix:')\n",
    "rating_und2_opt_cm = confusion_matrix(y_test, rating_und2_opt_predictions)\n",
    "print(rating_und2_opt_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define undersample strategy\n",
    "ros = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'verde': 23122, 'rosso': 23122})\n"
     ]
    }
   ],
   "source": [
    "X_over, y_over = ros.fit_resample(x_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_over.Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n"
     ]
    }
   ],
   "source": [
    "#vect_over = CountVectorizer(analyzer=spacy_nlp_tokenizer, min_df=5)  \n",
    "#reset_counter()\n",
    "#X_train_over_tok = vect_over.fit_transform(X_over.Racconto_Text_Only)\n",
    "#reset_counter()\n",
    "#X_test_over_tok = vect_over.transform(x_test.Racconto_Text_Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(path+r'\\Rating\\vg_vs_ar\\X_train_over_tok.pkl','wb') as outfile:\n",
    "#    pickle.dump(X_train_over_tok,outfile)\n",
    "#with open(path+r'\\Rating\\vg_vs_ar\\X_test_over_tok.pkl','wb') as outfile:\n",
    "#    pickle.dump(X_test_over_tok,outfile)\n",
    "#with open(path+r'\\Rating\\vg_vs_ar\\vect_over.pkl','wb') as outfile:\n",
    "#    pickle.dump(vect_over,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(path+r\"\\Rating\\vg_vs_ar\\X_train_over_tok.pkl\", \"rb\")\n",
    "X_train_over_tok = pickle.load(a_file)\n",
    "\n",
    "b_file = open(path+r\"\\Rating\\vg_vs_ar\\X_test_over_tok.pkl\", \"rb\")\n",
    "X_test_over_tok = pickle.load(b_file)\n",
    "\n",
    "c_file = open(path+r\"\\Rating\\vg_vs_ar\\vect_over.pkl\", \"rb\")\n",
    "vect_over = pickle.load(c_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'sel__k': [10000, 100000, 250000, 500000, 'all'],\n",
    "                 'learner':[MultinomialNB()],\n",
    "                 'learner__alpha': [1e-3, 1e-2, 0.1, 1.0, 10.0],\n",
    "                 'learner__fit_prior':[True, False]}, \n",
    "                {'sel__k': [10000, 100000, 250000, 500000, 'all'],\n",
    "                 'learner':[LinearSVC()],\n",
    "                 'learner__C': [0.01, 0.1, 1, 10, 100]},\n",
    "                {'sel__k': [10000, 100000, 250000, 500000, 'all'], \n",
    "                 'learner':[LogisticRegression()],\n",
    "                 'learner__solver':[\"liblinear\"],\n",
    "                 'learner__penalty' : ['l1', 'l2'],\n",
    "                 'learner__C': [0.01, 0.1, 1, 10, 100]} \n",
    "               ]\n",
    "\n",
    "rating_over_opt_pipeline = Pipeline([\n",
    "#    ('vect', CountVectorizer()),  # feature extraction\n",
    "    ('sel', SelectKBest(chi2)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LinearSVC())  # learning algorithm\n",
    "])\n",
    "\n",
    "scoring = make_scorer(f1_score, greater_is_better=True, pos_label='rosso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 125 candidates, totalling 375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiar\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "rating_over_opt_search = GridSearchCV(rating_over_opt_pipeline, \n",
    "                                     search_space, \n",
    "                                     scoring = scoring, \n",
    "                                     cv=3, n_jobs = -1, verbose=True).fit(X_train_over_tok, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner': LinearSVC(C=10), 'learner__C': 10, 'sel__k': 'all'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_over_opt_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sel',\n",
       "                 SelectKBest(k='all',\n",
       "                             score_func=<function chi2 at 0x000001516A1E5DC0>)),\n",
       "                ('tfidf', TfidfTransformer()), ('learner', LinearSVC(C=10))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_over_opt_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "rating_over_opt_predictions = rating_over_opt_search.best_estimator_.predict(X_test_over_tok)\n",
    "\n",
    "rating_over_correct = 0\n",
    "rating_over_true_labels = [x for x in y_test.Rating]\n",
    "\n",
    "for prediction,rating_over_true_labels in zip(rating_over_opt_predictions, rating_over_true_labels):\n",
    "    if prediction==rating_over_true_labels:\n",
    "        rating_over_correct += 1\n",
    "        \n",
    "print(f\"Accuracy: {(rating_over_correct/len(rating_over_opt_predictions)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       rosso       0.84      0.38      0.52      1399\n",
      "       verde       0.92      0.99      0.95      9909\n",
      "\n",
      "    accuracy                           0.91     11308\n",
      "   macro avg       0.88      0.68      0.74     11308\n",
      "weighted avg       0.91      0.91      0.90     11308\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 532  867]\n",
      " [ 103 9806]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "rating_over_opt_predictions = rating_over_opt_search.best_estimator_.predict(X_test_over_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, rating_over_opt_predictions))\n",
    "print('Confusion matrix:')\n",
    "rating_over_opt_cm = confusion_matrix(y_test, rating_over_opt_predictions)\n",
    "print(rating_over_opt_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model: Class weight 20:1 - Inspecting the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt_pipeline = Pipeline(steps=[('sel',\n",
    "                 SelectKBest(k='all',\n",
    "                             score_func=chi2)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('learner',\n",
    "                 LogisticRegression(C=10,\n",
    "                                    class_weight={'rosso': 20, 'verde': 1},\n",
    "                                    solver='liblinear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sel',\n",
       "                 SelectKBest(k='all',\n",
       "                             score_func=<function chi2 at 0x00000209DFB01700>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('learner',\n",
       "                 LogisticRegression(C=10,\n",
       "                                    class_weight={'rosso': 20, 'verde': 1},\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_opt_pipeline.fit(X_train_tok, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tokenizer = vect\n",
    "rating_selector = model_opt_pipeline.named_steps['sel']\n",
    "rating_classifier = model_opt_pipeline.named_steps['learner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911443"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_feature_names = rating_tokenizer.get_feature_names()\n",
    "rating_feats_w_score = list()\n",
    "for index,(selected,score) in enumerate(zip(rating_selector.get_support(),rating_selector.scores_)):\n",
    "    rating_feats_w_score.append((score,selected,rating_feature_names[index]))\n",
    "rating_feats_w_score = sorted(rating_feats_w_score)\n",
    "len(rating_feats_w_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating_feats_w_score[:100],rating_feats_w_score[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911443"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_feats_w_classifier_weight = list()\n",
    "for index,weight in enumerate(rating_selector.inverse_transform(rating_classifier.coef_)[0]):\n",
    "    if weight!=0:\n",
    "        rating_feats_w_classifier_weight.append((weight,rating_feature_names[index]))\n",
    "rating_feats_w_classifier_weight = sorted(rating_feats_w_classifier_weight)\n",
    "len(rating_feats_w_classifier_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.0315734108499393, 'LEMMA_lacrima'),\n",
       " (3.036774913161319, 'LEMMA_silenziare'),\n",
       " (3.0382158354857047, 'LEMMA_muro'),\n",
       " (3.0462282007379677, 'LEMMA_torto'),\n",
       " (3.0517666303823026, 'LEMMA_Sai'),\n",
       " (3.063252435764093, 'BI_LEMMA_;_LEMMA_e'),\n",
       " (3.065011157555644, 'BI_LEMMA_morire_LEMMA_,'),\n",
       " (3.0716020009998113, 'BI_LEMMA_lo_LEMMA_scrivere'),\n",
       " (3.0738947705041593, 'LEMMA_amicizia'),\n",
       " (3.080184946738424, 'BI_LEMMA_volere_LEMMA_andare'),\n",
       " (3.0935815349234197, 'LEMMA_saltellare'),\n",
       " (3.0976090631110393, 'BI_LEMMA_venire_LEMMA_mentire'),\n",
       " (3.099010378552887, 'LEMMA_idiota'),\n",
       " (3.1011021379107206, 'LEMMA_adorare'),\n",
       " (3.107717124937904, 'LEMMA_Grattastinchi'),\n",
       " (3.11633585333988, 'LEMMA_increspare'),\n",
       " (3.119578844351076, 'LEMMA_rassegnare'),\n",
       " (3.125103668290136, 'BI_LEMMA_scrivere_LEMMA_,'),\n",
       " (3.130878786463479, 'TRI_LEMMA_-_LEMMA_._LEMMA_-'),\n",
       " (3.138975257794404, 'LEMMA_gigante'),\n",
       " (3.1479215979162114, 'LEMMA_vestire'),\n",
       " (3.149091645195105, 'BI_LEMMA_“_LEMMA_...'),\n",
       " (3.1543930785923795, 'LEMMA_coda'),\n",
       " (3.1552285276838767, 'BI_LEMMA_._LEMMA_osservare'),\n",
       " (3.1727824496955, 'LEMMA_Natale'),\n",
       " (3.2018326524457605, 'LEMMA_ripensare'),\n",
       " (3.2065460888234623, 'BI_LEMMA_._LEMMA_donna'),\n",
       " (3.233210934172983, 'BI_LEMMA_,_LEMMA_dire'),\n",
       " (3.245011206240074, 'LEMMA_onore'),\n",
       " (3.256888167383405, 'LEMMA_pioggia'),\n",
       " (3.344198539650468, 'LEMMA_canzone'),\n",
       " (3.358843659985161, 'BI_LEMMA_Ok_LEMMA_,'),\n",
       " (3.3729547037528764, 'LEMMA_frase'),\n",
       " (3.379955432216178, 'LEMMA_erba'),\n",
       " (3.4213907083489663, 'LEMMA_freddare'),\n",
       " (3.4261059727588803, 'BI_LEMMA_”_LEMMA_Hermione'),\n",
       " (3.4369655495194307, 'LEMMA_borsa'),\n",
       " (3.4538394353237236, \"LEMMA_E'\"),\n",
       " (3.4575987338155887, 'BI_LEMMA_,_LEMMA_—'),\n",
       " (3.4630387779401377, 'LEMMA_felice'),\n",
       " (3.4690543122957433, 'TRI_LEMMA_:_LEMMA_<_LEMMA_<'),\n",
       " (3.4732566074239166, 'LEMMA_fondere'),\n",
       " (3.4773498976921378, 'LEMMA_descrivere'),\n",
       " (3.4819654050654556, 'LEMMA_povero'),\n",
       " (3.497836652841848, 'LEMMA_zia'),\n",
       " (3.518005531094947, 'LEMMA_cielo'),\n",
       " (3.525438317780122, 'LEMMA_vento'),\n",
       " (3.532233233610715, 'LEMMA_rosso'),\n",
       " (3.5371512250361157, 'BI_LEMMA_._LEMMA_Potter'),\n",
       " (3.5577578089857154, 'LEMMA_poesia'),\n",
       " (3.5653977864470816, 'LEMMA_tempo'),\n",
       " (3.5957349010311703, 'LEMMA_NdA'),\n",
       " (3.6275623073754244, 'BI_LEMMA_padre_LEMMA_.'),\n",
       " (3.6393531111084156, 'BI_LEMMA_sguardo_LEMMA_,'),\n",
       " (3.6568323716904954, 'BI_LEMMA_Lily_LEMMA_,'),\n",
       " (3.6656147837761273, 'LEMMA_avvicinare'),\n",
       " (3.705999227860763, 'LEMMA_Dissennatori'),\n",
       " (3.709781126383583, 'BI_LEMMA_._LEMMA_passare'),\n",
       " (3.7114472715823412, 'LEMMA_Be'),\n",
       " (3.726235336376985, 'LEMMA_riflettere'),\n",
       " (3.743573533064586, 'BI_LEMMA_e_LEMMA_,'),\n",
       " (3.748550101807291, 'BI_LEMMA_baciare_LEMMA_.'),\n",
       " (3.7506427172613503, 'LEMMA_Angolo'),\n",
       " (3.7528898720127484, 'LEMMA_battere'),\n",
       " (3.7608582183004544, 'LEMMA_pagina'),\n",
       " (3.831122131164329, 'LEMMA_Umbridge'),\n",
       " (3.8533624067814594, 'LEMMA_librare'),\n",
       " (3.881531505157981, 'BI_LEMMA_!_LEMMA_)'),\n",
       " (3.917482414011479, 'BI_LEMMA_James_LEMMA_,'),\n",
       " (3.9251184756200357, 'LEMMA_Cho'),\n",
       " (3.934862748366133, 'BI_LEMMA_._LEMMA_,'),\n",
       " (3.9412118776384104, 'LEMMA_concluso'),\n",
       " (3.987993148299779, 'LEMMA_piccolo'),\n",
       " (4.082180556807014, 'LEMMA_naso'),\n",
       " (4.086223441837522, 'LEMMA_tasca'),\n",
       " (4.102411822466244, 'LEMMA_drabble'),\n",
       " (4.150835539360573, 'LEMMA_saltare'),\n",
       " (4.177803776299256, 'LEMMA_po’'),\n",
       " (4.210117349554933, 'LEMMA_orgoglio'),\n",
       " (4.2324487957488985, 'LEMMA_....'),\n",
       " (4.248845450784387, 'LEMMA_!'),\n",
       " (4.342765576662638, 'LEMMA_giardino'),\n",
       " (4.388177019549155, 'BI_LEMMA_sorridere_LEMMA_.'),\n",
       " (4.403546752592844, 'LEMMA_scrivere'),\n",
       " (4.521826203170361, 'LEMMA_osservare'),\n",
       " (4.646969278433795, 'LEMMA_Ninfadora'),\n",
       " (4.7078990527777895, 'LEMMA_cuore'),\n",
       " (4.710557373511937, 'LEMMA_:)'),\n",
       " (4.739549818876776, 'LEMMA_parola'),\n",
       " (4.911619322648045, 'LEMMA_accanto'),\n",
       " (5.000624853267844, 'LEMMA_neve'),\n",
       " (5.108526284389459, 'TRI_LEMMA_»_LEMMA_,_LEMMA_dire'),\n",
       " (5.1238054160477216, 'LEMMA_fronte'),\n",
       " (5.201315977758785, 'BI_LEMMA_Lily_LEMMA_.'),\n",
       " (5.222877283840582, 'LEMMA_volare'),\n",
       " (5.2434810312716, 'TRI_LEMMA_!_LEMMA_”_LEMMA_“'),\n",
       " (6.382851262532067, 'LEMMA_recensire'),\n",
       " (7.1105148220813525, 'LEMMA_ballare'),\n",
       " (7.522452585689027, 'LEMMA_Narcissa'),\n",
       " (8.630048655345037, 'LEMMA_sorridere')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_feats_w_classifier_weight[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-18.097778635466, 'LEMMA_corpo'),\n",
       " (-16.810622086790264, 'LEMMA_gemito'),\n",
       " (-15.63512568075024, 'LEMMA_sesso'),\n",
       " (-15.451257567287875, 'LEMMA_seno'),\n",
       " (-12.59878864153141, 'LEMMA_lingua'),\n",
       " (-11.821674736945305, 'LEMMA_orgasmo'),\n",
       " (-11.627788691586755, 'LEMMA_erezione'),\n",
       " (-10.5952269042034, 'LEMMA_pantalone'),\n",
       " (-10.516864989902631, 'LEMMA_gamba'),\n",
       " (-10.311711403436751, 'LEMMA_collare'),\n",
       " (-10.210643204059814, 'LEMMA_spingere'),\n",
       " (-10.107646599273288, 'LEMMA_gemere'),\n",
       " (-10.10698577135987, 'LEMMA_capitolare'),\n",
       " (-10.023642462329745, 'LEMMA_spinto'),\n",
       " (-9.88785642102203, 'LEMMA_bocca'),\n",
       " (-9.64356367340396, 'LEMMA_nudo'),\n",
       " (-9.282737711496287, 'LEMMA_coscia'),\n",
       " (-9.251168581281776, 'LEMMA_scendere'),\n",
       " (-8.83613388813969, 'LEMMA_eccitare'),\n",
       " (-8.585669212319274, 'LEMMA_passione'),\n",
       " (-8.38834621977512, 'LEMMA_labbro'),\n",
       " (-8.11121583680865, 'LEMMA_pelle'),\n",
       " (-8.063459075700171, 'LEMMA_dito'),\n",
       " (-8.02438806124627, 'LEMMA_prologo'),\n",
       " (-7.848542989677528, 'LEMMA_eccitazione'),\n",
       " (-7.690778824751348, 'LEMMA_capezzolo'),\n",
       " (-7.605373705948895, 'BI_LEMMA_il_LEMMA_pantalone'),\n",
       " (-7.488525161800286, 'LEMMA_sangue'),\n",
       " (-7.361009487842039, 'LEMMA_iniziare'),\n",
       " (-7.141654639291765, 'LEMMA_membro'),\n",
       " (-7.070902203308727, 'LEMMA_reggiseno'),\n",
       " (-6.942985884168292, 'LEMMA_desiderio'),\n",
       " (-6.665251836923815, 'LEMMA_fianco'),\n",
       " (-6.609681725442256, 'LEMMA_leggere'),\n",
       " (-6.593395834524205, 'LEMMA_leccare'),\n",
       " (-6.581359926899102, 'LEMMA_cazzo'),\n",
       " (-6.544597700495397, 'LEMMA_Dio'),\n",
       " (-6.533144602624587, 'LEMMA_gonna'),\n",
       " (-6.372818001733327, 'LEMMA_piacere'),\n",
       " (-6.308654556234186, 'LEMMA_odore'),\n",
       " (-6.292622889852703, 'LEMMA_sfilare'),\n",
       " (-6.246904213830392, 'LEMMA_ansimare'),\n",
       " (-6.185920445969908, 'BI_LEMMA_collare_LEMMA_,'),\n",
       " (-6.120131597828856, 'LEMMA_accarezzare'),\n",
       " (-6.1085764053546905, 'LEMMA_togliere'),\n",
       " (-5.985823297171606, 'LEMMA_schiena'),\n",
       " (-5.969347110296932, 'LEMMA_camicia'),\n",
       " (-5.964215558207067, 'BI_LEMMA_»_LEMMA_,'),\n",
       " (-5.921216578887386, 'TRI_LEMMA_,_LEMMA_,_LEMMA_,'),\n",
       " (-5.8948807519649415, 'BI_LEMMA_\"_LEMMA_Disse'),\n",
       " (-5.779681335659459, 'LEMMA_penetrare'),\n",
       " (-5.723556560297648, 'LEMMA_stanza'),\n",
       " (-5.701011555340723, 'LEMMA_slacciare'),\n",
       " (-5.674771197456204, 'LEMMA_torturare'),\n",
       " (-5.642955707152064, 'LEMMA_venire'),\n",
       " (-5.634838651259438, 'LEMMA_capitolo'),\n",
       " (-5.629151568755619, 'BI_LEMMA_piacere_LEMMA_.'),\n",
       " (-5.58883460156276, 'LEMMA_puttana'),\n",
       " (-5.485822782213899, 'LEMMA_vestito'),\n",
       " (-5.431213559723549, 'LEMMA_fisico'),\n",
       " (-5.39884206343023, 'LEMMA_Prologo'),\n",
       " (-5.353111282252309, 'LEMMA_/'),\n",
       " (-5.325017738960598, 'LEMMA_Auror'),\n",
       " (-5.30955547936232, 'LEMMA_POV'),\n",
       " (-5.297431026754345, 'BI_LEMMA_il_LEMMA_gemito'),\n",
       " (-5.2836967114750495, 'LEMMA_violenza'),\n",
       " (-5.236674618970647, 'LEMMA_Ryta'),\n",
       " (-5.09103792337436, 'LEMMA_spogliare'),\n",
       " (-5.029517603896095, 'LEMMA_Ares'),\n",
       " (-5.027957588911446, 'BI_LEMMA_il_LEMMA_fianco'),\n",
       " (-4.961375768574736, 'LEMMA_°'),\n",
       " (-4.9587322267248535, 'LEMMA_ventre'),\n",
       " (-4.946723912697859, 'BI_LEMMA_seno_LEMMA_,'),\n",
       " (-4.925132702013094, 'LEMMA_mutandina'),\n",
       " (-4.925028210747477, 'LEMMA_fottere'),\n",
       " (-4.876401947089312, 'LEMMA_Cassandra'),\n",
       " (-4.821482471314718, 'LEMMA_indumento'),\n",
       " (-4.8113818888565065, 'LEMMA_il'),\n",
       " (-4.784616666506181, 'LEMMA_rating'),\n",
       " (-4.75565991076388, 'LEMMA_pena'),\n",
       " (-4.740310761373688, 'LEMMA_bacio'),\n",
       " (-4.705816143927698, 'BI_LEMMA_piacere_LEMMA_,'),\n",
       " (-4.696101144327477, 'LEMMA_Anakin'),\n",
       " (-4.689920495599311, 'LEMMA_vergine'),\n",
       " (-4.688830811342252, 'LEMMA_bastardo'),\n",
       " (-4.67897841236625, 'TRI_LEMMA_♥_LEMMA_♥_LEMMA_♥'),\n",
       " (-4.657700428538533, 'LEMMA_Rosemary'),\n",
       " (-4.629038271178895, 'LEMMA_lenzuolo'),\n",
       " (-4.611450189152746, 'BI_LEMMA_)_LEMMA_('),\n",
       " (-4.595128891923584, 'LEMMA_sdraiare'),\n",
       " (-4.562883112838259, 'LEMMA_carne'),\n",
       " (-4.549074377889829, 'LEMMA_all’'),\n",
       " (-4.546433164174265, 'BI_LEMMA_prossimo_LEMMA_capitolare'),\n",
       " (-4.5042849659044135, 'LEMMA_sessuale'),\n",
       " (-4.487385111625656, 'LEMMA_camicetta'),\n",
       " (-4.446127300050595, 'BI_LEMMA_orgasmo_LEMMA_.'),\n",
       " (-4.4451681788900475, 'LEMMA_divano'),\n",
       " (-4.416721309741312, 'LEMMA_bottone'),\n",
       " (-4.411177138102945, 'BI_LEMMA_leggere_LEMMA_,'),\n",
       " (-4.408695839770053, 'LEMMA_succhiare')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_feats_w_classifier_weight[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
