{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "path = r'C:\\Users\\chiar\\Documents\\Università\\Text analytics\\Data'\n",
    "#path = r'D:\\tirocinioLC\\tirocinioLC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37693 entries, 1 to 54718\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype              \n",
      "---  ------   --------------  -----              \n",
      " 0   ID       37693 non-null  int64              \n",
      " 1   Title    37690 non-null  object             \n",
      " 2   Rating   37693 non-null  object             \n",
      " 3   Author   37693 non-null  object             \n",
      " 4   Date     37693 non-null  datetime64[ns, UTC]\n",
      " 5   Chapter  37693 non-null  int64              \n",
      " 6   Text     37693 non-null  object             \n",
      " 7   N_Rev    37693 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(3), object(4)\n",
      "memory usage: 2.6+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Text</th>\n",
       "      <th>N_Rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2909917</td>\n",
       "      <td>Rilassati! Hai tutta la morte davanti!</td>\n",
       "      <td>verde</td>\n",
       "      <td>Tonks98</td>\n",
       "      <td>2014-11-15 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Zi zieda, prego. Allora, quale ezzere zuo  \"B...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1390250</td>\n",
       "      <td>Episodi della Old Generation 1.</td>\n",
       "      <td>verde</td>\n",
       "      <td>mrsreg</td>\n",
       "      <td>2012-11-17 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduzione.     Personaggi:     Argus Gazza:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1143283</td>\n",
       "      <td>In Noctem</td>\n",
       "      <td>verde</td>\n",
       "      <td>LilacLilium</td>\n",
       "      <td>2012-04-07 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Questo mio piccolo lavoretto è ispirato a una ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>917615</td>\n",
       "      <td>Dirty flower.</td>\n",
       "      <td>verde</td>\n",
       "      <td>Rue</td>\n",
       "      <td>2012-07-01 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>DIRTY FLOWER.     Lo hai sempre saputo, Lily. ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>917635</td>\n",
       "      <td>Hawthorn and Unicorn Air</td>\n",
       "      <td>giallo</td>\n",
       "      <td>Tonna</td>\n",
       "      <td>2012-08-01 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Before you read:     Bentro...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                   Title  Rating       Author  \\\n",
       "1  2909917  Rilassati! Hai tutta la morte davanti!   verde      Tonks98   \n",
       "4  1390250         Episodi della Old Generation 1.   verde       mrsreg   \n",
       "5  1143283                               In Noctem   verde  LilacLilium   \n",
       "7   917615                           Dirty flower.   verde          Rue   \n",
       "8   917635                Hawthorn and Unicorn Air  giallo        Tonna   \n",
       "\n",
       "                       Date  Chapter  \\\n",
       "1 2014-11-15 00:00:00+00:00        1   \n",
       "4 2012-11-17 00:00:00+00:00        1   \n",
       "5 2012-04-07 00:00:00+00:00        1   \n",
       "7 2012-07-01 00:00:00+00:00        1   \n",
       "8 2012-08-01 00:00:00+00:00        1   \n",
       "\n",
       "                                                Text  N_Rev  \n",
       "1  \"Zi zieda, prego. Allora, quale ezzere zuo  \"B...      3  \n",
       "4  Introduzione.     Personaggi:     Argus Gazza:...      0  \n",
       "5  Questo mio piccolo lavoretto è ispirato a una ...      2  \n",
       "7  DIRTY FLOWER.     Lo hai sempre saputo, Lily. ...      3  \n",
       "8                     Before you read:     Bentro...      4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(path+'\\df_final.json')\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Rating.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verde        0.692542\n",
       "giallo       0.183774\n",
       "arancione    0.069589\n",
       "rosso        0.054095\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rating.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verde        26104\n",
       "giallo        6927\n",
       "arancione     2623\n",
       "rosso         2039\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Text</th>\n",
       "      <th>N_Rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2909917</td>\n",
       "      <td>Rilassati! Hai tutta la morte davanti!</td>\n",
       "      <td>verde</td>\n",
       "      <td>Tonks98</td>\n",
       "      <td>2014-11-15 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Zi zieda, prego. Allora, quale ezzere zuo  \"B...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1390250</td>\n",
       "      <td>Episodi della Old Generation 1.</td>\n",
       "      <td>verde</td>\n",
       "      <td>mrsreg</td>\n",
       "      <td>2012-11-17 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduzione.     Personaggi:     Argus Gazza:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1143283</td>\n",
       "      <td>In Noctem</td>\n",
       "      <td>verde</td>\n",
       "      <td>LilacLilium</td>\n",
       "      <td>2012-04-07 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Questo mio piccolo lavoretto è ispirato a una ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>917615</td>\n",
       "      <td>Dirty flower.</td>\n",
       "      <td>verde</td>\n",
       "      <td>Rue</td>\n",
       "      <td>2012-07-01 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>DIRTY FLOWER.     Lo hai sempre saputo, Lily. ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>917635</td>\n",
       "      <td>Hawthorn and Unicorn Air</td>\n",
       "      <td>rosso</td>\n",
       "      <td>Tonna</td>\n",
       "      <td>2012-08-01 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Before you read:     Bentro...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                   Title Rating       Author  \\\n",
       "1  2909917  Rilassati! Hai tutta la morte davanti!  verde      Tonks98   \n",
       "4  1390250         Episodi della Old Generation 1.  verde       mrsreg   \n",
       "5  1143283                               In Noctem  verde  LilacLilium   \n",
       "7   917615                           Dirty flower.  verde          Rue   \n",
       "8   917635                Hawthorn and Unicorn Air  rosso        Tonna   \n",
       "\n",
       "                       Date  Chapter  \\\n",
       "1 2014-11-15 00:00:00+00:00        1   \n",
       "4 2012-11-17 00:00:00+00:00        1   \n",
       "5 2012-04-07 00:00:00+00:00        1   \n",
       "7 2012-07-01 00:00:00+00:00        1   \n",
       "8 2012-08-01 00:00:00+00:00        1   \n",
       "\n",
       "                                                Text  N_Rev  \n",
       "1  \"Zi zieda, prego. Allora, quale ezzere zuo  \"B...      3  \n",
       "4  Introduzione.     Personaggi:     Argus Gazza:...      0  \n",
       "5  Questo mio piccolo lavoretto è ispirato a una ...      2  \n",
       "7  DIRTY FLOWER.     Lo hai sempre saputo, Lily. ...      3  \n",
       "8                     Before you read:     Bentro...      4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col         = 'Rating'\n",
    "conditions  = [ (df[col] == 'giallo') | (df[col] == 'rosso') | (df[col] == 'arancione'), df[col] == 'verde']\n",
    "choices     = [ 'rosso', 'verde' ] \n",
    "    \n",
    "df[col] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Rating.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verde    26104\n",
       "rosso    11589\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verde    0.692542\n",
       "rosso    0.307458\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rating.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[['Rating']]\n",
    "del df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RepeatedKFold\n",
    "\n",
    "#split on train-test \n",
    "x_train, x_test, y_train, y_test = train_test_split(df, target, test_size=0.30, random_state=42, stratify=target, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 26385\n",
      "Test set size: 11308\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set size: {len(x_train)}\\nTest set size: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction with nltk and spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download it_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load('it_core_news_sm')\n",
    "\n",
    "doc_counter = 0\n",
    "def reset_counter():\n",
    "  global doc_counter\n",
    "  doc_counter = 0\n",
    "\n",
    "def increase_counter():\n",
    "  global doc_counter\n",
    "  doc_counter += 1\n",
    "  if doc_counter % 100 == 0:\n",
    "    print(doc_counter)\n",
    "\n",
    "def spacy_nlp_tokenizer(text):\n",
    "    increase_counter()\n",
    "\n",
    "    # substituting all space characters with a single space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "\n",
    "    # we use spacy for main nlp tasks\n",
    "    doc = nlp(text)\n",
    "    # lemmatized tokens, skipping stopwords\n",
    "    lemmas = ['LEMMA_'+token.lemma_ for token in doc if not token.is_stop]\n",
    "    # entity_types\n",
    "    entity_types = ['NER_'+token.ent_type_ for token in doc if token.ent_type_]\n",
    "\n",
    "    # in case an entity linker is available, we can use it do put actual entities as\n",
    "    # features, e.g. Queen Elizabeth, Elizabeth II, Her Majesty -> KB2912\n",
    "    # see https://spacy.io/usage/training#entity-linker\n",
    "    # entities = ['ENT_'+token.ent_kb_id_ for token in doc if token.ent_kb_id_]\n",
    "\n",
    "    # we use a simple nltk function to create ngrams\n",
    "    lemma_bigrams = ['BI_'+p1+'_'+p2 for p1,p2 in nltk.ngrams(lemmas,2)]\n",
    "    lemma_trigrams = ['TRI_'+p1+'_'+p2+'_'+p3 for p1,p2,p3 in nltk.ngrams(lemmas,3)]\n",
    "\n",
    "    all_tokens = list()\n",
    "    all_tokens.extend(lemmas)\n",
    "    all_tokens.extend(lemma_bigrams)\n",
    "    all_tokens.extend(lemma_trigrams)\n",
    "    all_tokens.extend(entity_types)\n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vect = CountVectorizer(analyzer=spacy_nlp_tokenizer, min_df=5)  \n",
    "#reset_counter()\n",
    "#X_train_tok = vect.fit_transform(x_train.Racconto_Text_Only)\n",
    "#reset_counter()\n",
    "#X_test_tok = vect.transform(x_test.Racconto_Text_Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(path+r'\\Rating\\x_train_tok.pkl','wb') as outfile:\n",
    "#    pickle.dump(X_train_tok,outfile)\n",
    "#with open(path+r'\\Rating\\x_test_tok.pkl','wb') as outfile:\n",
    "#    pickle.dump(X_test_tok,outfile)\n",
    "#with open(path+r'\\Rating\\vect.pkl','wb') as outfile:\n",
    "#    pickle.dump(vect,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(path+r\"\\Rating\\x_train_tok.pkl\", \"rb\")\n",
    "X_train_tok = pickle.load(a_file)\n",
    "\n",
    "b_file = open(path+r\"\\Rating\\x_test_tok.pkl\", \"rb\")\n",
    "X_test_tok = pickle.load(b_file)\n",
    "\n",
    "c_file = open(path+r\"\\Rating\\vect.pkl\", \"rb\")\n",
    "vect = pickle.load(c_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lunghezza del vocabolario: 913760\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lunghezza del vocabolario: {len(vect.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect.inverse_transform(X_train_tok[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2, k=5000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LinearSVC())  # learning algorithm\n",
    "])\n",
    "\n",
    "reset_counter()\n",
    "rating_pipeline.fit(X_train_tok,y_train.values.ravel())\n",
    "\n",
    "reset_counter()\n",
    "rating_predictions = rating_pipeline.predict(X_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       rosso       0.72      0.46      0.56      3477\n",
      "       verde       0.79      0.92      0.85      7831\n",
      "\n",
      "    accuracy                           0.78     11308\n",
      "   macro avg       0.76      0.69      0.71     11308\n",
      "weighted avg       0.77      0.78      0.76     11308\n",
      "\n",
      "Confusion matrix:\n",
      "[[1615 1862]\n",
      " [ 632 7199]]\n"
     ]
    }
   ],
   "source": [
    "print('Classification report:')\n",
    "print(classification_report(y_test, rating_predictions))\n",
    "print('Confusion matrix:')\n",
    "rating_cm = confusion_matrix(y_test, rating_predictions)\n",
    "print(rating_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "search_space = [{'sel__k': [10000, 100000, 250000, 500000, 'all'],\n",
    "                 'learner':[MultinomialNB()],\n",
    "                 'learner__alpha': [1e-3, 1e-2, 0.1, 1.0, 10.0],\n",
    "                 'learner__fit_prior':[True, False]}, \n",
    "                {'sel__k': [10000, 100000, 250000, 500000, 'all'],\n",
    "                 'learner':[LinearSVC()],\n",
    "                 'learner__C': [0.01, 0.1, 1, 10, 100]},\n",
    "                {'sel__k': [10000, 100000, 250000, 500000, 'all'], \n",
    "                 'learner':[LogisticRegression()],\n",
    "                 'learner__solver':[\"liblinear\"],\n",
    "                 'learner__penalty' : ['l1', 'l2'],\n",
    "                 'learner__C': [0.01, 0.1, 1, 10, 100]} \n",
    "               ]\n",
    "\n",
    "rating_opt_pipeline = Pipeline([\n",
    "#    ('vect', CountVectorizer()),  # feature extraction\n",
    "    ('sel', SelectKBest(chi2)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LinearSVC())  # learning algorithm\n",
    "])\n",
    "\n",
    "scoring = make_scorer(f1_score, greater_is_better=True, pos_label='rosso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 125 candidates, totalling 375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiar\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "rating_opt_search = GridSearchCV(rating_opt_pipeline, \n",
    "                                 search_space,\n",
    "                                 scoring = scoring,\n",
    "                                 cv=3, n_jobs = -1, verbose=True).fit(X_train_tok,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       " 'learner__alpha': 0.01,\n",
       " 'learner__fit_prior': False,\n",
       " 'sel__k': 250000}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_opt_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 10.00858347,  13.78289922,  15.39444447,  17.66776864,\n",
       "         29.20883799,  11.12733928,  15.45294499,  14.49225752,\n",
       "         17.50299398,  22.09736443,   9.90248728,  10.74764347,\n",
       "         12.06622831,  16.55121994,  21.92073139,   9.61044788,\n",
       "         10.72063669,  11.88081956,  14.80273851,  20.81448968,\n",
       "          8.70260326,   8.92703279,  10.83496102,  13.68880916,\n",
       "         19.72724732,   7.60755181,   8.7772944 ,  10.45825092,\n",
       "         15.32106694,  22.24480216,   7.54649067,   8.80388745,\n",
       "         10.34566021,  16.37268996,  23.01634685,   8.48693117,\n",
       "          9.09402363,  10.73245494,  15.81460182,  20.29464293,\n",
       "          7.22911453,   8.57145747,   9.7401921 ,  13.98356303,\n",
       "         18.84450277,   7.50490141,   7.82597558,   9.8975242 ,\n",
       "         13.71425811,  20.03053236,   8.74388353,  10.69234697,\n",
       "         11.3403302 ,  19.17591015,  27.51566172,   9.25406218,\n",
       "         11.48793316,  14.30746802,  22.37292878,  28.93068608,\n",
       "         12.86830886,  14.16115546,  23.80266587,  38.61937396,\n",
       "         52.39139303,  37.20050828,  64.70537527, 136.26012039,\n",
       "        209.08540281, 288.31647992,  92.81302174, 196.89590589,\n",
       "        368.78860188, 583.87377119, 808.83007622,  12.05855274,\n",
       "         18.77253707,  25.35929998,  46.76310023,  68.00585651,\n",
       "         12.84064221,  17.06251701,  27.52872419,  38.92574946,\n",
       "         53.76351142,  13.27434444,  17.85152793,  25.83435726,\n",
       "         38.09385141,  54.12260532,  12.70411857,  20.13283976,\n",
       "         33.07558346,  44.08847157,  62.67355967,  18.1345787 ,\n",
       "         20.29621545,  23.2871472 ,  30.75648499,  38.07819327,\n",
       "         14.42692455,  18.37338861,  42.67531236,  69.75347185,\n",
       "         83.82335265,  53.90638121,  33.37318023,  30.90921172,\n",
       "         33.86713012,  41.0997142 ,  14.04996411,  30.29774761,\n",
       "         65.78769978, 126.22150858, 144.79243326, 128.27669406,\n",
       "         38.49630157,  29.35559058,  38.92935236,  44.62464778,\n",
       "         26.92933043,  48.89354285, 125.53052727, 176.84433325,\n",
       "        157.51470351]),\n",
       " 'std_fit_time': array([6.15707078e-01, 5.94159727e-01, 8.87480396e-01, 1.10705157e+00,\n",
       "        1.08393966e+00, 1.54300584e+00, 7.55848059e-01, 1.12500480e-01,\n",
       "        7.51780387e-01, 3.38227952e-01, 9.71601571e-01, 7.53860892e-01,\n",
       "        4.25499293e-01, 1.90865162e+00, 8.94747154e-01, 2.95786370e-01,\n",
       "        4.27659364e-01, 5.28644552e-01, 9.11322815e-01, 9.72001350e-01,\n",
       "        5.67224271e-01, 7.41919714e-01, 1.29414616e+00, 4.73772060e-01,\n",
       "        5.64262485e-01, 5.40899241e-01, 4.23373521e-01, 1.97250870e-01,\n",
       "        6.39269433e-01, 8.42989371e-01, 3.35722722e-01, 1.22455996e-01,\n",
       "        4.92612962e-01, 3.51813787e-01, 6.60906268e-01, 7.70241565e-01,\n",
       "        5.87917695e-01, 1.24704875e+00, 1.01544920e+00, 1.23667533e+00,\n",
       "        4.37350866e-01, 3.53568780e-01, 5.72940729e-01, 1.59468112e+00,\n",
       "        8.00576200e-01, 2.46242000e-02, 1.14042386e-01, 4.12348774e-01,\n",
       "        4.24924758e-01, 5.87780540e-01, 3.49278527e-01, 4.52712766e-01,\n",
       "        7.32423142e-01, 1.08853909e+00, 7.19548792e-01, 1.51164342e-01,\n",
       "        1.17217746e-01, 4.56272873e-01, 2.60937523e-01, 6.03693377e-01,\n",
       "        1.71873547e+00, 4.14532074e-01, 1.71418404e+00, 2.16681254e+00,\n",
       "        3.29395641e+00, 3.60157639e+00, 5.10192636e+00, 7.85006685e+00,\n",
       "        6.53852073e+00, 1.44606622e+01, 5.84789851e+00, 7.28956722e+00,\n",
       "        1.66173982e+01, 1.73127637e+01, 2.15941016e+01, 1.44624742e-01,\n",
       "        8.10010694e-01, 5.70900157e-01, 4.97471019e-01, 1.38287926e+00,\n",
       "        1.08124830e+00, 1.08174854e-01, 6.41427541e-01, 8.58196289e-01,\n",
       "        8.14570512e-01, 3.38363867e-01, 8.47754894e-01, 1.65787941e+00,\n",
       "        1.10511921e+00, 6.57800001e-01, 4.93814365e-01, 1.62197078e-01,\n",
       "        8.37181515e-01, 2.66846015e+00, 7.63344572e-01, 2.17489527e-01,\n",
       "        6.09334436e-01, 1.90061584e+00, 3.36634356e-01, 7.56314943e-01,\n",
       "        1.96814699e+00, 8.24638494e-01, 3.03859228e+00, 2.48657758e+00,\n",
       "        4.93209760e+00, 6.10026404e+00, 3.47909632e+00, 9.74895343e-01,\n",
       "        2.50283629e-01, 2.19170562e+00, 3.30775898e-01, 1.34955498e+00,\n",
       "        8.16437003e+00, 5.24731917e+00, 6.59680908e+00, 2.96016578e+01,\n",
       "        7.87702085e+00, 1.23112273e+00, 1.08781506e+00, 1.33296727e+00,\n",
       "        8.41421704e+00, 6.97426485e+00, 1.77349469e+01, 4.15432014e+00,\n",
       "        2.68143475e+01]),\n",
       " 'mean_score_time': array([1.57067402, 2.81225189, 4.65641451, 9.05559945, 7.63912416,\n",
       "        2.89703107, 3.11104655, 4.01775821, 7.87561576, 6.4918642 ,\n",
       "        1.91407307, 2.32226022, 3.9067959 , 6.56000431, 5.90204922,\n",
       "        1.96373836, 2.62259396, 3.66112884, 5.85713283, 6.43106882,\n",
       "        1.89264043, 2.03874373, 3.52311095, 6.63639148, 6.47006305,\n",
       "        1.56605275, 2.51213233, 4.11319327, 6.61842442, 6.37424684,\n",
       "        1.7844615 , 2.47504203, 4.20224047, 7.08261832, 6.61424963,\n",
       "        1.69188428, 2.71128734, 3.50254504, 5.87955324, 6.29951898,\n",
       "        1.43883808, 1.70675929, 3.74249903, 5.76881822, 5.68262132,\n",
       "        1.31581521, 2.15065575, 2.78961595, 6.33992998, 6.08589323,\n",
       "        1.55445313, 1.99598908, 3.68015019, 5.81704497, 5.79250002,\n",
       "        1.40087295, 2.18321546, 4.19868032, 6.28751397, 5.42620524,\n",
       "        1.24395458, 2.07725477, 5.25017023, 6.56715107, 5.2555728 ,\n",
       "        1.30604839, 3.16306996, 6.60100635, 7.8511169 , 7.40684803,\n",
       "        2.16069333, 2.95366971, 6.60523248, 8.1039385 , 7.83949788,\n",
       "        2.28952297, 4.37579441, 6.60507377, 8.86402845, 9.64296476,\n",
       "        1.9374481 , 3.54110297, 5.58246891, 8.71817676, 9.17182167,\n",
       "        1.87079334, 2.67932288, 5.0386591 , 7.00347042, 8.55341355,\n",
       "        1.7691853 , 3.28451769, 4.74358304, 6.85321577, 6.69614546,\n",
       "        1.70611699, 2.9834168 , 3.97637566, 4.63142904, 5.51737158,\n",
       "        1.23535577, 2.29908458, 5.49350007, 6.10865402, 4.94331328,\n",
       "        1.04834183, 1.76284051, 2.78385131, 3.4999404 , 5.70976011,\n",
       "        1.08666142, 2.78998391, 5.99667271, 5.92524155, 4.41161005,\n",
       "        1.07500537, 1.48262986, 2.20474521, 3.3035961 , 5.06062659,\n",
       "        1.02867564, 3.16500545, 5.45349662, 4.90388838, 2.74117963]),\n",
       " 'std_score_time': array([0.22545779, 0.15352636, 0.19834075, 1.25061448, 0.12118177,\n",
       "        0.63834515, 0.30850031, 0.49570786, 0.11752653, 0.47083115,\n",
       "        0.18017573, 0.05328485, 0.3138432 , 0.15505216, 0.32070658,\n",
       "        0.18517119, 0.03971411, 0.18327446, 0.3853744 , 0.61433551,\n",
       "        0.09971056, 0.13894066, 0.43837403, 0.47139283, 0.26444292,\n",
       "        0.1811096 , 0.06126578, 0.53936176, 0.25735794, 0.57540028,\n",
       "        0.15236278, 0.17120822, 0.9630978 , 0.19557498, 0.51629713,\n",
       "        0.22831823, 0.41025726, 0.56409268, 0.4603413 , 0.2639324 ,\n",
       "        0.25289749, 0.26338109, 0.21113044, 0.08147032, 0.29372608,\n",
       "        0.3402524 , 0.05448778, 0.10092089, 0.44258809, 0.17403282,\n",
       "        0.41935473, 0.15329069, 0.80666508, 0.19457288, 0.03423629,\n",
       "        0.38616587, 0.06078535, 0.76690472, 0.18396393, 0.91201162,\n",
       "        0.26686591, 0.20971497, 0.2151321 , 0.40729377, 0.91259703,\n",
       "        0.09859554, 0.45881951, 0.43656065, 0.07778711, 0.49682204,\n",
       "        0.30600397, 0.09859723, 0.1905213 , 0.37074609, 2.14487319,\n",
       "        0.07769187, 0.20421676, 0.32056729, 0.20888504, 0.36125246,\n",
       "        0.18770799, 0.28088852, 0.49085649, 0.01856144, 0.86672534,\n",
       "        0.07666352, 0.11889796, 0.27349085, 0.38218156, 0.24475429,\n",
       "        0.13880647, 0.3165889 , 0.51121829, 0.55244952, 0.49955345,\n",
       "        0.13771155, 0.18943064, 0.1963575 , 0.19158946, 0.94656783,\n",
       "        0.10286038, 0.65685254, 0.25641025, 0.59084418, 0.54193484,\n",
       "        0.18702081, 0.36826006, 0.10878371, 0.13043802, 0.89782728,\n",
       "        0.22957432, 0.15349134, 0.60204347, 0.07409049, 0.61371458,\n",
       "        0.15055465, 0.08040858, 0.15619427, 0.6239107 , 0.88477651,\n",
       "        0.22887301, 0.24460362, 0.20213845, 0.83012354, 0.53117337]),\n",
       " 'param_learner': masked_array(data=[MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "                    LinearSVC(), LinearSVC(), LinearSVC(), LinearSVC(),\n",
       "                    LinearSVC(), LinearSVC(), LinearSVC(), LinearSVC(),\n",
       "                    LinearSVC(), LinearSVC(), LinearSVC(), LinearSVC(),\n",
       "                    LinearSVC(), LinearSVC(), LinearSVC(), LinearSVC(),\n",
       "                    LinearSVC(), LinearSVC(), LinearSVC(), LinearSVC(),\n",
       "                    LinearSVC(), LinearSVC(), LinearSVC(), LinearSVC(),\n",
       "                    LinearSVC(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression(), LogisticRegression(),\n",
       "                    LogisticRegression()],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__alpha': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0,\n",
       "                    10.0, 10.0, 10.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__fit_prior': masked_array(data=[True, True, True, True, True, False, False, False,\n",
       "                    False, False, True, True, True, True, True, False,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    True, False, False, False, False, False, True, True,\n",
       "                    True, True, True, False, False, False, False, False,\n",
       "                    True, True, True, True, True, False, False, False,\n",
       "                    False, False, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_sel__k': masked_array(data=[10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all', 10000,\n",
       "                    100000, 250000, 500000, 'all', 10000, 100000, 250000,\n",
       "                    500000, 'all', 10000, 100000, 250000, 500000, 'all',\n",
       "                    10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all', 10000,\n",
       "                    100000, 250000, 500000, 'all', 10000, 100000, 250000,\n",
       "                    500000, 'all', 10000, 100000, 250000, 500000, 'all',\n",
       "                    10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all', 10000,\n",
       "                    100000, 250000, 500000, 'all', 10000, 100000, 250000,\n",
       "                    500000, 'all', 10000, 100000, 250000, 500000, 'all',\n",
       "                    10000, 100000, 250000, 500000, 'all', 10000, 100000,\n",
       "                    250000, 500000, 'all', 10000, 100000, 250000, 500000,\n",
       "                    'all', 10000, 100000, 250000, 500000, 'all'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__C': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 10, 10,\n",
       "                    10, 10, 10, 100, 100, 100, 100, 100, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__penalty': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'l1', 'l1', 'l1', 'l1', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learner__solver': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'liblinear', 'liblinear', 'liblinear'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.001,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.01,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 0.1,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 1.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': True,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 10000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 100000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 250000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 500000},\n",
       "  {'learner': MultinomialNB(alpha=0.01, fit_prior=False),\n",
       "   'learner__alpha': 10.0,\n",
       "   'learner__fit_prior': False,\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.01, 'sel__k': 10000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.01, 'sel__k': 100000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.01, 'sel__k': 250000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.01, 'sel__k': 500000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.01, 'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.1, 'sel__k': 10000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.1, 'sel__k': 100000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.1, 'sel__k': 250000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.1, 'sel__k': 500000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 0.1, 'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(), 'learner__C': 1, 'sel__k': 10000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 1, 'sel__k': 100000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 1, 'sel__k': 250000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 1, 'sel__k': 500000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 1, 'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(), 'learner__C': 10, 'sel__k': 10000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 10, 'sel__k': 100000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 10, 'sel__k': 250000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 10, 'sel__k': 500000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 10, 'sel__k': 'all'},\n",
       "  {'learner': LinearSVC(), 'learner__C': 100, 'sel__k': 10000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 100, 'sel__k': 100000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 100, 'sel__k': 250000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 100, 'sel__k': 500000},\n",
       "  {'learner': LinearSVC(), 'learner__C': 100, 'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.01,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 0.1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 1,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 10,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l1',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 10000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 100000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 250000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 500000},\n",
       "  {'learner': LogisticRegression(),\n",
       "   'learner__C': 100,\n",
       "   'learner__penalty': 'l2',\n",
       "   'learner__solver': 'liblinear',\n",
       "   'sel__k': 'all'}],\n",
       " 'split0_test_score': array([0.42429106, 0.55951417, 0.57911236, 0.5325646 , 0.51327036,\n",
       "        0.56714782, 0.58597532, 0.57442799, 0.56569746, 0.55449032,\n",
       "        0.41915523, 0.5266486 , 0.55874567, 0.5485035 , 0.55120101,\n",
       "        0.56576775, 0.57983786, 0.58369653, 0.57873533, 0.58027079,\n",
       "        0.39966924, 0.37796175, 0.32659221, 0.32943995, 0.34610849,\n",
       "        0.55735849, 0.50324675, 0.43991641, 0.44598765, 0.46176987,\n",
       "        0.3007657 , 0.03843365, 0.0036914 , 0.        , 0.        ,\n",
       "        0.49172794, 0.08218208, 0.01395007, 0.00442641, 0.00442641,\n",
       "        0.01322557, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.06361687, 0.00147765, 0.00147765, 0.00147765, 0.00147765,\n",
       "        0.17336011, 0.14582624, 0.1383088 , 0.17903494, 0.25583567,\n",
       "        0.45219229, 0.44348762, 0.44107288, 0.44731183, 0.45608548,\n",
       "        0.5395411 , 0.53644048, 0.53940374, 0.53909368, 0.54413825,\n",
       "        0.53121409, 0.54313887, 0.55175292, 0.55673682, 0.56719669,\n",
       "        0.50474517, 0.53926392, 0.55031383, 0.55445545, 0.56888512,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.19026265, 0.16081392, 0.15633245, 0.19872204, 0.28879813,\n",
       "        0.21028646, 0.18663137, 0.17690254, 0.22308188, 0.28389831,\n",
       "        0.49777338, 0.49088639, 0.48895582, 0.48935637, 0.49840881,\n",
       "        0.47264321, 0.46512847, 0.46340819, 0.46802935, 0.47522236,\n",
       "        0.53905478, 0.55177961, 0.56067619, 0.56413424, 0.56904115,\n",
       "        0.54083885, 0.54005935, 0.54376596, 0.53907721, 0.5380117 ,\n",
       "        0.51859649, 0.54500663, 0.54909438, 0.55379869, 0.5585337 ,\n",
       "        0.53511317, 0.55001062, 0.55210158, 0.55422773, 0.55537939]),\n",
       " 'split1_test_score': array([0.42830138, 0.56661316, 0.58473869, 0.53837838, 0.52213601,\n",
       "        0.56634897, 0.58222771, 0.57135098, 0.56592593, 0.55419304,\n",
       "        0.42193864, 0.52490775, 0.56511868, 0.54984894, 0.55187166,\n",
       "        0.56600994, 0.57999303, 0.58531073, 0.58273   , 0.58399576,\n",
       "        0.40949227, 0.38073525, 0.32670283, 0.34266985, 0.35577771,\n",
       "        0.56143667, 0.50271162, 0.4432828 , 0.44857881, 0.4600558 ,\n",
       "        0.29741379, 0.03701016, 0.00221648, 0.        , 0.        ,\n",
       "        0.4961885 , 0.07659574, 0.01101726, 0.00589102, 0.00442478,\n",
       "        0.01030169, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0594343 , 0.00221484, 0.00221484, 0.00221484, 0.00221484,\n",
       "        0.18218218, 0.15421196, 0.14231953, 0.17993311, 0.24937028,\n",
       "        0.44945025, 0.43624525, 0.42946794, 0.44174757, 0.44929059,\n",
       "        0.54141876, 0.54242003, 0.54634146, 0.55243931, 0.5575304 ,\n",
       "        0.53685239, 0.54241486, 0.55629971, 0.56820156, 0.57092589,\n",
       "        0.51557771, 0.52757316, 0.54684976, 0.55658784, 0.56726024,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.19536949, 0.17365854, 0.16830386, 0.2112587 , 0.28394698,\n",
       "        0.22481374, 0.18839138, 0.18272758, 0.21796951, 0.28266829,\n",
       "        0.48458599, 0.4780036 , 0.47973147, 0.48784233, 0.4951091 ,\n",
       "        0.47077244, 0.45906818, 0.44988035, 0.46008403, 0.46702592,\n",
       "        0.53850843, 0.55021477, 0.55422664, 0.56133829, 0.56686291,\n",
       "        0.54463277, 0.54953704, 0.55053563, 0.55162592, 0.54806786,\n",
       "        0.51704342, 0.52810707, 0.53996582, 0.5464756 , 0.55480807,\n",
       "        0.5462069 , 0.5504942 , 0.56493223, 0.57091481, 0.5659003 ]),\n",
       " 'split2_test_score': array([0.44580559, 0.56558176, 0.583878  , 0.5425032 , 0.52487058,\n",
       "        0.56221534, 0.57723208, 0.57477925, 0.5649078 , 0.56195122,\n",
       "        0.44164882, 0.53835861, 0.56094578, 0.55284897, 0.55663158,\n",
       "        0.56237406, 0.57625366, 0.58370895, 0.58015267, 0.58400279,\n",
       "        0.41906327, 0.39000852, 0.32973621, 0.3346211 , 0.34690265,\n",
       "        0.55787691, 0.5094208 , 0.44340844, 0.4495766 , 0.46010101,\n",
       "        0.30454684, 0.04693141, 0.0036914 , 0.00073937, 0.        ,\n",
       "        0.50636943, 0.08931083, 0.01536773, 0.00368189, 0.00221076,\n",
       "        0.01614087, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.06688011, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.19352708, 0.15972927, 0.1517523 , 0.17810512, 0.24340642,\n",
       "        0.47549531, 0.46104759, 0.45571659, 0.46285409, 0.46935017,\n",
       "        0.54771416, 0.55341347, 0.55563171, 0.56450862, 0.57156177,\n",
       "        0.54285714, 0.54796748, 0.55963868, 0.5734385 , 0.58405172,\n",
       "        0.52426509, 0.52639752, 0.55074744, 0.56796117, 0.5753537 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.22752635, 0.19309463, 0.19325843, 0.23185674, 0.29157989,\n",
       "        0.23264781, 0.20460526, 0.19129857, 0.21917808, 0.28342081,\n",
       "        0.50724994, 0.49763387, 0.49173761, 0.50609604, 0.51597052,\n",
       "        0.49467816, 0.48240166, 0.47526825, 0.48035621, 0.48627853,\n",
       "        0.54892695, 0.54915254, 0.55184815, 0.5632137 , 0.56705931,\n",
       "        0.55729052, 0.55673839, 0.5528791 , 0.56522754, 0.56721311,\n",
       "        0.52602166, 0.52255639, 0.53106923, 0.54644809, 0.55414258,\n",
       "        0.54493088, 0.55988213, 0.56316916, 0.57149191, 0.58087739]),\n",
       " 'mean_test_score': array([4.32799345e-01, 5.63903030e-01, 5.82576347e-01, 5.37815392e-01,\n",
       "        5.20092316e-01, 5.65237377e-01, 5.81811702e-01, 5.73519409e-01,\n",
       "        5.65510394e-01, 5.56878191e-01, 4.27580897e-01, 5.29971652e-01,\n",
       "        5.61603378e-01, 5.50400473e-01, 5.53234749e-01, 5.64717251e-01,\n",
       "        5.78694849e-01, 5.84238738e-01, 5.80539335e-01, 5.82756449e-01,\n",
       "        4.09408261e-01, 3.82901838e-01, 3.27677086e-01, 3.35576966e-01,\n",
       "        3.49596286e-01, 5.58890690e-01, 5.05126391e-01, 4.42202550e-01,\n",
       "        4.48047688e-01, 4.60642224e-01, 3.00908777e-01, 4.07917384e-02,\n",
       "        3.19975796e-03, 2.46457178e-04, 0.00000000e+00, 4.98095288e-01,\n",
       "        8.26962168e-02, 1.34450205e-02, 4.66643741e-03, 3.68731624e-03,\n",
       "        1.32227092e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.33104277e-02, 1.23082999e-03, 1.23082999e-03,\n",
       "        1.23082999e-03, 1.23082999e-03, 1.83023123e-01, 1.53255821e-01,\n",
       "        1.44126877e-01, 1.79024391e-01, 2.49537454e-01, 4.59045950e-01,\n",
       "        4.46926822e-01, 4.42085802e-01, 4.50637830e-01, 4.58242083e-01,\n",
       "        5.42891341e-01, 5.44091328e-01, 5.47125640e-01, 5.52013871e-01,\n",
       "        5.57743476e-01, 5.36974544e-01, 5.44507069e-01, 5.55897102e-01,\n",
       "        5.66125627e-01, 5.74058100e-01, 5.14862656e-01, 5.31078201e-01,\n",
       "        5.49303676e-01, 5.59668149e-01, 5.70499689e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.04386163e-01, 1.75855694e-01, 1.72631582e-01,\n",
       "        2.13945827e-01, 2.88108334e-01, 2.22582669e-01, 1.93209337e-01,\n",
       "        1.83642895e-01, 2.20076492e-01, 2.83329135e-01, 4.96536435e-01,\n",
       "        4.88841289e-01, 4.86808301e-01, 4.94431584e-01, 5.03162811e-01,\n",
       "        4.79364601e-01, 4.68866102e-01, 4.62852265e-01, 4.69489864e-01,\n",
       "        4.76175605e-01, 5.42163388e-01, 5.50382307e-01, 5.55583660e-01,\n",
       "        5.62895411e-01, 5.67654458e-01, 5.47587381e-01, 5.48778259e-01,\n",
       "        5.49060231e-01, 5.51976890e-01, 5.51097557e-01, 5.20553854e-01,\n",
       "        5.31890033e-01, 5.40043143e-01, 5.48907459e-01, 5.55828119e-01,\n",
       "        5.42083649e-01, 5.53462316e-01, 5.60067656e-01, 5.65544818e-01,\n",
       "        5.67385692e-01]),\n",
       " 'std_test_score': array([0.0093414 , 0.00313183, 0.00247448, 0.0040769 , 0.00495135,\n",
       "        0.00216165, 0.00358152, 0.00154   , 0.00043619, 0.00358923,\n",
       "        0.01001222, 0.00597291, 0.00264299, 0.00181639, 0.00241748,\n",
       "        0.00165983, 0.00172734, 0.00075803, 0.00165358, 0.00175763,\n",
       "        0.0079178 , 0.00515116, 0.00145672, 0.00544321, 0.00438294,\n",
       "        0.00181268, 0.00304445, 0.00161736, 0.00151255, 0.00079758,\n",
       "        0.00291381, 0.00438012, 0.00069529, 0.00034854, 0.        ,\n",
       "        0.00612754, 0.00520363, 0.00181162, 0.00091771, 0.00104408,\n",
       "        0.00238383, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00304745, 0.00092089, 0.00092089, 0.00092089, 0.00092089,\n",
       "        0.00825458, 0.00571602, 0.00563511, 0.00074631, 0.0050756 ,\n",
       "        0.0116852 , 0.01041346, 0.01073987, 0.00893189, 0.00833006,\n",
       "        0.00349534, 0.00702925, 0.0066482 , 0.01037996, 0.01119662,\n",
       "        0.00475404, 0.00246467, 0.00323191, 0.00697465, 0.0072287 ,\n",
       "        0.007985  , 0.00580805, 0.00174419, 0.00592831, 0.00349582,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01649487, 0.01326981, 0.01538243, 0.01365998, 0.00315406,\n",
       "        0.0092643 , 0.00809011, 0.00591269, 0.00218166, 0.00050632,\n",
       "        0.00929377, 0.00814345, 0.00513132, 0.00827115, 0.00915605,\n",
       "        0.01085522, 0.00988569, 0.01037202, 0.00834027, 0.0078887 ,\n",
       "        0.00478776, 0.00107902, 0.00372959, 0.00116342, 0.00098381,\n",
       "        0.00703381, 0.0068303 , 0.00386393, 0.01067871, 0.01211239,\n",
       "        0.00391796, 0.00954765, 0.00735894, 0.00345864, 0.00193233,\n",
       "        0.00495632, 0.00454379, 0.00567867, 0.00800585, 0.01046237]),\n",
       " 'rank_test_score': array([ 75,  17,   3,  47,  53,  15,   4,   8,  14,  24,  76,  51,  19,\n",
       "         33,  29,  16,   6,   1,   5,   2,  77,  78,  81,  80,  79,  22,\n",
       "         55,  73,  71,  67,  82, 100, 105, 110, 111,  57,  98, 101, 103,\n",
       "        104, 102, 111, 111, 111, 111,  99, 106, 106, 106, 106,  92,  96,\n",
       "         97,  93,  85,  68,  72,  74,  70,  69,  43,  42,  40,  30,  23,\n",
       "         48,  41,  25,  12,   7,  54,  50,  35,  21,   9, 111, 111, 111,\n",
       "        111, 111, 111, 111, 111, 111, 111,  89,  94,  95,  88,  83,  86,\n",
       "         90,  91,  87,  84,  58,  60,  61,  59,  56,  62,  65,  66,  64,\n",
       "         63,  44,  34,  27,  18,  10,  39,  38,  36,  31,  32,  52,  49,\n",
       "         46,  37,  26,  45,  28,  20,  13,  11])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_opt_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sel',\n",
       "                 SelectKBest(k=250000,\n",
       "                             score_func=<function chi2 at 0x0000015F4877DD30>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('learner', MultinomialNB(alpha=0.01, fit_prior=False))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_opt_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt_pipeline = Pipeline([\n",
    "#    ('vect', CountVectorizer()),  # feature extraction\n",
    "    ('sel', SelectKBest(chi2, k=250000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', MultinomialNB(alpha=0.01, fit_prior=False))  # learning algorithm\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating_opt_predictions = rating_opt_search.best_estimator_.predict(X_test_tok)\n",
    "\n",
    "reset_counter()\n",
    "model_opt_pipeline.fit(X_train_tok, y_train.values.ravel())\n",
    "\n",
    "reset_counter()\n",
    "rating_opt_predictions = model_opt_pipeline.predict(X_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       rosso       0.58      0.60      0.59      3477\n",
      "       verde       0.82      0.81      0.81      7831\n",
      "\n",
      "    accuracy                           0.75     11308\n",
      "   macro avg       0.70      0.71      0.70     11308\n",
      "weighted avg       0.75      0.75      0.75     11308\n",
      "\n",
      "Confusion matrix:\n",
      "[[2093 1384]\n",
      " [1496 6335]]\n"
     ]
    }
   ],
   "source": [
    "print('Classification report:')\n",
    "print(classification_report(y_test, rating_opt_predictions))\n",
    "print('Confusion matrix:')\n",
    "rating_opt_cm = confusion_matrix(y_test, rating_opt_predictions)\n",
    "print(rating_opt_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tokenizer = vect\n",
    "rating_selector = model_opt_pipeline.named_steps['sel']\n",
    "rating_classifier = model_opt_pipeline.named_steps['learner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = rating_classifier.feature_log_prob_[0]/rating_classifier.feature_log_prob_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_w_classifier_weight = list()\n",
    "feature_names = rating_tokenizer.get_feature_names()\n",
    "for index,weight in enumerate(rating_selector.inverse_transform([ratio])[0]):\n",
    "    if weight!=0:\n",
    "        feats_w_classifier_weight.append((weight,feature_names[index]))\n",
    "feats_w_classifier_weight = sorted(feats_w_classifier_weight)\n",
    "len(feats_w_classifier_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.3017309251150995, 'BI_LEMMA___LEMMA_Falsa'),\n",
       " (1.3017309251150995, 'BI_LEMMA_Pista_LEMMA__'),\n",
       " (1.3017309251150995, 'BI_LEMMA_Falsa_LEMMA_Pista'),\n",
       " (1.301483212809652, 'BI_LEMMA_lo_LEMMA_film'),\n",
       " (1.3010486307484186, 'BI_LEMMA_!_LEMMA_-.-'),\n",
       " (1.3010093850598314, 'BI_LEMMA_So_LEMMA_Harry'),\n",
       " (1.3010051307924173, 'LEMMA_Ninna'),\n",
       " (1.3010048205461264, 'BI_LEMMA_tanto_LEMMA_regalo'),\n",
       " (1.3006262567155729, 'BI_LEMMA_alberare_LEMMA_”'),\n",
       " (1.300449540878736, 'BI_LEMMA_»_LEMMA_Angolo'),\n",
       " (1.3001666748540273, 'TRI_LEMMA_invitare_LEMMA_Fleur_LEMMA_ballare'),\n",
       " (1.3001666748540273, 'BI_LEMMA_Fleur_LEMMA_ballare'),\n",
       " (1.300033346196739, 'LEMMA_Elsa'),\n",
       " (1.2999557323865987, 'BI_LEMMA_._LEMMA_Lanciata'),\n",
       " (1.2996652415874215, 'TRI_LEMMA_giudizio_LEMMA_personale_LEMMA_:'),\n",
       " (1.2996344995246103, 'TRI_LEMMA_IMPORTANTE_LEMMA_,_LEMMA_AMICO'),\n",
       " (1.2996344995246103, 'TRI_LEMMA_DAVVERO_LEMMA_IMPORTANTE_LEMMA_,'),\n",
       " (1.2996344995246103, 'TRI_LEMMA_,_LEMMA_AMICO_LEMMA_...'),\n",
       " (1.2996344995246103, 'BI_LEMMA_DAVVERO_LEMMA_IMPORTANTE'),\n",
       " (1.2996344995246103, 'BI_LEMMA_AMICO_LEMMA_...'),\n",
       " (1.2993043632091186, 'TRI_LEMMA_Finchè_LEMMA_morto_LEMMA_separare'),\n",
       " (1.2992571800496953, 'TRI_LEMMA_personale_LEMMA_:_LEMMA_3'),\n",
       " (1.298775709943967, \"BI_LEMMA_E'_LEMMA_pubblicare\"),\n",
       " (1.2986651978301316, 'LEMMA_George!-'),\n",
       " (1.2986614571813002, 'LEMMA_5\\\\5'),\n",
       " (1.2985605234633248, 'BI_LEMMA_of_LEMMA_Life'),\n",
       " (1.2984604124273744, 'TRI_LEMMA_Trovate_LEMMA_Fanfiction_LEMMA_\"'),\n",
       " (1.2984604124273744, 'TRI_LEMMA_Radiopotter_LEMMA_\"_LEMMA_:'),\n",
       " (1.2984604124273744, 'TRI_LEMMA_Fanfiction_LEMMA_\"_LEMMA_Radiopotter'),\n",
       " (1.2984604124273744, 'TRI_LEMMA_\"_LEMMA_Radiopotter_LEMMA_\"'),\n",
       " (1.2984604124273744,\n",
       "  'TRI_LEMMA_\"_LEMMA_:_LEMMA_http://www.radiopotter.com/forum/viewtopic.php'),\n",
       " (1.2984604124273744, 'BI_LEMMA_Radiopotter_LEMMA_\"'),\n",
       " (1.2984604124273744, 'BI_LEMMA_\"_LEMMA_Radiopotter'),\n",
       " (1.2983350335253556, 'BI_LEMMA_essere_LEMMA_©'),\n",
       " (1.2982957714489178, 'TRI_LEMMA_Fred_LEMMA_,_LEMMA_manco'),\n",
       " (1.2980385233419114, 'TRI_LEMMA_lacrima_LEMMA_,_LEMMA_dovere'),\n",
       " (1.29789598246854, 'TRI_LEMMA_Stile_LEMMA_–_LEMMA_formare'),\n",
       " (1.29789598246854, 'TRI_LEMMA_Grammatica_LEMMA_–_LEMMA_punteggiatura'),\n",
       " (1.29789598246854, 'BI_LEMMA_–_LEMMA_punteggiatura'),\n",
       " (1.2978210837386033, 'LEMMA_areon'),\n",
       " (1.2974091438045634, 'TRI_LEMMA_tocco_LEMMA_mangiare_LEMMA_u.u'),\n",
       " (1.2974091438045634, 'TRI_LEMMA_mangiare_LEMMA_u.u_LEMMA_)'),\n",
       " (1.2974091438045634, 'TRI_LEMMA_e_LEMMA_tocco_LEMMA_mangiare'),\n",
       " (1.2974091438045634, 'TRI_LEMMA_appartenere_LEMMA_(_LEMMA_escluso'),\n",
       " (1.2974091438045634, 'TRI_LEMMA_OC_LEMMA_,_LEMMA_ovviare'),\n",
       " (1.2974091438045634, 'BI_LEMMA_tocco_LEMMA_mangiare'),\n",
       " (1.2974091438045634, 'BI_LEMMA_mangiare_LEMMA_u.u'),\n",
       " (1.2971462134956226, 'BI_LEMMA_(_LEMMA_-1'),\n",
       " (1.2971328759062304, \"LEMMA_She'\"),\n",
       " (1.2971219579831716, 'BI_LEMMA_Grattastinchi_LEMMA_!'),\n",
       " (1.2968626668277634, 'TRI_LEMMA_andare_LEMMA_invitare_LEMMA_Fleur'),\n",
       " (1.2968626668277634, 'TRI_LEMMA_Fleur_LEMMA_ballare_LEMMA_!'),\n",
       " (1.2967356942626107, 'BI_LEMMA_I_LEMMA_kissed'),\n",
       " (1.296293678504515, 'TRI_LEMMA_coppia_LEMMA_Ron_LEMMA_/'),\n",
       " (1.2951519200874884, 'TRI_LEMMA_Fanfictions_LEMMA_Challengers_LEMMA_II'),\n",
       " (1.2951519200874884, 'LEMMA_Challengers'),\n",
       " (1.2951519200874884, 'BI_LEMMA_Fanfictions_LEMMA_Challengers'),\n",
       " (1.2951519200874884, 'BI_LEMMA_Challengers_LEMMA_II'),\n",
       " (1.2949130473618464, 'BI_LEMMA_Parola_LEMMA_:'),\n",
       " (1.2948561133158711, 'TRI_LEMMA_..._LEMMA_potere_LEMMA_dimenticare'),\n",
       " (1.2948443610993432, 'TRI_LEMMA_vecchio_LEMMA_,_LEMMA_essere'),\n",
       " (1.294607829445828, 'BI_LEMMA_Silvia_LEMMA_.'),\n",
       " (1.294033772321321, 'LEMMA_Ombrosa'),\n",
       " (1.294033772321321, 'BI_LEMMA_,_LEMMA_Ombrosa'),\n",
       " (1.2939631928790043, 'LEMMA_HG'),\n",
       " (1.2939149213920478, 'TRI_LEMMA_vento_LEMMA_,_LEMMA_essere'),\n",
       " (1.293624915310413, 'TRI_LEMMA_._LEMMA_-_LEMMA_NdA'),\n",
       " (1.293272842311039, 'TRI_LEMMA_Rispetto_LEMMA_regola_LEMMA_contest'),\n",
       " (1.2931798828924792, 'TRI_LEMMA_Welcome_LEMMA_To_LEMMA_PageBreeze'),\n",
       " (1.2931798828924792, 'BI_LEMMA_Welcome_LEMMA_To'),\n",
       " (1.2931249093153907, 'BI_LEMMA_Flashfic_LEMMA_('),\n",
       " (1.2927544103780864, \"BI_LEMMA_She'_LEMMA_ll\"),\n",
       " (1.2922683859612816, 'TRI_LEMMA_e_LEMMA_l_LEMMA__'),\n",
       " (1.2922683859612816, 'BI_LEMMA_l_LEMMA__'),\n",
       " (1.2922135288951335, 'TRI_LEMMA_[_LEMMA_109_LEMMA_parola'),\n",
       " (1.2921232920803913, 'BI_LEMMA_Utilizzo_LEMMA_:'),\n",
       " (1.291661137083319, 'BI_LEMMA___LEMMA_M'),\n",
       " (1.2913102060700674, 'TRI_LEMMA_Spero_LEMMA_piacere_LEMMA_;'),\n",
       " (1.2912189006340251, 'TRI_LEMMA_..._LEMMA_James_LEMMA_:'),\n",
       " (1.2911398335885886, 'TRI_LEMMA_._LEMMA_IC_LEMMA_:'),\n",
       " (1.2909685292303619, 'LEMMA_kia85'),\n",
       " (1.290714177561078, 'BI_LEMMA_visitare_LEMMA_!'),\n",
       " (1.2905923953034626, 'TRI_LEMMA_?_LEMMA_Sirius_LEMMA_:'),\n",
       " (1.290487604794719, 'BI_LEMMA_Complimenti_LEMMA_e'),\n",
       " (1.2904801102595793, 'BI_LEMMA_Angie_LEMMA_,'),\n",
       " (1.2899264291285963, 'TRI_LEMMA___LEMMA_M_LEMMA_e'),\n",
       " (1.2899264291285963, 'TRI_LEMMA_M_LEMMA_e_LEMMA_l'),\n",
       " (1.289394240497416, 'BI_LEMMA_,_LEMMA_always'),\n",
       " (1.2892568868694807, 'TRI_LEMMA_,_LEMMA_o_LEMMA_persona'),\n",
       " (1.2892086623787178, 'LEMMA_Addobba'),\n",
       " (1.2891953283983362, 'TRI_LEMMA_Potter_LEMMA_Prompt_LEMMA_:'),\n",
       " (1.2891953283983362, 'BI_LEMMA_Potter_LEMMA_Prompt'),\n",
       " (1.2889229479528326, 'LEMMA_Ettore'),\n",
       " (1.2888530545524337, 'BI_LEMMA_._LEMMA_Mug'),\n",
       " (1.288831491377196, 'LEMMA_Yaya'),\n",
       " (1.288709220423138, 'BI_LEMMA_solitudine_LEMMA_portare'),\n",
       " (1.2885327224668455, 'TRI_LEMMA_My_LEMMA_Space_LEMMA_.'),\n",
       " (1.2885250578040839, 'BI_LEMMA_..._LEMMA_-Herm'),\n",
       " (1.2883748725763662, 'LEMMA_bu'),\n",
       " (1.288358397829731, 'BI_LEMMA_23_LEMMA_e'),\n",
       " (1.2882449879001416, 'BI_LEMMA_AUTRICE_LEMMA_...'),\n",
       " (1.2879177180982229, 'BI_LEMMA_caratterialmente_LEMMA_.'),\n",
       " (1.2876016801052235, 'TRI_LEMMA_Ok_LEMMA_,_LEMMA_parlare'),\n",
       " (1.2875473257792638, 'TRI_LEMMA_pranzare_LEMMA_o_LEMMA_cenare'),\n",
       " (1.287488651146049, 'TRI_LEMMA_-_LEMMA_tum_LEMMA_.'),\n",
       " (1.287436095671179, 'BI_LEMMA_freddo_LEMMA_lapide'),\n",
       " (1.2874285707590907, 'BI_LEMMA_rumore_LEMMA_risata'),\n",
       " (1.2874174306712616, 'TRI_LEMMA_,_LEMMA_Hannah_LEMMA_.'),\n",
       " (1.2873703762118118, 'TRI_LEMMA_obbligatorio_LEMMA_:_LEMMA_3/3'),\n",
       " (1.287358654166119, 'TRI_LEMMA_,_LEMMA_._LEMMA_Spazio'),\n",
       " (1.287240956146289, 'TRI_LEMMA_essere_LEMMA_acceso_LEMMA_lampadina'),\n",
       " (1.2872315939649905, 'LEMMA_Prayer'),\n",
       " (1.28721364508318, 'BI_LEMMA_bellissima_LEMMA_famiglia'),\n",
       " (1.287071028513021, 'TRI_LEMMA_usare_LEMMA_secondo_LEMMA_persona'),\n",
       " (1.2870635392923038, 'TRI_LEMMA_:_LEMMA_3/3_LEMMA_Utilizzo'),\n",
       " (1.2870635392923038, 'BI_LEMMA_3/3_LEMMA_Utilizzo'),\n",
       " (1.2869032731812993, \"TRI_LEMMA_E'_LEMMA_andare_LEMMA_invitare\"),\n",
       " (1.2865552900874373, 'BI_LEMMA_9.5/10_LEMMA_Gradimento'),\n",
       " (1.2864339617577565, 'BI_LEMMA_»_LEMMA_Victoire'),\n",
       " (1.2863303262705739, 'TRI_LEMMA_._LEMMA_Arriva_LEMMA_,'),\n",
       " (1.286231439936087, 'TRI_LEMMA_109_LEMMA_parola_LEMMA_]'),\n",
       " (1.2860730596704455, 'BI_LEMMA_!_LEMMA_LOL'),\n",
       " (1.2859261679019056, 'TRI_LEMMA_are_LEMMA_the_LEMMA_only'),\n",
       " (1.2853656430032276, 'TRI_LEMMA_Caro_LEMMA_papà_LEMMA_,'),\n",
       " (1.2853539486676149, 'TRI_LEMMA_sposare_LEMMA_,_LEMMA_sposare'),\n",
       " (1.285335321058373, 'TRI_LEMMA_ragazzo_LEMMA_goffo_LEMMA_e'),\n",
       " (1.2853128276356671, 'BI_LEMMA_P_LEMMA_:'),\n",
       " (1.2848445901353718, 'BI_LEMMA_citazione_LEMMA_usato'),\n",
       " (1.2848172513423444, 'TRI_LEMMA_Hermione_LEMMA_Prompt_LEMMA_:'),\n",
       " (1.2846154953560358, 'BI_LEMMA_recensioncina_LEMMA_piccino'),\n",
       " (1.2845357906269994, 'TRI_LEMMA_l’_LEMMA_alberare_LEMMA_”'),\n",
       " (1.2842150116542117, 'LEMMA_e_e'),\n",
       " (1.284176631986966, 'TRI_LEMMA_fioccare_LEMMA_neve_LEMMA_.'),\n",
       " (1.2840170743590162, 'BI_LEMMA_giudizio_LEMMA_GiudiciA'),\n",
       " (1.2837339443029907, 'TRI_LEMMA_pario_LEMMA_meritare_LEMMA_:'),\n",
       " (1.2835353107598044, 'TRI_LEMMA_Sev_LEMMA_e_LEMMA_Lily'),\n",
       " (1.283290343890803, 'TRI_LEMMA_._LEMMA_P_LEMMA_:'),\n",
       " (1.2824334853622987, 'LEMMA_Birthday-A'),\n",
       " (1.2823974419373758, 'TRI_LEMMA_capire_LEMMA_lo_LEMMA_amore'),\n",
       " (1.28238171629193, 'BI_LEMMA_regola_LEMMA_contest'),\n",
       " (1.282367856828537, 'BI_LEMMA_......_LEMMA_......'),\n",
       " (1.282334960329517, 'BI_LEMMA_(_LEMMA_beato'),\n",
       " (1.2821680956719688, 'BI_LEMMA_you_LEMMA_enjoy'),\n",
       " (1.281906766002277, 'BI_LEMMA_*_LEMMA_Giudizio'),\n",
       " (1.2817593313710656, 'BI_LEMMA_Manchi_LEMMA_.'),\n",
       " (1.281311496588485, 'BI_LEMMA_._LEMMA_Kathleen'),\n",
       " (1.2811275015716141, 'LEMMA_Matata'),\n",
       " (1.280952767486828, 'TRI_LEMMA_._LEMMA_Ciao_LEMMA_ragazzo'),\n",
       " (1.2809393085979779, 'TRI_LEMMA_,_LEMMA_5_LEMMA_)'),\n",
       " (1.280917791866094, 'BI_LEMMA_ormai_LEMMA_occhio'),\n",
       " (1.2805782983089335, 'TRI_LEMMA_Serpeverde_LEMMA_,_LEMMA_Serpeverde'),\n",
       " (1.2805654068782235, 'LEMMA_Alisya'),\n",
       " (1.280552672667903, 'TRI_LEMMA_:_LEMMA_\"_LEMMA_Ciao'),\n",
       " (1.2805133871454009, 'LEMMA_Eireen'),\n",
       " (1.2805061243815774, 'TRI_LEMMA_Totale_LEMMA_:_LEMMA_41'),\n",
       " (1.2803884964827619, 'LEMMA_Hakuna'),\n",
       " (1.2802980247467077, 'LEMMA_complimenti^^'),\n",
       " (1.2802538083974435, 'TRI_LEMMA_:_LEMMA_9.5/10_LEMMA_Gradimento'),\n",
       " (1.2801337017545198, 'BI_LEMMA_Fan_LEMMA_Club'),\n",
       " (1.2799531166270197, 'BI_LEMMA_Fabrizio_LEMMA_Moro'),\n",
       " (1.2799415339123625, 'TRI_LEMMA_I_LEMMA_Tiri_LEMMA_Vispi'),\n",
       " (1.2797432535635682, 'TRI_LEMMA_essere_LEMMA_colpa_LEMMA_morto'),\n",
       " (1.2795753555882055, 'BI_LEMMA_Herm_LEMMA_:'),\n",
       " (1.279455424875218, 'BI_LEMMA_’s_LEMMA_space'),\n",
       " (1.2794265128836535, 'TRI_LEMMA_._LEMMA_Fratello_LEMMA_,'),\n",
       " (1.2793955921632483, 'BI_LEMMA_James_LEMMA_*'),\n",
       " (1.2793935629414077, 'LEMMA_ottelfirnon'),\n",
       " (1.2793935629414077, 'LEMMA_amotlov'),\n",
       " (1.2793935629414077, 'BI_LEMMA_Erouc_LEMMA_amotlov'),\n",
       " (1.2793586233381453, 'BI_LEMMA_giurare_LEMMA_Merlino'),\n",
       " (1.2793270865781021, 'BI_LEMMA_prestare_LEMMA_Ginevra'),\n",
       " (1.2792507302937584, 'BI_LEMMA_sperare_LEMMA_errore'),\n",
       " (1.2791883861919489, 'TRI_LEMMA_Ron_LEMMA_._LEMMA_:'),\n",
       " (1.2790410182124465, 'TRI_LEMMA_of_LEMMA_Life_LEMMA_Avvertimenti'),\n",
       " (1.2790410182124465, 'TRI_LEMMA_Life_LEMMA_Avvertimenti_LEMMA_:'),\n",
       " (1.2790410182124465, 'BI_LEMMA_Life_LEMMA_Avvertimenti'),\n",
       " (1.2788916548832927, 'BI_LEMMA_club_LEMMA_!'),\n",
       " (1.2788245851759703, 'BI_LEMMA_immaginare_LEMMA_incontrare'),\n",
       " (1.2786590413178538, 'TRI_LEMMA_,_LEMMA_Neville_LEMMA_!'),\n",
       " (1.2786236847709356, 'TRI_LEMMA_:_LEMMA_9/10_LEMMA_.'),\n",
       " (1.2784583756280752, 'BI_LEMMA_-Fred_LEMMA_!'),\n",
       " (1.2783338210238175, 'BI_LEMMA_Tanti_LEMMA_piccolo'),\n",
       " (1.2780952075026715, 'TRI_LEMMA_Raiting_LEMMA_:_LEMMA_Verde'),\n",
       " (1.2780628036830048, 'TRI_LEMMA_uccidere_LEMMA_serpere_LEMMA_.'),\n",
       " (1.278060244767137, 'BI_LEMMA_9/10_LEMMA_-'),\n",
       " (1.2780370378988726, 'BI_LEMMA_passare_LEMMA_doloroso'),\n",
       " (1.2780045344489643, 'TRI_LEMMA_._LEMMA_Manchi_LEMMA_.'),\n",
       " (1.277837592307525, 'BI_LEMMA_castello_LEMMA_incantare'),\n",
       " (1.2778172990316952, 'BI_LEMMA_Perce_LEMMA_!'),\n",
       " (1.2776378906462988, 'TRI_LEMMA_Cara_LEMMA_Luna_LEMMA_,'),\n",
       " (1.2776378906462988, 'BI_LEMMA_Cara_LEMMA_Luna'),\n",
       " (1.2773898663148737, 'BI_LEMMA_Spero_LEMMA_tornare'),\n",
       " (1.2772082715189843, 'BI_LEMMA_._LEMMA_Buonsalve'),\n",
       " (1.2771294212880029, 'BI_LEMMA_X_LEMMA_°'),\n",
       " (1.276985559855466, 'TRI_LEMMA_Kiss_LEMMA_the_LEMMA_rain'),\n",
       " (1.2768950419041578, 'BI_LEMMA_felicità_LEMMA_trovare'),\n",
       " (1.2768729264930545, 'BI_LEMMA_:_LEMMA_47'),\n",
       " (1.276677179142969, 'TRI_LEMMA_._LEMMA_Caro_LEMMA_Fred'),\n",
       " (1.2766538943921353, 'BI_LEMMA_,_LEMMA_Odio'),\n",
       " (1.2765064592108102, 'BI_LEMMA_Nota_LEMMA_Herm90'),\n",
       " (1.276422089668625, 'LEMMA_flash!fic'),\n",
       " (1.2763612762053147, 'BI_LEMMA_Ninna_LEMMA_nanna'),\n",
       " (1.2762348694126122, 'LEMMA_tables'),\n",
       " (1.2761832012583376, \"BI_LEMMA_creare_LEMMA_po'\"),\n",
       " (1.2760796187375192, 'BI_LEMMA_pieno_LEMMA_sasso'),\n",
       " (1.2760741762515917, 'BI_LEMMA_\"_LEMMA_Sorrido'),\n",
       " (1.2758076287361566, 'BI_LEMMA_nonna_LEMMA_Augusta'),\n",
       " (1.2755740895923124, 'LEMMA_Alya'),\n",
       " (1.2754396775531551, 'TRI_LEMMA_Erouc_LEMMA_amotlov_LEMMA_ottelfirnon'),\n",
       " (1.2754396775531551, 'BI_LEMMA_amotlov_LEMMA_ottelfirnon'),\n",
       " (1.2753225678969076, 'TRI_LEMMA_?_LEMMA_H_LEMMA_:'),\n",
       " (1.2752384590421133, 'TRI_LEMMA_personale_LEMMA_:_LEMMA_8.5/10'),\n",
       " (1.274890171270779, 'BI_LEMMA_._LEMMA_brillo'),\n",
       " (1.2748269833500585, 'LEMMA_Clio'),\n",
       " (1.2745358217900493, 'BI_LEMMA_Perchè_LEMMA_scegliere'),\n",
       " (1.2744149287939952, 'BI_LEMMA_!_LEMMA_volare'),\n",
       " (1.2743577822785879, 'TRI_LEMMA_._LEMMA_cuore_LEMMA_?'),\n",
       " (1.27431296440659, 'BI_LEMMA_sgridare_LEMMA_il'),\n",
       " (1.2740610164831287, 'TRI_LEMMA_!_LEMMA_\"_LEMMA_George'),\n",
       " (1.2738082973157117, 'LEMMA_Remvsg'),\n",
       " (1.2736905152291897, 'LEMMA_Jessie'),\n",
       " (1.273634842308852, 'BI_LEMMA_perchè_LEMMA_Voldemort'),\n",
       " (1.273581663748206, 'TRI_LEMMA_?_LEMMA_Fred_LEMMA_,'),\n",
       " (1.2732774315210023, 'BI_LEMMA_._LEMMA_Leena'),\n",
       " (1.2732700399459054, 'LEMMA_-Nonna'),\n",
       " (1.2732650510367096, 'TRI_LEMMA_il_LEMMA_Nargilli_LEMMA_,'),\n",
       " (1.2732529493298592, 'TRI_LEMMA_buio_LEMMA_._LEMMA_lucere'),\n",
       " (1.2730794383254107, 'TRI_LEMMA_capello_LEMMA_castano_LEMMA_ricadere'),\n",
       " (1.273042416052131, 'BI_LEMMA_Buonsalve_LEMMA_!'),\n",
       " (1.2730389111410068, 'TRI_LEMMA_._LEMMA_:_LEMMA_<'),\n",
       " (1.273037729226854, 'TRI_LEMMA_passare_LEMMA_San_LEMMA_Valentino'),\n",
       " (1.272752026289079, 'TRI_LEMMA_volare_LEMMA_cielo_LEMMA_.'),\n",
       " (1.2727231769846499, 'TRI_LEMMA_puro_LEMMA_follia_LEMMA_,'),\n",
       " (1.2723826393214674, 'TRI_LEMMA_buon_LEMMA_compleanno_LEMMA_!'),\n",
       " (1.2723228001404434, 'TRI_LEMMA_-_LEMMA_:_LEMMA_\"'),\n",
       " (1.2723078706525979, 'TRI_LEMMA_bacioni_LEMMA_,_LEMMA_confettina'),\n",
       " (1.272185656331912, 'BI_LEMMA_dividere_LEMMA_camera'),\n",
       " (1.272157845071361, 'BI_LEMMA_eva_LEMMA_.'),\n",
       " (1.2721249777172539, 'BI_LEMMA_Ale_LEMMA_HP'),\n",
       " (1.2720411807127747, 'LEMMA_Riga'),\n",
       " (1.271969424216341, 'BI_LEMMA_,_LEMMA_Asfe'),\n",
       " (1.2718466066471341, 'LEMMA_S_Lily_S'),\n",
       " (1.2718331826856426, 'TRI_LEMMA_Spazio_LEMMA_Autrice_LEMMA_*'),\n",
       " (1.2717403187250087, 'BI_LEMMA_mettere_LEMMA_nome'),\n",
       " (1.271651381663924, 'BI_LEMMA_lunare_LEMMA_specchiare'),\n",
       " (1.2715956977291383, 'BI_LEMMA_coraggio_LEMMA_restare'),\n",
       " (1.2715737409451289, 'TRI_LEMMA_stellare_LEMMA_luminoso_LEMMA_cielo'),\n",
       " (1.2715047394107695, 'LEMMA_Danielle'),\n",
       " (1.2714480597245412, 'TRI_LEMMA_?_LEMMA_James_LEMMA_:'),\n",
       " (1.2708447500024223, \"BI_LEMMA_E'_LEMMA_scherzare\"),\n",
       " (1.2707758991958507, 'LEMMA_Zoe'),\n",
       " (1.2707206040193044, 'TRI_LEMMA_(_LEMMA_beato_LEMMA_...'),\n",
       " (1.2706552603930614, 'TRI_LEMMA_essere_LEMMA_,_LEMMA_decidere'),\n",
       " (1.2706151416182963, 'BI_LEMMA_!_LEMMA_Petunia'),\n",
       " (1.2705717800154113, 'TRI_LEMMA_flash_LEMMA_-_LEMMA_fiction'),\n",
       " (1.2705218811687942, 'LEMMA_SBlue'),\n",
       " (1.2704076834118405, 'BI_LEMMA_creatura_LEMMA_piccolo'),\n",
       " (1.2703416856918226, 'TRI_LEMMA_essere_LEMMA_classificare_LEMMA_decimo'),\n",
       " (1.2703416856918226, 'BI_LEMMA_classificare_LEMMA_decimo'),\n",
       " (1.270297140789907, 'TRI_LEMMA_proprietà_LEMMA_Madam_LEMMA_J.K.'),\n",
       " (1.270297140789907, 'TRI_LEMMA_escluso_LEMMA_eventuale_LEMMA_OC'),\n",
       " (1.270297140789907, 'TRI_LEMMA_beato_LEMMA_..._LEMMA_)'),\n",
       " (1.270297140789907, 'TRI_LEMMA_Rowling_LEMMA_(_LEMMA_beato'),\n",
       " (1.270297140789907, 'TRI_LEMMA_Madam_LEMMA_J.K._LEMMA_Rowling'),\n",
       " (1.270297140789907, 'TRI_LEMMA_,_LEMMA_proprietà_LEMMA_Madam'),\n",
       " (1.270297140789907, 'TRI_LEMMA_(_LEMMA_escluso_LEMMA_eventuale'),\n",
       " (1.270297140789907, 'BI_LEMMA_proprietà_LEMMA_Madam'),\n",
       " (1.270297140789907, 'BI_LEMMA_escluso_LEMMA_eventuale'),\n",
       " (1.270297140789907, 'BI_LEMMA_Madam_LEMMA_J.K.'),\n",
       " (1.2701980190440627, 'TRI_LEMMA_Piton_LEMMA_morire_LEMMA_.'),\n",
       " (1.270032449217186, 'TRI_LEMMA_._LEMMA_E_LEMMA_gente'),\n",
       " (1.2699824247961904, 'TRI_LEMMA_(_LEMMA_Team_LEMMA_Harry'),\n",
       " (1.2699824247961904, 'BI_LEMMA_(_LEMMA_Team'),\n",
       " (1.2698405320857635, 'TRI_LEMMA_._LEMMA_-Perché_LEMMA_essere'),\n",
       " (1.2696389029518127, 'TRI_LEMMA_leggere_LEMMA_solamente_LEMMA_:)'),\n",
       " (1.2696389029518127, 'BI_LEMMA_solamente_LEMMA_:)'),\n",
       " (1.2695535586844453, 'TRI_LEMMA_,_LEMMA_AliH_LEMMA_,'),\n",
       " (1.2695352502298614, 'BI_LEMMA_:)_LEMMA_~'),\n",
       " (1.2694425398355338, \"TRI_LEMMA_'s_LEMMA_the_LEMMA_only\"),\n",
       " (1.269440100181155, 'BI_LEMMA_!_LEMMA_ù.ù'),\n",
       " (1.2693352897607386, 'BI_LEMMA_._LEMMA_♫'),\n",
       " (1.2693309302850535, 'BI_LEMMA_perchè_LEMMA_diventare'),\n",
       " (1.2693152158850158, 'TRI_LEMMA_e_LEMMA_leggere_LEMMA_solamente'),\n",
       " (1.2692828414631065, 'BI_LEMMA_CONTEST_LEMMA_\"'),\n",
       " (1.2692504365472492, 'BI_LEMMA_pensiero_LEMMA_Luna'),\n",
       " (1.269228628627049, 'BI_LEMMA_lacrima_LEMMA_abbracciare'),\n",
       " (1.269204218049765, 'TRI_LEMMA_cugino_LEMMA_._LEMMA_-'),\n",
       " (1.269142072862813, 'LEMMA_sbrilluccica'),\n",
       " (1.2689356899631414, 'BI_LEMMA_}_LEMMA_,'),\n",
       " (1.268892001209075, 'BI_LEMMA_immaginare_LEMMA_Albus'),\n",
       " (1.2688807539330007, 'TRI_LEMMA_.._LEMMA_oh_LEMMA_,'),\n",
       " (1.2687839183503538, 'BI_LEMMA_,_LEMMA_AMORE'),\n",
       " (1.268534357173584, 'TRI_LEMMA_\"_LEMMA_._LEMMA_Rose'),\n",
       " (1.2685185596309807, 'TRI_LEMMA_Verde_LEMMA_,_LEMMA_verde'),\n",
       " (1.2685037936782926, 'TRI_LEMMA_gioia_LEMMA_e_LEMMA_difficoltà'),\n",
       " (1.2684992770828913, 'TRI_LEMMA_!_LEMMA_Sirius_LEMMA_:'),\n",
       " (1.2684952050120297, 'TRI_LEMMA_descrivere_LEMMA_il_LEMMA_pensiero'),\n",
       " (1.2684607000028494, 'BI_LEMMA_stellare_LEMMA_illuminare'),\n",
       " (1.268449844830974, 'TRI_LEMMA_(_LEMMA_,_LEMMA_\"'),\n",
       " (1.268449844830974, 'BI_LEMMA_]_LEMMA_}'),\n",
       " (1.268334967442321, 'TRI_LEMMA_chiesa_LEMMA_Luna_LEMMA_,'),\n",
       " (1.267995981030989, 'TRI_LEMMA_\"_LEMMA_Sev_LEMMA_,'),\n",
       " (1.2679355253511226, 'BI_LEMMA_scelto_LEMMA_nome'),\n",
       " (1.2678385413716797, 'TRI_LEMMA_/_LEMMA_Hermione_LEMMA_Prompt'),\n",
       " (1.2678385413716797, 'BI_LEMMA_Hermione_LEMMA_Prompt'),\n",
       " (1.267783601108871, 'TRI_LEMMA_will_LEMMA_guida_LEMMA_you'),\n",
       " (1.267783601108871, 'TRI_LEMMA_guida_LEMMA_you_LEMMA_home'),\n",
       " (1.267783601108871, 'TRI_LEMMA_Lights_LEMMA_will_LEMMA_guida'),\n",
       " (1.267783601108871, 'BI_LEMMA_Lights_LEMMA_will'),\n",
       " (1.2677339572395767, 'BI_LEMMA_._LEMMA_bracciale'),\n",
       " (1.2675907776158284, 'BI_LEMMA_specchiarmi_LEMMA_occhio'),\n",
       " (1.2675626189709566, 'TRI_LEMMA_lasciata_LEMMA_recensione_LEMMA_!'),\n",
       " (1.2674392733475643, 'BI_LEMMA_&_LEMMA_&'),\n",
       " (1.2674180309588223, 'BI_LEMMA_lo_LEMMA_mantenuto'),\n",
       " (1.2674006625100598, 'TRI_LEMMA_onda_LEMMA_mare_LEMMA_.'),\n",
       " (1.267324362620105, 'TRI_LEMMA_riuscire_LEMMA_._LEMMA_essere'),\n",
       " (1.2673100580240606, 'TRI_LEMMA_Natale_LEMMA_e_LEMMA_Natale'),\n",
       " (1.2672703322687422, 'TRI_LEMMA_stile_LEMMA_essere_LEMMA_semplice'),\n",
       " (1.2671498871015838, 'BI_LEMMA_:_LEMMA_10/15'),\n",
       " (1.267123386193602, 'TRI_LEMMA_!_LEMMA_E’_LEMMA_vero'),\n",
       " (1.2671123306009078, 'LEMMA_Lancelot'),\n",
       " (1.2670051458304163, 'TRI_LEMMA_:_LEMMA_15_LEMMA_punto'),\n",
       " (1.2669557604829247, 'TRI_LEMMA_compleanno_LEMMA_,_LEMMA_Fred'),\n",
       " (1.2669070384220174, \"TRI_LEMMA_'s_LEMMA_not_LEMMA_worth\"),\n",
       " (1.2667505494660212, 'TRI_LEMMA_piccolo_LEMMA_Luna_LEMMA_.'),\n",
       " (1.2667476107447386, 'TRI_LEMMA_James_LEMMA_..._LEMMA_,'),\n",
       " (1.2667311378837591, 'TRI_LEMMA_\"-_LEMMA_:_LEMMA_\"'),\n",
       " (1.2667311378837591, 'BI_LEMMA_\"-_LEMMA_:'),\n",
       " (1.266696862128157, 'TRI_LEMMA_Ron_LEMMA_.._LEMMA_”'),\n",
       " (1.2666121452103958, 'TRI_LEMMA_,_LEMMA_osservare_LEMMA_movimentare'),\n",
       " (1.2665741029830853, 'TRI_LEMMA_uccidere_LEMMA_il_LEMMA_migliorare'),\n",
       " (1.2665658779868065, 'LEMMA_2.5/5'),\n",
       " (1.26654647883094, 'TRI_LEMMA_,_LEMMA_7_LEMMA_]'),\n",
       " (1.2664228278001597, 'TRI_LEMMA_Welcome_LEMMA_to_LEMMA_my'),\n",
       " (1.2662072841982985, 'BI_LEMMA_..._LEMMA_Riesco'),\n",
       " (1.266164440156658, 'BI_LEMMA_mica_LEMMA_capitare'),\n",
       " (1.2661533367747682, 'LEMMA_Cover'),\n",
       " (1.26611749586387, 'TRI_LEMMA_,_LEMMA_bacio_LEMMA_!'),\n",
       " (1.266089695168737, 'TRI_LEMMA_ricordare_LEMMA_,_LEMMA_recensire'),\n",
       " (1.2660606133933363, 'BI_LEMMA_stregare_LEMMA_dotato'),\n",
       " (1.2660536801696964, 'BI_LEMMA_Lily_LEMMA_mancare'),\n",
       " (1.2659706977149714, 'TRI_LEMMA_manco_LEMMA_terribilmente_LEMMA_.'),\n",
       " (1.2659395880006432, 'TRI_LEMMA_Utilizzo_LEMMA_pairing_LEMMA_:'),\n",
       " (1.2658732840496043, 'TRI_LEMMA_,_LEMMA_essere_LEMMA_odiare'),\n",
       " (1.2657793511202737, 'TRI_LEMMA_,_LEMMA_sorridere_LEMMA_aprire'),\n",
       " (1.2655399219314325, 'TRI_LEMMA_Totale_LEMMA_:_LEMMA_47'),\n",
       " (1.265533015144092, 'BI_LEMMA_manco_LEMMA_sorridere'),\n",
       " (1.2655138550758664, 'TRI_LEMMA_Seconda_LEMMA_classificare_LEMMA_:'),\n",
       " (1.2654006320238185, 'BI_LEMMA_window_LEMMA_.'),\n",
       " (1.2652750473063348, 'TRI_LEMMA_E_LEMMA_storia_LEMMA_essere'),\n",
       " (1.265267064857069, 'LEMMA_Bha'),\n",
       " (1.2651920031069988, 'BI_LEMMA_]_LEMMA_]'),\n",
       " (1.2651696845843499, 'BI_LEMMA_._LEMMA_Hayley'),\n",
       " (1.2651070166866842, 'LEMMA_Ninja'),\n",
       " (1.265105480020732, 'TRI_LEMMA_,_LEMMA_sorridere_LEMMA_spengere'),\n",
       " (1.2649982731905156, 'BI_LEMMA_._LEMMA_Augustus'),\n",
       " (1.2649692559703203, 'BI_LEMMA_Frank_LEMMA_essere'),\n",
       " (1.2649557484069263, 'BI_LEMMA_guardare_LEMMA_lettera'),\n",
       " (1.264939121563139, 'TRI_LEMMA_\"_LEMMA_-_LEMMA_:'),\n",
       " (1.2649163946698034, 'LEMMA_orticello'),\n",
       " (1.264849386543696, 'TRI_LEMMA_!_LEMMA_H_LEMMA_:'),\n",
       " (1.264740297420879, 'TRI_LEMMA_the_LEMMA_best_LEMMA_,'),\n",
       " (1.2646870083099464, 'BI_LEMMA_impronto_LEMMA_neve'),\n",
       " (1.2646813295611312, 'BI_LEMMA_succedere_LEMMA_qualsiasi'),\n",
       " (1.264600491559116, 'TRI_LEMMA_volere_LEMMA_chiederti_LEMMA_,'),\n",
       " (1.2645394343199705, 'TRI_LEMMA_Ehi_LEMMA_,_LEMMA_Mocciosus'),\n",
       " (1.2643675739374662, 'BI_LEMMA_,_LEMMA_Yaya'),\n",
       " (1.2642653159023536, 'LEMMA_137'),\n",
       " (1.2642393945048456, 'TRI_LEMMA_,_LEMMA_attraversare_LEMMA_barriera'),\n",
       " (1.2642163173168797, 'BI_LEMMA_adorare_LEMMA_<3'),\n",
       " (1.2641826977037707, 'BI_LEMMA_AMORE_LEMMA_...'),\n",
       " (1.2641606718782532, 'TRI_LEMMA_di_LEMMA_alare_LEMMA_.'),\n",
       " (1.2641485909429793, 'TRI_LEMMA_speciale_LEMMA_._LEMMA_.'),\n",
       " (1.2641344651650228, 'TRI_LEMMA_,_LEMMA_cuore_LEMMA_mano'),\n",
       " (1.2639466497509277, 'TRI_LEMMA_roba_LEMMA_Rowling_LEMMA_('),\n",
       " (1.2639466126656003, 'BI_LEMMA_Always_LEMMA_.'),\n",
       " (1.2638871866198775, 'LEMMA_Plimpy'),\n",
       " (1.263855731108716, 'BI_LEMMA_Scorps_LEMMA_,'),\n",
       " (1.263771806106319, 'BI_LEMMA_:_LEMMA_5\\\\5'),\n",
       " (1.2637119039640934, 'BI_LEMMA_usare_LEMMA_pacchetto'),\n",
       " (1.2636361322200815, 'TRI_LEMMA_felice_LEMMA_e_LEMMA_sereno'),\n",
       " (1.2636061386600759, 'TRI_LEMMA_._LEMMA_]_LEMMA_.'),\n",
       " (1.2635291642786513, 'LEMMA_assegnarlo'),\n",
       " (1.263474994370227, 'BI_LEMMA_stellare_LEMMA_portare'),\n",
       " (1.263097572842189, 'BI_LEMMA_._LEMMA_strambo'),\n",
       " (1.26309398006327, 'TRI_LEMMA_il_LEMMA_ringraziamento_LEMMA_.'),\n",
       " (1.263015794994929, 'TRI_LEMMA_._LEMMA_entrare_LEMMA_classe'),\n",
       " (1.2629616931005385, 'BI_LEMMA_sedere_LEMMA_camera'),\n",
       " (1.2629601030079216, 'BI_LEMMA_milione_LEMMA_!'),\n",
       " (1.2628480779202054, 'TRI_LEMMA_-_LEMMA_*_LEMMA_essere'),\n",
       " (1.2627641972437038, 'LEMMA_TittiGranger'),\n",
       " (1.2626831429225411, 'TRI_LEMMA_D_LEMMA_*_LEMMA_*'),\n",
       " (1.262617974685266, 'BI_LEMMA_«_LEMMA_Guar'),\n",
       " (1.262513827281861, 'TRI_LEMMA_e_LEMMA_Fred_LEMMA_Weasley'),\n",
       " (1.2623675867000583, 'TRI_LEMMA_love_LEMMA_you_LEMMA_!'),\n",
       " (1.262292969809039, 'TRI_LEMMA_._LEMMA_Note_LEMMA_piè'),\n",
       " (1.2622730386168122, 'TRI_LEMMA_manco_LEMMA_,_LEMMA_fratello'),\n",
       " (1.262217081725887, 'TRI_LEMMA_:_LEMMA_10/10_LEMMA_caratterizzazione'),\n",
       " (1.262216078713065, 'BI_LEMMA_passeggiata_LEMMA_,'),\n",
       " (1.2622115386398463, 'BI_LEMMA_Luna_LEMMA_Lunatica'),\n",
       " (1.2620944057604284, 'BI_LEMMA_Fred_LEMMA_fissare'),\n",
       " (1.261966191106292, 'BI_LEMMA_figlioletta_LEMMA_.'),\n",
       " (1.2619616390985555, 'LEMMA_wand'),\n",
       " (1.261801058593813, 'TRI_LEMMA_._LEMMA_sacrificare_LEMMA_.'),\n",
       " (1.261715988388271, 'BI_LEMMA_capitare_LEMMA_dalla'),\n",
       " (1.2616559768736353, 'TRI_LEMMA_Peter_LEMMA_._LEMMA_-'),\n",
       " (1.261650349042274, 'BI_LEMMA_il_LEMMA_Plimpi'),\n",
       " (1.2616416365000862, 'TRI_LEMMA_:_LEMMA_47_LEMMA_,'),\n",
       " (1.2615700765905544, 'LEMMA_Terence'),\n",
       " (1.2615029322420384, 'TRI_LEMMA_-No_LEMMA_,_LEMMA_Potter'),\n",
       " (1.26137510948525, 'TRI_LEMMA_tornare_LEMMA_lì_LEMMA_,'),\n",
       " (1.2613749129347616, 'TRI_LEMMA_voltare_LEMMA_padre_LEMMA_.'),\n",
       " (1.2613421993910603, 'BI_LEMMA_piccolo_LEMMA_Dominique'),\n",
       " (1.2611858134500264, 'TRI_LEMMA_And_LEMMA_the_LEMMA_sun'),\n",
       " (1.261181483162617, 'TRI_LEMMA_7_LEMMA_]_LEMMA_,'),\n",
       " (1.2611226397336701, 'TRI_LEMMA_._LEMMA_,_LEMMA_recensire'),\n",
       " (1.2610517113077153, 'TRI_LEMMA_._LEMMA_Spero_LEMMA_one'),\n",
       " (1.2610050662579853, 'BI_LEMMA_ç_ç_LEMMA_,'),\n",
       " (1.260996979879798, 'BI_LEMMA_James_LEMMA_fiancare'),\n",
       " (1.2609968148238286, 'BI_LEMMA_mettere_LEMMA_pc'),\n",
       " (1.2609730907435392, 'BI_LEMMA_trovare_LEMMA_speciale'),\n",
       " (1.2609407059729358, 'TRI_LEMMA_._LEMMA_regolare_LEMMA_,'),\n",
       " (1.260907280468762, 'BI_LEMMA_Nevicava_LEMMA_.'),\n",
       " (1.26089893286394, 'LEMMA_Hono'),\n",
       " (1.2608981469090783, 'TRI_LEMMA_._LEMMA_So_LEMMA_Harry'),\n",
       " (1.2608863726409019, 'BI_LEMMA_cadere_LEMMA_pila'),\n",
       " (1.2608078579808908, 'TRI_LEMMA_invitato_LEMMA_Ballo_LEMMA_Ceppo'),\n",
       " (1.2607402341825267, 'TRI_LEMMA_Luna_LEMMA_Lunatica_LEMMA_Lovegood'),\n",
       " (1.2607260227200237, 'TRI_LEMMA_,_LEMMA_pergamena_LEMMA_nuovo'),\n",
       " (1.2607258180916021, 'LEMMA_Leanne'),\n",
       " (1.2607024803924471, 'TRI_LEMMA_fiore_LEMMA_tomba_LEMMA_.'),\n",
       " (1.260698187923784, 'TRI_LEMMA_Harry_LEMMA_._LEMMA_So'),\n",
       " (1.2606437008071119, 'TRI_LEMMA_appoggiare_LEMMA_finestra_LEMMA_,'),\n",
       " (1.2606174160054406, 'TRI_LEMMA_piccolo_LEMMA_Lily_LEMMA_e'),\n",
       " (1.2605613507732545, 'LEMMA_Bleise'),\n",
       " (1.2603464688183403, 'TRI_LEMMA_10/10_LEMMA_Parere_LEMMA_personale'),\n",
       " (1.2603464688183403, 'BI_LEMMA_10/10_LEMMA_Parere'),\n",
       " (1.2602544679291399, 'TRI_LEMMA_-_LEMMA_fic_LEMMA_piacere'),\n",
       " (1.2602139291862025, 'BI_LEMMA_specchiare_LEMMA_riflesso'),\n",
       " (1.2601622695810608, \"TRI_LEMMA_,_LEMMA_I_LEMMA_won'\"),\n",
       " (1.2601234900509721, 'TRI_LEMMA_Peter_LEMMA_Minus_LEMMA_essere'),\n",
       " (1.2600852060990817, 'TRI_LEMMA_Uso_LEMMA_canzone_LEMMA_:'),\n",
       " (1.2600852060990817, 'BI_LEMMA_Uso_LEMMA_canzone'),\n",
       " (1.2600425801332529, 'BI_LEMMA_razzo_LEMMA_,'),\n",
       " (1.2599964970545343, 'BI_LEMMA_8.5/10_LEMMA_Totale'),\n",
       " (1.2599756226245775, 'LEMMA_M4RT1'),\n",
       " (1.259724543095084, 'TRI_LEMMA_coppia_LEMMA_preferito_LEMMA_!'),\n",
       " (1.259592821186409, 'BI_LEMMA_Jay_LEMMA_,'),\n",
       " (1.2594847277116812, 'LEMMA_DracosWife'),\n",
       " (1.2594369511534995, 'LEMMA_milly92'),\n",
       " (1.259220271947994, 'LEMMA_Narcy'),\n",
       " (1.2591665054980423, 'BI_LEMMA_9.5_LEMMA_punto'),\n",
       " (1.2590339371942008, 'BI_LEMMA_._LEMMA_Riga'),\n",
       " (1.2589385852779735, 'TRI_LEMMA_._LEMMA_,_LEMMA_tristo'),\n",
       " (1.2589155396514704, 'TRI_LEMMA_Genere_LEMMA_:_LEMMA_fluff'),\n",
       " (1.2587993912603002, 'BI_LEMMA_allegria_LEMMA_essere'),\n",
       " (1.2587671739435455, 'TRI_LEMMA_-Beh_LEMMA_..._LEMMA_-'),\n",
       " (1.2587627970513027, 'BI_LEMMA_specchiare_LEMMA_sapere'),\n",
       " (1.2587210057220881, 'TRI_LEMMA_,_LEMMA_George_LEMMA_essere'),\n",
       " (1.2586643518314433, \"TRI_LEMMA_won'_LEMMA_t_LEMMA_ever\"),\n",
       " (1.2585774151697056, 'BI_LEMMA_Londra_LEMMA_\"'),\n",
       " (1.2585298555438884, 'TRI_LEMMA_:_LEMMA_James_LEMMA_essere'),\n",
       " (1.2584352835009716, 'BI_LEMMA_,_LEMMA_mamma!-'),\n",
       " (1.2584327803094892, 'BI_LEMMA_Piton_LEMMA_Lily'),\n",
       " (1.2584208496307916, 'BI_LEMMA_morire_LEMMA_*'),\n",
       " (1.2584122131547013, 'BI_LEMMA_infinito_LEMMA_amore'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_}_LEMMA_,_LEMMA_7'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_}_LEMMA_)_LEMMA_;'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_window_LEMMA_._LEMMA_Bootloader'),\n",
       " (1.2583030609244275,\n",
       "  'TRI_LEMMA_new_LEMMA_(_LEMMA_require(\"ServerJS\"))().handle'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_]_LEMMA_}_LEMMA_)'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_]_LEMMA_]_LEMMA_}'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_]_LEMMA_)_LEMMA_;'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_[_LEMMA_\"_LEMMA_URLFragmentPreludeConfig'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_[_LEMMA_\"_LEMMA_Session'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_URLFragmentPreludeConfig_LEMMA_\"_LEMMA_,'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_Session_LEMMA_\"_LEMMA_,'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_II_LEMMA_new_LEMMA_('),\n",
       " (1.2583030609244275, 'TRI_LEMMA_Challengers_LEMMA_II_LEMMA_new'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_Bootloader_LEMMA_&_LEMMA_&'),\n",
       " (1.2583030609244275,\n",
       "  'TRI_LEMMA_Bootloader.loadEarlyResources_LEMMA_(_LEMMA_,'),\n",
       " (1.2583030609244275,\n",
       "  'TRI_LEMMA_;_LEMMA_Bootloader.loadEarlyResources_LEMMA_('),\n",
       " (1.2583030609244275, 'TRI_LEMMA_:_LEMMA_}_LEMMA_)'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_213_LEMMA_]_LEMMA_]'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_137_LEMMA_]_LEMMA_,'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_._LEMMA_Bootloader_LEMMA_&'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_,_LEMMA_213_LEMMA_]'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_,_LEMMA_137_LEMMA_]'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_,_LEMMA_,_LEMMA_213'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_,_LEMMA_,_LEMMA_137'),\n",
       " (1.2583030609244275,\n",
       "  'TRI_LEMMA_)_LEMMA_;_LEMMA_Bootloader.loadEarlyResources'),\n",
       " (1.2583030609244275,\n",
       "  'TRI_LEMMA_(_LEMMA_require(\"ServerJS\"))().handle_LEMMA_('),\n",
       " (1.2583030609244275, 'TRI_LEMMA_\"_LEMMA_]_LEMMA_)'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_\"_LEMMA_URLFragmentPreludeConfig_LEMMA_\"'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_\"_LEMMA_Session_LEMMA_\"'),\n",
       " (1.2583030609244275, 'TRI_LEMMA_\"_LEMMA_:_LEMMA_}'),\n",
       " (1.2583030609244275, 'LEMMA_require(\"ServerJS\"))().handle'),\n",
       " (1.2583030609244275, 'LEMMA_URLFragmentPreludeConfig'),\n",
       " (1.2583030609244275, 'LEMMA_Session'),\n",
       " (1.2583030609244275, 'LEMMA_Bootloader.loadEarlyResources'),\n",
       " (1.2583030609244275, 'LEMMA_Bootloader'),\n",
       " (1.2583030609244275, 'BI_LEMMA_require(\"ServerJS\"))().handle_LEMMA_('),\n",
       " (1.2583030609244275, 'BI_LEMMA_new_LEMMA_('),\n",
       " (1.2583030609244275, 'BI_LEMMA_URLFragmentPreludeConfig_LEMMA_\"'),\n",
       " (1.2583030609244275, 'BI_LEMMA_Session_LEMMA_\"'),\n",
       " (1.2583030609244275, 'BI_LEMMA_II_LEMMA_new'),\n",
       " (1.2583030609244275, 'BI_LEMMA_Bootloader_LEMMA_&'),\n",
       " (1.2583030609244275, 'BI_LEMMA_Bootloader.loadEarlyResources_LEMMA_('),\n",
       " (1.2583030609244275, 'BI_LEMMA_;_LEMMA_Bootloader.loadEarlyResources'),\n",
       " (1.2583030609244275, 'BI_LEMMA_:_LEMMA_}'),\n",
       " (1.2583030609244275, 'BI_LEMMA_213_LEMMA_]'),\n",
       " (1.2583030609244275, 'BI_LEMMA_137_LEMMA_]'),\n",
       " (1.2583030609244275, 'BI_LEMMA_._LEMMA_Bootloader'),\n",
       " (1.2583030609244275, 'BI_LEMMA_,_LEMMA_213'),\n",
       " (1.2583030609244275, 'BI_LEMMA_,_LEMMA_137'),\n",
       " (1.2583030609244275, 'BI_LEMMA_(_LEMMA_require(\"ServerJS\"))().handle'),\n",
       " (1.2583030609244275, 'BI_LEMMA_\"_LEMMA_URLFragmentPreludeConfig'),\n",
       " (1.2583030609244275, 'BI_LEMMA_\"_LEMMA_Session'),\n",
       " (1.2581905491250034, 'BI_LEMMA_._LEMMA_Piangerò'),\n",
       " (1.2581622313189134, 'BI_LEMMA_linguaggio_LEMMA_semplice'),\n",
       " (1.2580858519590639, 'TRI_LEMMA_vivere_LEMMA_,_LEMMA_amore'),\n",
       " (1.2580600706456255, 'TRI_LEMMA_._LEMMA_odiare_LEMMA_sapere'),\n",
       " (1.2580496013638993, 'BI_LEMMA_Neville_LEMMA_provare'),\n",
       " (1.258043163570058, 'BI_LEMMA_Jean_LEMMA_Weasley'),\n",
       " (1.2580123167837356, 'LEMMA_LOVEGOOD'),\n",
       " (1.2580111060592365, 'BI_LEMMA_._LEMMA_Frida'),\n",
       " (1.2580054332534245, 'LEMMA_GiulyHermi96'),\n",
       " (1.2579444132510018, 'BI_LEMMA_Delusione_LEMMA_.'),\n",
       " (1.2578609031050436, 'BI_LEMMA_leggero_LEMMA_recensione'),\n",
       " (1.2578190978065191, 'LEMMA_Kneazle'),\n",
       " (1.2578128028085893, 'TRI_LEMMA_lo_LEMMA_immagine_LEMMA_Lily'),\n",
       " (1.2577332406852482, 'BI_LEMMA_fissare_LEMMA_sorella'),\n",
       " (1.2576840781243044, 'TRI_LEMMA_amare_LEMMA_._LEMMA_Angolo'),\n",
       " (1.2575686985440442, 'BI_LEMMA_Joanne_LEMMA_,'),\n",
       " (1.257508267209361, \"BI_LEMMA_Moody_LEMMA_'s\"),\n",
       " (1.257502343953158, 'BI_LEMMA_tubetto_LEMMA_dentifricio'),\n",
       " (1.2574606894428721, 'TRI_LEMMA_Sai_LEMMA_cosa_LEMMA_essere'),\n",
       " (1.2574586977522992, 'TRI_LEMMA_essere_LEMMA_secondo_LEMMA_storia'),\n",
       " (1.2574531968297646, 'BI_LEMMA_rimanere_LEMMA_fantasma'),\n",
       " (1.2574027719798127, 'BI_LEMMA_aspettare_LEMMA_cinque'),\n",
       " (1.2574021898686907, 'TRI_LEMMA_!_LEMMA_Lily_LEMMA_:'),\n",
       " (1.2572380146557105, 'TRI_LEMMA_odiare_LEMMA_neve_LEMMA_.'),\n",
       " (1.2572151341031153, 'BI_LEMMA_._LEMMA_Christine'),\n",
       " (1.2572099766396705, 'TRI_LEMMA_negoziare_LEMMA_._LEMMA_E'),\n",
       " (1.2572057324183925, 'TRI_LEMMA_mettere_LEMMA_storia_LEMMA_seguito'),\n",
       " (1.2571417740675788, 'TRI_LEMMA_\"_LEMMA_Lily_LEMMA_Evans'),\n",
       " (1.2570220045161025, 'TRI_LEMMA_A._LEMMA_:_LEMMA_il'),\n",
       " (1.2569534987338464, 'BI_LEMMA_contraddistinguere_LEMMA_e'),\n",
       " (1.2569430512430169, 'BI_LEMMA_!_LEMMA_Xevias'),\n",
       " (1.2568858670950849, 'BI_LEMMA_«_LEMMA_Vic'),\n",
       " (1.2567289218434565, 'BI_LEMMA_Natale_LEMMA_volere'),\n",
       " (1.256726237935773, 'TRI_LEMMA_e_LEMMA_vincere_LEMMA_!'),\n",
       " (1.2566405606521482, 'TRI_LEMMA_\"_LEMMA_bambino_LEMMA_\"'),\n",
       " (1.2566134466124288, 'LEMMA_xAlisx'),\n",
       " (1.2565879268599471, 'BI_LEMMA_guardia_LEMMA_tendere'),\n",
       " (1.256561351433441, 'BI_LEMMA_figliare_LEMMA_lunare'),\n",
       " (1.2565426169553235, 'TRI_LEMMA_figliare_LEMMA_,_LEMMA_Harry'),\n",
       " (1.256478414357301, 'TRI_LEMMA_8/10_LEMMA_Caratterizzazione_LEMMA_:'),\n",
       " (1.2563061712130275, 'BI_LEMMA_immagine_LEMMA_Fred'),\n",
       " (1.2562578322931504, 'BI_LEMMA_Molly_LEMMA_Jr'),\n",
       " (1.2562537703452992, 'BI_LEMMA_.._LEMMA_lacrima'),\n",
       " (1.256248347635902, 'TRI_LEMMA_<_LEMMA_Papà_LEMMA_,'),\n",
       " (1.2561965177493712, 'LEMMA_Yates'),\n",
       " (1.2561926583333203, 'BI_LEMMA_,_LEMMA_sonnecchiare'),\n",
       " (1.256169555756766, 'TRI_LEMMA_10/10_LEMMA_Grammatica_LEMMA_e'),\n",
       " (1.2560610591473398, 'TRI_LEMMA_diventare_LEMMA_rosso_LEMMA_fuoco'),\n",
       " (1.2560523530887067, 'LEMMA_-0.50'),\n",
       " (1.255988489378591, 'TRI_LEMMA_rivolgere_LEMMA_largire_LEMMA_sorridere'),\n",
       " (1.255988489378591, 'BI_LEMMA_rivolgere_LEMMA_largire'),\n",
       " (1.2559701654276179, 'TRI_LEMMA_Eccomi_LEMMA_,_LEMMA_,'),\n",
       " (1.2559666749907252, 'BI_LEMMA_suggestivo_LEMMA_e'),\n",
       " (1.2558405297410957, 'TRI_LEMMA_e_LEMMA_._LEMMA_diverso'),\n",
       " (1.2557880609310745, 'LEMMA_NORMALE'),\n",
       " (1.2557479314779108, 'BI_LEMMA_e_LEMMA_Patronus'),\n",
       " (1.2556935148430446, 'BI_LEMMA_nostalgia_LEMMA_...'),\n",
       " (1.2556639279117157, 'LEMMA_figliuolo'),\n",
       " (1.255630236995094, 'TRI_LEMMA_,_LEMMA_“_LEMMA_Ron'),\n",
       " (1.255452860766395, 'BI_LEMMA_e_LEMMA_lettore'),\n",
       " (1.25543918754426, 'BI_LEMMA_Mostro_LEMMA_!'),\n",
       " (1.2552044289679491, 'TRI_LEMMA_._LEMMA_Lily_LEMMA_paura'),\n",
       " (1.2551562508245684, 'BI_LEMMA_._LEMMA_Arancione'),\n",
       " (1.2550877946214332, 'BI_LEMMA_vuoto_LEMMA_stanza'),\n",
       " (1.255016780531754, 'TRI_LEMMA_Complimenti_LEMMA_e_LEMMA_partecipare'),\n",
       " (1.2549945541689176, 'BI_LEMMA_mamma_LEMMA_ragione'),\n",
       " (1.2549935128513843, 'BI_LEMMA_Jr_LEMMA_e'),\n",
       " (1.2548947255573955, 'BI_LEMMA_Hannah_LEMMA_!'),\n",
       " (1.2548353659160671, 'TRI_LEMMA_fanfiction_LEMMA_challenge_LEMMA_:'),\n",
       " (1.2548154302327499, 'BI_LEMMA_gradire_LEMMA_storia'),\n",
       " (1.2547815943715481, 'BI_LEMMA_Finchè_LEMMA_morto'),\n",
       " (1.254746228721739, 'BI_LEMMA_Ringrazio_LEMMA_mettere'),\n",
       " (1.2547369030125985, 'BI_LEMMA_._LEMMA_El'),\n",
       " (1.2546605254434402, 'BI_LEMMA_Ronald_LEMMA_Weasly'),\n",
       " (1.2545137860834155, 'TRI_LEMMA_,_LEMMA_assistere_LEMMA_impotente'),\n",
       " (1.2544860787511625, 'LEMMA_rapanello'),\n",
       " (1.2544187043645998, 'BI_LEMMA_:_LEMMA_2.5/5'),\n",
       " (1.2543647203224786, 'TRI_LEMMA_Genere_LEMMA_:_LEMMA_Slice'),\n",
       " (1.2542613946928378, 'TRI_LEMMA_?_LEMMA_innamorato_LEMMA_?'),\n",
       " (1.2542295499153708, 'BI_LEMMA_ragazza_LEMMA_sedici'),\n",
       " (1.254182173289866, 'TRI_LEMMA_“_LEMMA_Evans_LEMMA_?'),\n",
       " (1.254143429841959, 'BI_LEMMA_your_LEMMA_bones'),\n",
       " (1.253905953913436, 'TRI_LEMMA_ _LEMMA_storia_LEMMA_partecipare'),\n",
       " (1.2538908672178983, 'BI_LEMMA_dipingere_LEMMA_:'),\n",
       " (1.253831147819776, 'TRI_LEMMA_appena_LEMMA_salire_LEMMA_treno'),\n",
       " (1.2538033773758086, 'BI_LEMMA_-Peter_LEMMA_,'),\n",
       " (1.2537366242237507, 'LEMMA_Nin'),\n",
       " (1.2537022610673987, 'TRI_LEMMA_e_LEMMA_Rosie_LEMMA_,'),\n",
       " (1.253483836116233, 'TRI_LEMMA_leggere_LEMMA_quello_LEMMA_libro'),\n",
       " (1.2534115265733576, 'BI_LEMMA_foto_LEMMA_stringere'),\n",
       " (1.2533978351991322, 'LEMMA_Hayley'),\n",
       " (1.2533015324339667, 'TRI_LEMMA_cancellare_LEMMA_pagina_LEMMA_immagine'),\n",
       " (1.2532816622815781, 'TRI_LEMMA_._LEMMA_I_LEMMA_malandrino'),\n",
       " (1.2532560800306354, 'TRI_LEMMA_-_LEMMA_Ehm_LEMMA_..'),\n",
       " (1.2531396726394919, 'BI_LEMMA_pecora_LEMMA_bianco'),\n",
       " (1.2529812227014896, 'TRI_LEMMA_,_LEMMA_e_LEMMA_Rosie'),\n",
       " (1.2529699734159767, 'TRI_LEMMA_cuore_LEMMA_,_LEMMA_...'),\n",
       " (1.2529684468333908, 'TRI_LEMMA_strano_LEMMA_cicatrice_LEMMA_fronte'),\n",
       " (1.25285039423178, 'TRI_LEMMA_!_LEMMA_”_LEMMA_l'),\n",
       " (1.2527559681015714, 'TRI_LEMMA_–_LEMMA_chiesa_LEMMA_Remus'),\n",
       " (1.2526882119690295, 'TRI_LEMMA_*_LEMMA_*_LEMMA_Giudizio'),\n",
       " (1.2526565134557326, 'BI_LEMMA_lieve_LEMMA_vento'),\n",
       " (1.2525719302469431, 'TRI_LEMMA_,_LEMMA_e_LEMMA_amarti'),\n",
       " (1.252532047307678, 'BI_LEMMA_!_LEMMA_Voldy'),\n",
       " (1.2523974782128153, 'TRI_LEMMA_quello_LEMMA_momento_LEMMA_passato'),\n",
       " (1.2523334367121004, 'TRI_LEMMA_._LEMMA___LEMMA_EpicLoVe'),\n",
       " (1.2522820447689593, 'TRI_LEMMA_piacere_LEMMA_rivederti_LEMMA_,'),\n",
       " (1.2522040050276018, 'TRI_LEMMA_9.5/10_LEMMA_Gradimento_LEMMA_personale'),\n",
       " (1.2521772105815263, 'TRI_LEMMA_dedicare_LEMMA_Harry_LEMMA_Potter'),\n",
       " (1.2520582288116286, 'TRI_LEMMA_guardare_LEMMA_immagine_LEMMA_riflesso'),\n",
       " (1.2518418079945097, 'BI_LEMMA_Cioccorana_LEMMA_,'),\n",
       " (1.2518161254308315, 'TRI_LEMMA_sulla_LEMMA_altalenare_LEMMA_.'),\n",
       " (1.251798094615822, 'BI_LEMMA_._LEMMA_-Nonna'),\n",
       " (1.2517649580702153, 'TRI_LEMMA_._LEMMA_succedere_LEMMA_tanto'),\n",
       " (1.251745724182641, 'TRI_LEMMA_essere_LEMMA_braccio_LEMMA_.'),\n",
       " (1.2517191456739876, 'LEMMA_strilettera'),\n",
       " (1.2517151675252336, 'TRI_LEMMA_occhio_LEMMA_Fred_LEMMA_fissare'),\n",
       " (1.2517151675252336, 'TRI_LEMMA_fissare_LEMMA_vederli_LEMMA_,'),\n",
       " (1.2517151675252336, 'TRI_LEMMA_Fred_LEMMA_fissare_LEMMA_vederli'),\n",
       " (1.2517048147107401, 'BI_LEMMA_Lavanda_LEMMA_”'),\n",
       " (1.2515835092924847, 'LEMMA_Worm'),\n",
       " (1.2515525437027075, 'TRI_LEMMA_!_LEMMA_mille_LEMMA_,'),\n",
       " (1.25152126509197, 'TRI_LEMMA_,_LEMMA___LEMMA_M'),\n",
       " (1.2515030789408854, 'LEMMA_Emm'),\n",
       " (1.251477588142836, 'TRI_LEMMA_amare_LEMMA_,_LEMMA_promettere'),\n",
       " (1.2514375067082708, 'TRI_LEMMA_lo_LEMMA_amore_LEMMA_madre'),\n",
       " (1.2513751814149146, 'LEMMA_Apple'),\n",
       " (1.251312125393605, 'LEMMA_Donovan'),\n",
       " (1.2513073944035848, 'BI_LEMMA_donare_LEMMA_affettare'),\n",
       " (1.2512571513284105, 'BI_LEMMA_qui?-_LEMMA_Chiese'),\n",
       " (1.2511900519211883, 'LEMMA_Fans'),\n",
       " (1.2511441908644214, 'BI_LEMMA_buono_LEMMA_('),\n",
       " (1.2509574606776022, 'BI_LEMMA_il_LEMMA_treno'),\n",
       " (1.2509365800602017, 'LEMMA_POTTER!-'),\n",
       " (1.2509216700517645, 'TRI_LEMMA_._LEMMA_Tana_LEMMA_.'),\n",
       " (1.2508746484642717, 'TRI_LEMMA_restare_LEMMA_immobile_LEMMA_parlare'),\n",
       " (1.2508600725026198, 'TRI_LEMMA_sapere_LEMMA_riuscire_LEMMA_farlo'),\n",
       " (1.250836411512758, 'TRI_LEMMA_spettinare_LEMMA_,_LEMMA_occhiale'),\n",
       " (1.250792247642589, 'TRI_LEMMA_._LEMMA_e_LEMMA_tenere'),\n",
       " (1.2505514143039151, 'TRI_LEMMA_Verde_LEMMA_Genere_LEMMA_:'),\n",
       " (1.2505514143039151, 'TRI_LEMMA_:_LEMMA_Verde_LEMMA_Genere'),\n",
       " (1.2505514143039151, 'BI_LEMMA_Verde_LEMMA_Genere'),\n",
       " (1.25047923586625, 'BI_LEMMA_Calendario_LEMMA_della'),\n",
       " (1.2504606823281603, 'LEMMA_HarryPotterianaDOC'),\n",
       " (1.2503298204640094, 'BI_LEMMA_Luna_LEMMA_notare'),\n",
       " (1.2502844401741287, 'BI_LEMMA_tonks_LEMMA_,'),\n",
       " (1.2502802508907527, 'TRI_LEMMA_castano_LEMMA_,_LEMMA_il'),\n",
       " (1.250277025939595, 'BI_LEMMA_somigliare_LEMMA_tantissimo'),\n",
       " (1.2501761560813565, 'LEMMA_N.A.'),\n",
       " (1.25008091530876, 'TRI_LEMMA_._LEMMA_ragazzo_LEMMA_occhiale'),\n",
       " (1.2500302112912423, 'BI_LEMMA_”_LEMMA_l'),\n",
       " (1.2500109755878754, 'BI_LEMMA_es_LEMMA_.'),\n",
       " (1.250008819953411, 'BI_LEMMA_fix_LEMMA_you'),\n",
       " (1.2499562558128114, 'BI_LEMMA_tonalità_LEMMA_capello'),\n",
       " (1.2499353856062696, 'TRI_LEMMA_James_LEMMA_!_LEMMA_–'),\n",
       " (1.2499353362626002, 'TRI_LEMMA_sognare_LEMMA_essere_LEMMA_avverare'),\n",
       " (1.2499152325804388, 'LEMMA_Anacleto'),\n",
       " (1.2499060944144431, 'TRI_LEMMA_lunare_LEMMA_pieno_LEMMA_”'),\n",
       " (1.2499031948703478, 'TRI_LEMMA_,_LEMMA_spuntare_LEMMA_sorridere'),\n",
       " (1.249902511429463, 'TRI_LEMMA_quell_LEMMA_’_LEMMA_“'),\n",
       " (1.2498690364638014, 'LEMMA_anagrafe'),\n",
       " (1.2498429226641958, 'TRI_LEMMA_always_LEMMA_be_LEMMA_there'),\n",
       " (1.2497603530082224, 'TRI_LEMMA_sembrare_LEMMA_tristo_LEMMA_.'),\n",
       " (1.249742554526691, 'TRI_LEMMA_-_LEMMA_Ronald_LEMMA_Weasley'),\n",
       " (1.2497199957205456, 'TRI_LEMMA_._LEMMA_E’_LEMMA_voce'),\n",
       " (1.249715049308937, 'BI_LEMMA_sprecare_LEMMA_lacrima'),\n",
       " (1.2496790006570302, 'LEMMA_dlon'),\n",
       " (1.2496352670973119, 'TRI_LEMMA_(_LEMMA_-0.50_LEMMA_)'),\n",
       " (1.2496352670973119, 'BI_LEMMA_-0.50_LEMMA_)'),\n",
       " (1.2496352670973119, 'BI_LEMMA_(_LEMMA_-0.50'),\n",
       " (1.2496311432696476, 'BI_LEMMA_mimosa_LEMMA_.'),\n",
       " (1.249536709539385, 'BI_LEMMA_della_LEMMA_Avvento'),\n",
       " (1.2495225042205056, 'BI_LEMMA_Malandrini_LEMMA_”'),\n",
       " (1.2495165510969943, 'LEMMA_´'),\n",
       " (1.2495024171403906, 'TRI_LEMMA_-_LEMMA_dire_LEMMA_Luna'),\n",
       " (1.2492460428117171, 'LEMMA_Cabiria'),\n",
       " (1.2492460428117171, 'BI_LEMMA_Cabiria_LEMMA_Minerva'),\n",
       " (1.2492399820426128, 'TRI_LEMMA_gemellare_LEMMA_._LEMMA_,'),\n",
       " (1.2491802067121616, 'BI_LEMMA_Take_LEMMA_your'),\n",
       " (1.2491372457793977, 'BI_LEMMA_cry_LEMMA_...'),\n",
       " (1.2491162628882952, 'TRI_LEMMA_personaggio_LEMMA_:_LEMMA_7/10'),\n",
       " (1.249087893166051, 'LEMMA_Pikkola_Fe'),\n",
       " (1.2490837984751402, 'TRI_LEMMA_leggero_LEMMA_,_LEMMA_potere'),\n",
       " (1.2490676512829941, 'TRI_LEMMA_Remus_LEMMA_._LEMMA_il'),\n",
       " (1.2490512847568327, 'LEMMA_Perfettina'),\n",
       " (1.2489441725907993, 'TRI_LEMMA_._LEMMA_._LEMMA_rendere'),\n",
       " (1.2489208394025093, 'TRI_LEMMA_capire_LEMMA_,_LEMMA_Lily'),\n",
       " (1.2488994877176427, 'LEMMA_Beeene'),\n",
       " (1.2488806953048437, 'TRI_LEMMA_,_LEMMA_odiare_LEMMA_davvero'),\n",
       " (1.248664396156749, 'TRI_LEMMA_vedere_LEMMA_buono_LEMMA_amico'),\n",
       " (1.2486198429044717, 'BI_LEMMA_semplicemente_LEMMA_destinare'),\n",
       " (1.2485574610672565, 'TRI_LEMMA_you_LEMMA_ever_LEMMA_feel'),\n",
       " (1.2484761176662875, 'TRI_LEMMA_._LEMMA_Natale_LEMMA_avvicinare'),\n",
       " (1.2483776427263598, 'TRI_LEMMA_e_LEMMA_Ramoso_LEMMA_,'),\n",
       " (1.2483431666944642, 'TRI_LEMMA_Rowling_LEMMA_._LEMMA_scrivere'),\n",
       " (1.2483304082686075, 'TRI_LEMMA_Lily_LEMMA_Evans_LEMMA_guardare'),\n",
       " (1.2483288354710371, 'BI_LEMMA_castano_LEMMA_:'),\n",
       " (1.248326911813682, 'TRI_LEMMA_your_LEMMA_love_LEMMA_I'),\n",
       " (1.2483243554387227, 'TRI_LEMMA_4_LEMMA_,_LEMMA_9/5'),\n",
       " (1.2483243554387227, 'LEMMA_9/5'),\n",
       " (1.2483243554387227, 'BI_LEMMA_,_LEMMA_9/5'),\n",
       " (1.248320714256614, 'LEMMA_paperelle'),\n",
       " (1.2483199977633594, 'TRI_LEMMA_Hermione_LEMMA_._LEMMA_:'),\n",
       " (1.2481951554269353, 'TRI_LEMMA_salare_LEMMA_comune_LEMMA_Tassorosso'),\n",
       " (1.2481951554269353, 'BI_LEMMA_comune_LEMMA_Tassorosso'),\n",
       " (1.2481885522436829, 'BI_LEMMA_\"_LEMMA_Andromeda'),\n",
       " (1.2481684739255383, 'LEMMA_Derret'),\n",
       " (1.2481298567758765, 'BI_LEMMA_giardino_LEMMA_fiore'),\n",
       " (1.2481204895489721, 'BI_LEMMA_amico_LEMMA_accettare'),\n",
       " (1.2481143573959144, 'TRI_LEMMA_,_LEMMA_Severus_LEMMA_\"'),\n",
       " (1.2481095310653125, 'TRI_LEMMA_Eccomi_LEMMA_qua_LEMMA_.'),\n",
       " (1.2480544134405789, 'TRI_LEMMA_strada_LEMMA_cuore_LEMMA_.'),\n",
       " (1.2477325974131093, 'TRI_LEMMA_Grifondoro_LEMMA_,_LEMMA_cullare'),\n",
       " (1.2477121784825096, 'BI_LEMMA_grande_LEMMA_punto'),\n",
       " (1.2477081939398225, 'BI_LEMMA_vincere_LEMMA_lotteria'),\n",
       " (1.2476513209621942, 'TRI_LEMMA_frase_LEMMA_breve_LEMMA_,'),\n",
       " (1.2476354992347507, 'TRI_LEMMA_._LEMMA_I_LEMMA_negozio'),\n",
       " (1.2475590807627093, 'TRI_LEMMA_She_LEMMA_is_LEMMA_the'),\n",
       " (1.2474673875845208, 'TRI_LEMMA_caratterizzazione_LEMMA_essere_LEMMA_buono'),\n",
       " (1.2474593781578065, 'TRI_LEMMA_parola_LEMMA_o_LEMMA_gesto'),\n",
       " (1.2473044576879957, 'TRI_LEMMA_amare_LEMMA_e_LEMMA_dovere'),\n",
       " (1.2472987714483763, 'TRI_LEMMA_raggiungere_LEMMA_e_LEMMA_sedette'),\n",
       " (1.2472172158836694, 'BI_LEMMA_ricordare_LEMMA_recensione'),\n",
       " (1.247049014023567, 'TRI_LEMMA_potere_LEMMA_ridere_LEMMA_e'),\n",
       " (1.2469845617566726, 'BI_LEMMA_\"_LEMMA_Eleanor'),\n",
       " (1.2469754372642334, 'BI_LEMMA_allegare_LEMMA_giudizio'),\n",
       " (1.2469635580891028, 'BI_LEMMA_respirare_LEMMA_una'),\n",
       " (1.2469271704087166, 'BI_LEMMA_Freddy_LEMMA_,'),\n",
       " (1.2469221959860834, 'LEMMA_hush'),\n",
       " (1.2468181570315622, 'BI_LEMMA_il_LEMMA_pattino'),\n",
       " (1.2467102521519942, 'TRI_LEMMA_Luna_LEMMA_,_LEMMA_semplicemente'),\n",
       " (1.2466929436742789, 'LEMMA_Sognando'),\n",
       " (1.2466749889944215, 'BI_LEMMA_nome_LEMMA_Calice'),\n",
       " (1.246600660473928, 'TRI_LEMMA_Ringrazio_LEMMA_mettere_LEMMA_storia'),\n",
       " (1.2465388883671604, 'BI_LEMMA_Ced_LEMMA_.'),\n",
       " (1.246478595114551, 'TRI_LEMMA_Calendario_LEMMA_della_LEMMA_Avvento'),\n",
       " (1.2464771150736578, 'LEMMA_Rupertmania'),\n",
       " (1.2464335884451803, 'TRI_LEMMA_Lily_LEMMA_._LEMMA_lo'),\n",
       " (1.2463722330731457, 'TRI_LEMMA_voltare_LEMMA_stancare_LEMMA_.'),\n",
       " (1.2463717925626863, 'TRI_LEMMA_”_LEMMA_dire_LEMMA_bambina'),\n",
       " (1.2463550321138634, \"BI_LEMMA_prim'_LEMMA_ordine\"),\n",
       " (1.2463072554488084, 'BI_LEMMA_vedere_LEMMA_amato'),\n",
       " (1.2461956160798904, 'TRI_LEMMA_\"_LEMMA_._LEMMA_Credo'),\n",
       " (1.2461948144538313, 'TRI_LEMMA_potere_LEMMA_andare_LEMMA_giocare'),\n",
       " (1.2461762651905457, 'TRI_LEMMA_Pietra_LEMMA_Filosofale_LEMMA_\"'),\n",
       " (1.2461762651905457, 'BI_LEMMA_Filosofale_LEMMA_\"'),\n",
       " (1.2460993751812945, 'TRI_LEMMA_how_LEMMA_I_LEMMA_wish'),\n",
       " (1.2459389396761527, 'TRI_LEMMA_._LEMMA_scomparire_LEMMA_.'),\n",
       " (1.2458316882807292, 'TRI_LEMMA_veramente_LEMMA_,_LEMMA_riuscire'),\n",
       " (1.2457321216262052, 'BI_LEMMA_figurare_LEMMA_simile'),\n",
       " (1.2457301442748396, 'BI_LEMMA_passato_LEMMA_quindici'),\n",
       " (1.2457199107041128, 'BI_LEMMA_difficile_LEMMA_superare'),\n",
       " (1.2456899381374904, 'BI_LEMMA_Chips_LEMMA_:'),\n",
       " (1.2455613415528544, 'BI_LEMMA_L’_LEMMA_intelligenza'),\n",
       " (1.2455559293256644, 'BI_LEMMA_ever_LEMMA_say'),\n",
       " (1.245551910587866, 'TRI_LEMMA_visibilmente_LEMMA_imbarazzare_LEMMA_.'),\n",
       " (1.2455317767996095, 'BI_LEMMA_sfogliare_LEMMA_vecchio'),\n",
       " (1.2454703504906333, 'TRI_LEMMA_zio_LEMMA_._LEMMA_,'),\n",
       " (1.245313622922389, 'LEMMA_leccalecca'),\n",
       " (1.2452943448467846, 'BI_LEMMA_4/5_LEMMA_essere'),\n",
       " (1.245247334665454, 'BI_LEMMA_..._LEMMA_<3'),\n",
       " (1.245214784254852, 'TRI_LEMMA_my_LEMMA_life_LEMMA_,'),\n",
       " (1.2452084891531652, 'TRI_LEMMA_Rowling_LEMMA_(_LEMMA_Team'),\n",
       " (1.245114664263444, 'BI_LEMMA_._LEMMA_Beata'),\n",
       " (1.2449629142832126, 'BI_LEMMA_“_LEMMA_Tanti'),\n",
       " (1.24494978903137, 'LEMMA_CACCA'),\n",
       " (1.2447446053456614, 'TRI_LEMMA_e_LEMMA_malandrino_LEMMA_.'),\n",
       " (1.2446413053881789, 'TRI_LEMMA_Lily_LEMMA_!_LEMMA_Lily'),\n",
       " (1.2445895327924488, 'BI_LEMMA_,_LEMMA_bacino'),\n",
       " (1.2444508386549313, 'TRI_LEMMA_della_LEMMA_amicizia_LEMMA_,'),\n",
       " (1.244425514521831, 'TRI_LEMMA_semplice_LEMMA_,_LEMMA_dirigere'),\n",
       " (1.244416521605929, 'BI_LEMMA_salare_LEMMA_“'),\n",
       " (1.2443762849643125, 'TRI_LEMMA_,_LEMMA_barba_LEMMA_bianco'),\n",
       " (1.2443739062438244, \"TRI_LEMMA_!_LEMMA_Be_LEMMA_'\"),\n",
       " (1.2442465562248999, 'TRI_LEMMA_,_LEMMA_Tiri_LEMMA_Vispi'),\n",
       " (1.2442465562248999, 'BI_LEMMA_,_LEMMA_Tiri'),\n",
       " (1.24419944978209, 'TRI_LEMMA_Verde_LEMMA_Avvertimenti_LEMMA_:'),\n",
       " (1.24419944978209, 'TRI_LEMMA_:_LEMMA_Verde_LEMMA_Avvertimenti'),\n",
       " (1.24419944978209, 'BI_LEMMA_Verde_LEMMA_Avvertimenti'),\n",
       " (1.2441780187384344, 'TRI_LEMMA_e_LEMMA_ultimo_LEMMA_spiaggia'),\n",
       " (1.2441692852762798, 'TRI_LEMMA_Finché_LEMMA_morto_LEMMA_separare'),\n",
       " (1.244087069580842, 'BI_LEMMA_scongiurare_LEMMA_!'),\n",
       " (1.2440222927509172, 'LEMMA_Meli'),\n",
       " (1.243990441848586, 'BI_LEMMA_mamma_LEMMA_ripetere'),\n",
       " (1.2439762576592066, 'TRI_LEMMA_sulla_LEMMA_acqua_LEMMA_.'),\n",
       " (1.2439742612785194, 'BI_LEMMA_Neville_LEMMA_ricordare'),\n",
       " (1.2439604970833749, 'TRI_LEMMA_personaggio_LEMMA_piacere_LEMMA_,'),\n",
       " (1.243940369036715, 'TRI_LEMMA_canzone_LEMMA_:_LEMMA_5/5'),\n",
       " (1.2439288559046058, 'LEMMA_mioni'),\n",
       " (1.2439288559046058, 'BI_LEMMA_-_LEMMA_mioni'),\n",
       " (1.2438944465711559, 'TRI_LEMMA_zio_LEMMA_Fred_LEMMA_.'),\n",
       " (1.2438236043053825, 'TRI_LEMMA_capire_LEMMA_dolore_LEMMA_,'),\n",
       " (1.243812039298223, 'TRI_LEMMA_Ron_LEMMA_inginocchiare_LEMMA_accanto'),\n",
       " (1.2437811940729007, 'BI_LEMMA_,_LEMMA_Freddy'),\n",
       " (1.2436614635701684, 'BI_LEMMA_fondere_LEMMA_Lago'),\n",
       " (1.2436521541182992, 'BI_LEMMA_here_LEMMA_on'),\n",
       " (1.2436189461290805, 'BI_LEMMA_ragazzino_LEMMA_giocare'),\n",
       " (1.2436172520283697, 'TRI_LEMMA_piangere_LEMMA_,_LEMMA_corpo'),\n",
       " (1.2434812575210086, 'TRI_LEMMA_geloso_LEMMA_,_LEMMA_sapere'),\n",
       " (1.2434555992433207, 'LEMMA_Cerdic'),\n",
       " (1.2434466326919342, 'BI_LEMMA_e_LEMMA_penalizzare'),\n",
       " (1.2433022260231288, 'BI_LEMMA_here_LEMMA_I'),\n",
       " (1.2432747356309082, 'TRI_LEMMA_(_LEMMA_es_LEMMA_.'),\n",
       " (1.2432557087294347, 'BI_LEMMA_volare_LEMMA_liberare'),\n",
       " (1.243112166871112, 'BI_LEMMA_Fred_LEMMA_appoggiare'),\n",
       " (1.2431035674619564, 'TRI_LEMMA_parere_LEMMA_occhiale_LEMMA_tondo'),\n",
       " (1.2430680553360378, 'TRI_LEMMA_guerra_LEMMA_._LEMMA_.'),\n",
       " (1.2430372638866414, 'TRI_LEMMA_guardare_LEMMA_tramontare_LEMMA_,'),\n",
       " (1.2430106660111346, 'TRI_LEMMA_._LEMMA_provare_LEMMA_strano'),\n",
       " (1.2429869288806354, 'TRI_LEMMA_._LEMMA_volere_LEMMA_chiederle'),\n",
       " (1.242918683653912, 'BI_LEMMA_influire_LEMMA_punteggiare'),\n",
       " (1.2429167835627097, 'TRI_LEMMA_Hermione_LEMMA_]_LEMMA_.'),\n",
       " (1.2428617805672733, 'BI_LEMMA_._LEMMA_occhione'),\n",
       " (1.2428197955914617, 'LEMMA_-Anzi'),\n",
       " (1.242801389781557, 'TRI_LEMMA_,_LEMMA_ricordare_LEMMA_James'),\n",
       " (1.2428002142612953, 'BI_LEMMA_piacevole_LEMMA_stare'),\n",
       " (1.2426962725750916, 'BI_LEMMA_Hope_LEMMA_.'),\n",
       " (1.2426332898539596, 'TRI_LEMMA_essere_LEMMA_felice_LEMMA_?'),\n",
       " (1.2425933860904241, 'BI_LEMMA_essere_LEMMA_cerva'),\n",
       " (1.242576407909902, 'TRI_LEMMA_volere_LEMMA_ballare_LEMMA_?'),\n",
       " (1.2425332991488658, 'TRI_LEMMA_”_LEMMA_padre_LEMMA_.'),\n",
       " (1.2424142378554597, 'TRI_LEMMA_dovere_LEMMA_solo_LEMMA_.'),\n",
       " (1.2423040549920688, 'TRI_LEMMA_scrivere_LEMMA_contest_LEMMA_,'),\n",
       " (1.2421332048530178, 'TRI_LEMMA_,_LEMMA_trattare_LEMMA_figliare'),\n",
       " (1.2420592325410331, 'TRI_LEMMA_George_LEMMA_..._LEMMA_-'),\n",
       " (1.2420376092891083, 'TRI_LEMMA_Harry_LEMMA_crescere_LEMMA_.'),\n",
       " (1.2420294914391723, 'BI_LEMMA_Neanche_LEMMA_essere'),\n",
       " (1.2420200575032447, 'TRI_LEMMA_,_LEMMA_sorella_LEMMA_Lily'),\n",
       " (1.2419782805413895, 'BI_LEMMA_ormai_LEMMA_scrivere'),\n",
       " (1.2419376247460305, 'BI_LEMMA_ostinare_LEMMA_cercare'),\n",
       " (1.241929550368517, 'BI_LEMMA_il_LEMMA_chiamare'),\n",
       " (1.2419257002530877, 'TRI_LEMMA_andare_LEMMA_..._LEMMA_dovere'),\n",
       " (1.2419030867936798, 'TRI_LEMMA_,_LEMMA_sedette_LEMMA_sedia'),\n",
       " (1.2418646252310772, 'TRI_LEMMA_quarto_LEMMA_,_LEMMA_,'),\n",
       " (1.241841421016974, 'TRI_LEMMA_lezione_LEMMA_incantesimo_LEMMA_,'),\n",
       " (1.2418159079182454, 'TRI_LEMMA_partire_LEMMA_,_LEMMA_,'),\n",
       " (1.2418089479191066, 'BI_LEMMA_Vorresti_LEMMA_urlare'),\n",
       " (1.241806769793595, 'TRI_LEMMA_augurarvi_LEMMA_Buon_LEMMA_Natale'),\n",
       " (1.241806769793595, 'BI_LEMMA_augurarvi_LEMMA_Buon'),\n",
       " (1.2417639856639422, 'TRI_LEMMA_Voglio_LEMMA_andare_LEMMA_.'),\n",
       " (1.241751085853161, 'TRI_LEMMA_._LEMMA_Complimenti_LEMMA_e'),\n",
       " (1.2416395747120919, 'LEMMA_Ndtutti'),\n",
       " (1.241572512346538, 'BI_LEMMA_maglione_LEMMA_!'),\n",
       " (1.241528204714282, 'BI_LEMMA_dente_LEMMA_grande'),\n",
       " (1.2414540591398897, 'TRI_LEMMA_>_LEMMA_>_LEMMA_Lily'),\n",
       " (1.2414229824680572, 'BI_LEMMA_The_LEMMA_Day'),\n",
       " (1.2414185200026402, 'BI_LEMMA_stupido_LEMMA_scusa'),\n",
       " (1.2413900043490949, 'BI_LEMMA_:_LEMMA_Verde'),\n",
       " (1.2413808292542396, 'BI_LEMMA_vestitino_LEMMA_roso'),\n",
       " (1.2413404714177556, 'LEMMA_Flying'),\n",
       " (1.2413391110252967, 'TRI_LEMMA_!_LEMMA_!_LEMMA_parlare'),\n",
       " (1.2413318020491015, 'TRI_LEMMA_sedette_LEMMA_scrivania_LEMMA_.'),\n",
       " (1.2413216937770264, 'TRI_LEMMA_situazione_LEMMA_migliorare_LEMMA_.'),\n",
       " (1.241260167496586, 'TRI_LEMMA_10/10_LEMMA_Attinenza_LEMMA_citazione'),\n",
       " (1.2412337458516087, 'TRI_LEMMA_what_LEMMA_you_LEMMA_want'),\n",
       " (1.2412235388701718, 'TRI_LEMMA_baciare_LEMMA_guancia_LEMMA_madre'),\n",
       " (1.2410204944420107, 'TRI_LEMMA_appoggiare_LEMMA_alberare_LEMMA_,'),\n",
       " (1.2409811805098634, 'TRI_LEMMA_E’_LEMMA_difficile_LEMMA_,'),\n",
       " (1.2409605646848572, 'LEMMA_1500'),\n",
       " (1.2408778085158108, 'BI_LEMMA_sguardo_LEMMA_scrivania'),\n",
       " (1.240873098584033, 'TRI_LEMMA_darti_LEMMA_punteggiare_LEMMA_,'),\n",
       " (1.2408036040846833, 'TRI_LEMMA_parlare_LEMMA_amico_LEMMA_,'),\n",
       " (1.2407903089323786, 'TRI_LEMMA_*_LEMMA_Ehm_LEMMA_,'),\n",
       " (1.2407476977120817, 'BI_LEMMA_._LEMMA_sintassi'),\n",
       " (1.2407390761556303, 'TRI_LEMMA_continuo_LEMMA_cadere_LEMMA_,'),\n",
       " (1.2407374214458085, 'BI_LEMMA_away_LEMMA_?'),\n",
       " (1.24069980059957, 'TRI_LEMMA_adorare_LEMMA_,_LEMMA_essere'),\n",
       " (1.2405053075747825, 'TRI_LEMMA_un’_LEMMA_uscire_LEMMA_Hogsmeade'),\n",
       " (1.2405048362383708, 'TRI_LEMMA_ragazzo_LEMMA_,_LEMMA_lì'),\n",
       " (1.2404382311945437, 'TRI_LEMMA_il_LEMMA_genitore_LEMMA_sorridere'),\n",
       " (1.2404248449889959, 'TRI_LEMMA_,_LEMMA_occhio_LEMMA_c’'),\n",
       " (1.2404002512081906, 'TRI_LEMMA_trovare_LEMMA_,_LEMMA_dovere'),\n",
       " (1.240330119618108, 'BI_LEMMA_dire_LEMMA_cretino'),\n",
       " (1.2402863961632469, 'BI_LEMMA_e_LEMMA_improvvisare'),\n",
       " (1.2402239366811971, 'BI_LEMMA_)_LEMMA_recensire'),\n",
       " (1.2401572343009066, 'BI_LEMMA_*_LEMMA_Grammatica'),\n",
       " (1.2401195161989231, 'TRI_LEMMA_<_LEMMA_<_LEMMA_Luna'),\n",
       " (1.2400849576708879, 'TRI_LEMMA_occhio_LEMMA_s’_LEMMA_illuminare'),\n",
       " (1.2400642672130922, 'TRI_LEMMA_iniziare_LEMMA_piovere_LEMMA_,'),\n",
       " (1.2400519894044808, 'BI_LEMMA_eyes_LEMMA_are'),\n",
       " (1.2399982667109473, 'LEMMA_ridammelo'),\n",
       " (1.2399764132593174, 'BI_LEMMA_:_LEMMA_recensire'),\n",
       " (1.2399748478955122, 'BI_LEMMA_^^_LEMMA_bacione'),\n",
       " (1.2399525109645928, 'BI_LEMMA_il_LEMMA_E'),\n",
       " (1.2399325519800177, 'TRI_LEMMA_._LEMMA_–_LEMMA_Buon'),\n",
       " (1.2399039921904618, 'TRI_LEMMA_l’_LEMMA_vistare_LEMMA_!'),\n",
       " (1.2397911139555975, 'BI_LEMMA_-Oh_LEMMA_Ron'),\n",
       " (1.2397871886550587, 'LEMMA_misurini'),\n",
       " (1.2397760895691452, 'TRI_LEMMA_._LEMMA_]_LEMMA_«'),\n",
       " (1.2397699207547939, 'BI_LEMMA_rivedere_LEMMA_sé'),\n",
       " (1.2397399032131937, 'TRI_LEMMA_will_LEMMA_never_LEMMA_die'),\n",
       " (1.2397306475339325, 'TRI_LEMMA_,_LEMMA_fratello_LEMMA_;'),\n",
       " (1.23972809309166, 'TRI_LEMMA_,_LEMMA_Perce_LEMMA_!'),\n",
       " (1.2397056552867594, 'BI_LEMMA_idiota_LEMMA_Ron'),\n",
       " (1.2396847373325246, 'BI_LEMMA_amicizia_LEMMA_riuscire'),\n",
       " (1.2395845892304376, 'BI_LEMMA_realizzarlo_LEMMA_.'),\n",
       " (1.2394631375411087, 'TRI_LEMMA_tornire_LEMMA_,_LEMMA_tornire'),\n",
       " (1.2394372928800232, 'TRI_LEMMA_,_LEMMA_insicurezza_LEMMA_,'),\n",
       " (1.2394324195947024, 'TRI_LEMMA_”_LEMMA_dovere_LEMMA_“'),\n",
       " (1.2394198445307958, 'BI_LEMMA_._LEMMA_60'),\n",
       " (1.2393894610495602, 'TRI_LEMMA_Lily_LEMMA_,_LEMMA_scrivere'),\n",
       " (1.23935418901651, 'TRI_LEMMA_e_LEMMA_lessico_LEMMA_essere'),\n",
       " (1.2393212452661804, 'TRI_LEMMA_scala_LEMMA_e_LEMMA_vedere'),\n",
       " (1.239228463982454, 'TRI_LEMMA_angolare_LEMMA_cuore_LEMMA_.'),\n",
       " (1.2391716811184312, 'BI_LEMMA_rimbalzare_LEMMA_e'),\n",
       " (1.2390971431776303, 'BI_LEMMA_Attinenza_LEMMA_pacchetto'),\n",
       " (1.239045048889799, 'TRI_LEMMA_,_LEMMA_intento_LEMMA_guardare'),\n",
       " (1.238979647712296, 'BI_LEMMA_Because_LEMMA_of'),\n",
       " (1.238891293399531, 'LEMMA_fox'),\n",
       " (1.2388850378749585, 'BI_LEMMA_Plimpi_LEMMA_d’'),\n",
       " (1.2388765853735153, 'TRI_LEMMA_tristo_LEMMA_._LEMMA_.'),\n",
       " (1.2388468294797246, 'TRI_LEMMA_Natale_LEMMA_buono_LEMMA_,'),\n",
       " (1.238839600493128, 'TRI_LEMMA_Fred_LEMMA_Jr_LEMMA_e'),\n",
       " (1.238836702825555, 'TRI_LEMMA_e_LEMMA_canzone_LEMMA_,'),\n",
       " (1.2387267794660588, 'TRI_LEMMA_essere_LEMMA_scrivere_LEMMA_Harry'),\n",
       " (1.2387245930124315, 'BI_LEMMA_abbracciare_LEMMA_Fred'),\n",
       " (1.238717173978932, 'TRI_LEMMA_essere_LEMMA_piacevole_LEMMA_leggero'),\n",
       " (1.238714648805968, 'TRI_LEMMA_perdere_LEMMA_,_LEMMA_Lily'),\n",
       " (1.238713586839135, 'TRI_LEMMA_signore_LEMMA_Lunastorta_LEMMA_,'),\n",
       " (1.2387079625934847, 'TRI_LEMMA_.._LEMMA_essere_LEMMA_piacere'),\n",
       " (1.2385541933604725, 'TRI_LEMMA_,_LEMMA_piccolo_LEMMA_o'),\n",
       " (1.2384968090602024, 'BI_LEMMA_salvare_LEMMA_unico'),\n",
       " (1.2384750676623568, 'BI_LEMMA_normalissima_LEMMA_,'),\n",
       " (1.2384020799615942, 'LEMMA_pum'),\n",
       " (1.2383682001287883, 'TRI_LEMMA_Scusa_LEMMA_,_LEMMA_Hermione'),\n",
       " (1.2383053371772001, 'TRI_LEMMA_dispiacere_LEMMA_._LEMMA_E'),\n",
       " (1.2382919767337357, 'BI_LEMMA_em_LEMMA_...'),\n",
       " (1.2382556457224718, 'TRI_LEMMA_!_LEMMA_schifare_LEMMA_,'),\n",
       " (1.2382013153761013, \"TRI_LEMMA_Ron_LEMMA_._LEMMA_''\"),\n",
       " (1.2381681612564932, 'LEMMA_LAVANDA'),\n",
       " (1.238116322279491, 'BI_LEMMA_mettere_LEMMA_pulire'),\n",
       " (1.2380951583846644, 'BI_LEMMA_-Papà_LEMMA_!'),\n",
       " (1.2380744298959172, 'BI_LEMMA_ammenda_LEMMA_.'),\n",
       " (1.238058949072572, 'LEMMA_Emi'),\n",
       " (1.2380141279792827, 'TRI_LEMMA_._LEMMA_figliare_LEMMA_Harry'),\n",
       " (1.2380022565722693, 'TRI_LEMMA_pezzo_LEMMA_carta_LEMMA_e'),\n",
       " (1.2379384823119401, 'TRI_LEMMA_lunare_LEMMA_essere_LEMMA_pieno'),\n",
       " (1.2379343046710114, 'TRI_LEMMA_rendere_LEMMA_contare_LEMMA_scrivere'),\n",
       " (1.237898339916879, 'BI_LEMMA_aria_LEMMA_malaticcio'),\n",
       " (1.2378919192104687, 'BI_LEMMA_né_LEMMA_scrivere'),\n",
       " (1.2378890387224746, 'LEMMA_2020'),\n",
       " (1.237834317423646, 'BI_LEMMA_,_LEMMA_Payton'),\n",
       " (1.2378323611897408, 'BI_LEMMA_piccolo_LEMMA_chiedere'),\n",
       " (1.2377612360519, 'BI_LEMMA_Purosangue_LEMMA_Serpeverde'),\n",
       " (1.237734401622967, 'TRI_LEMMA_volare_LEMMA_aria_LEMMA_.'),\n",
       " (1.2377282255236097, 'TRI_LEMMA_*_LEMMA_Angolo_LEMMA_Autrice'),\n",
       " (1.2377150375427333, 'BI_LEMMA_buonissimo_LEMMA_.'),\n",
       " (1.237694310562157, 'LEMMA_Titty90'),\n",
       " (1.2376941881661807, 'TRI_LEMMA_,_LEMMA_sedere_LEMMA_nell’'),\n",
       " (1.2376752538659666, 'BI_LEMMA_essere_LEMMA_autunno'),\n",
       " (1.2376691723141586, 'TRI_LEMMA_prestare_LEMMA_,_LEMMA_Erica'),\n",
       " (1.2376672770181927, 'TRI_LEMMA_will_LEMMA_try_LEMMA_to'),\n",
       " (1.2376311291866862, 'BI_LEMMA_Fred_LEMMA_Jr'),\n",
       " (1.2375584219816713, 'BI_LEMMA_domandare_LEMMA_bambina'),\n",
       " (1.2375250173903662, 'TRI_LEMMA_finestra_LEMMA_dormitorio_LEMMA_.'),\n",
       " (1.2374141659878894, 'BI_LEMMA_Marzia_LEMMA_.'),\n",
       " (1.237340747949331, 'LEMMA_HPeace&Love'),\n",
       " (1.2372991231723367, 'LEMMA_Beatriz'),\n",
       " (1.2372160003113712, 'BI_LEMMA_zuppo_LEMMA_cipolla'),\n",
       " (1.2372110083493613, 'BI_LEMMA_Grifondoro_LEMMA_passare'),\n",
       " (1.237179295992226, 'BI_LEMMA_Occhi_LEMMA_colore'),\n",
       " (1.2371662812936843, 'BI_LEMMA_coperchio_LEMMA_scatolare'),\n",
       " (1.2370918914795108, 'BI_LEMMA_!_LEMMA_GIUDIZIO'),\n",
       " (1.2370529500875467, 'TRI_LEMMA_“_LEMMA_promettere_LEMMA_?'),\n",
       " (1.237030913343139, 'BI_LEMMA_Aspettiamo_LEMMA_bambino'),\n",
       " (1.237017605796031, 'BI_LEMMA_e_LEMMA_frivolezza'),\n",
       " (1.2369912106684429, 'TRI_LEMMA_Mimbulus_LEMMA_Mimbletonia_LEMMA_.'),\n",
       " (1.2369912106684429, 'BI_LEMMA_Mimbletonia_LEMMA_.'),\n",
       " (1.2369850403364728, 'BI_LEMMA_ridare_LEMMA_indietro'),\n",
       " (1.2369637209339293, 'TRI_LEMMA_nuovo_LEMMA_,_LEMMA_potere'),\n",
       " (1.2369458107971307, 'LEMMA_rosmarino'),\n",
       " (1.236810680101673, 'TRI_LEMMA_..._LEMMA_decidere_LEMMA_.'),\n",
       " (1.2367962448504204, 'BI_LEMMA_volare_LEMMA_velocemente'),\n",
       " (1.2367849709211423, 'BI_LEMMA_._LEMMA_Prigioniero'),\n",
       " (1.236738945382875, 'LEMMA_McKenzie'),\n",
       " (1.2367321855762952, 'BI_LEMMA_ragazzo_LEMMA_....'),\n",
       " (1.2367209580346028, 'BI_LEMMA_castano_LEMMA_...'),\n",
       " (1.236665512285774, 'BI_LEMMA_piccolo_LEMMA_Piton'),\n",
       " (1.2366005481986526, 'BI_LEMMA_davvero_LEMMA_degnare'),\n",
       " (1.2365482637508252, 'TRI_LEMMA_!_LEMMA_arrivare_LEMMA_,'),\n",
       " (1.2364886059139022, 'TRI_LEMMA_papa_LEMMA_’_LEMMA_,'),\n",
       " (1.2364857719202251, 'TRI_LEMMA_,_LEMMA_scompigliandoli_LEMMA_.'),\n",
       " ...]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_w_classifier_weight[-100::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6455440460709427, 'LEMMA_clitoride'),\n",
       " (0.6507442391765524, 'BI_LEMMA_erezione_LEMMA_,'),\n",
       " (0.6577413951917751, 'BI_LEMMA_lo_LEMMA_orgasmo'),\n",
       " (0.658896060011362, 'BI_LEMMA_capezzolo_LEMMA_.'),\n",
       " (0.662554994996594, 'LEMMA_capezzolo'),\n",
       " (0.6628867266074101, 'LEMMA_erezione'),\n",
       " (0.6735282059171619, 'LEMMA_PV'),\n",
       " (0.6739484469266507, 'LEMMA_Erotico'),\n",
       " (0.6763868888792137, 'BI_LEMMA_(_LEMMA_PV'),\n",
       " (0.6802372089003575, 'LEMMA_lubrificare'),\n",
       " (0.6816054711946514, 'BI_LEMMA_capezzolo_LEMMA_turgido'),\n",
       " (0.6835595726467507, 'BI_LEMMA_il_LEMMA_capezzolo'),\n",
       " (0.6906842574498303, 'BI_LEMMA_lo_LEMMA_erezione'),\n",
       " (0.6920495888109893, 'BI_LEMMA_il_LEMMA_testicolo'),\n",
       " (0.6922104763110548, 'TRI_LEMMA_raggiungere_LEMMA_l’_LEMMA_orgasmo'),\n",
       " (0.6929203742142941, 'LEMMA_pube'),\n",
       " (0.6941991315072007, 'BI_LEMMA_l’_LEMMA_orgasmo'),\n",
       " (0.6943833225320659, 'BI_LEMMA_._LEMMA_Eterosessuale'),\n",
       " (0.696554992956624, 'BI_LEMMA_allargare_LEMMA_gamba'),\n",
       " (0.6970745528165665, 'BI_LEMMA_ritmare_LEMMA_spinto'),\n",
       " (0.6985099808913369, 'LEMMA_testicolo'),\n",
       " (0.700286699792488, 'BI_LEMMA_capezzolo_LEMMA_e'),\n",
       " (0.7015229178037768, 'BI_LEMMA_spingere_LEMMA_baciare'),\n",
       " (0.7018868745012975, 'BI_LEMMA_orgasmo_LEMMA_.'),\n",
       " (0.7019427922001255, 'LEMMA_inturgidire'),\n",
       " (0.7047801275557636, 'TRI_LEMMA_raggiungere_LEMMA_lo_LEMMA_orgasmo'),\n",
       " (0.706930487929632, 'BI_LEMMA_clitoride_LEMMA_,'),\n",
       " (0.707183178287162, 'BI_LEMMA_all’_LEMMA_inguine'),\n",
       " (0.7082615020017925, 'BI_LEMMA_Eterosessuale_LEMMA_.'),\n",
       " (0.7082615020017925, 'TRI_LEMMA_._LEMMA_Eterosessuale_LEMMA_.'),\n",
       " (0.7087987582108091, 'LEMMA_masturbarlo'),\n",
       " (0.7089174597227974, 'BI_LEMMA_,_LEMMA_erezione'),\n",
       " (0.709404669733531, 'BI_LEMMA_unghia_LEMMA_schiena'),\n",
       " (0.7094691140604018, 'BI_LEMMA_Erotico_LEMMA_,'),\n",
       " (0.710109669061266, 'LEMMA_patta'),\n",
       " (0.7103903593057677, 'BI_LEMMA_:_LEMMA_Erotico'),\n",
       " (0.7112721734393218, 'BI_LEMMA_slip_LEMMA_e'),\n",
       " (0.7114176881054193, 'BI_LEMMA_turgido_LEMMA_.'),\n",
       " (0.7121665243901565, 'BI_LEMMA_membro_LEMMA_eretto'),\n",
       " (0.712435106180914, 'BI_LEMMA_proprio_LEMMA_erezione'),\n",
       " (0.7124986419054916, 'TRI_LEMMA_slacciare_LEMMA_il_LEMMA_pantalone'),\n",
       " (0.7129729734725175, 'LEMMA_daph'),\n",
       " (0.713480536880434, 'BI_LEMMA_clitoride_LEMMA_.'),\n",
       " (0.71425047428036, 'TRI_LEMMA_Genere_LEMMA_:_LEMMA_Erotico'),\n",
       " (0.7144497183134988, 'TRI_LEMMA_,_LEMMA_leccare_LEMMA_e'),\n",
       " (0.7147233460779439, 'BI_LEMMA_erezione_LEMMA_.'),\n",
       " (0.714734767527459, 'TRI_LEMMA_internare_LEMMA_coscia_LEMMA_,'),\n",
       " (0.7151159115422724, 'TRI_LEMMA_,_LEMMA_membro_LEMMA_Lumaclub'),\n",
       " (0.7154229968179413, 'TRI_LEMMA_il_LEMMA_capezzolo_LEMMA_.'),\n",
       " (0.7156631210776161, 'BI_LEMMA_l’_LEMMA_erezione'),\n",
       " (0.716079750398933, 'TRI_LEMMA_piacere_LEMMA_e_LEMMA_dolore'),\n",
       " (0.7160964311752612, 'LEMMA_succhiarlo'),\n",
       " (0.7161066513199775, 'BI_LEMMA_Libero_LEMMA_flirt'),\n",
       " (0.7161066513199775, 'TRI_LEMMA_._LEMMA_Libero_LEMMA_flirt'),\n",
       " (0.7163219886324391, 'TRI_LEMMA_,_LEMMA_Romantico_LEMMA_;'),\n",
       " (0.7168749323612887, 'TRI_LEMMA_l’_LEMMA_orgasmo_LEMMA_,'),\n",
       " (0.7172212956219923, 'BI_LEMMA_erezione_LEMMA_pulsare'),\n",
       " (0.7183307170772427, 'BI_LEMMA_Draco_LEMMA_gemette'),\n",
       " (0.7184173508153034, 'BI_LEMMA_membro_LEMMA_durare'),\n",
       " (0.7185449293193129, 'BI_LEMMA_alla_LEMMA_orgasmo'),\n",
       " (0.7189636758858735, 'TRI_LEMMA_l’_LEMMA_orgasmo_LEMMA_.'),\n",
       " (0.7190083558101832, 'BI_LEMMA_internare_LEMMA_coscia'),\n",
       " (0.7190337223549986, 'BI_LEMMA_,_LEMMA_Erotico'),\n",
       " (0.7193640307339016, 'BI_LEMMA_punto_LEMMA_membro'),\n",
       " (0.7197877721629794, 'BI_LEMMA_sentire_LEMMA_erezione'),\n",
       " (0.7201041442531187, 'TRI_LEMMA_Mary_LEMMA_Black_LEMMA_.'),\n",
       " (0.7203400120372502, 'TRI_LEMMA_d’_LEMMA_introduzione_LEMMA_essere'),\n",
       " (0.7207365948922752, 'TRI_LEMMA_leccare_LEMMA_e_LEMMA_succhiare'),\n",
       " (0.7208947527506472, 'TRI_LEMMA_togliere_LEMMA_il_LEMMA_boxer'),\n",
       " (0.7209287095070028, 'BI_LEMMA_slacciare_LEMMA_reggiseno'),\n",
       " (0.721842609692111, 'TRI_LEMMA_._LEMMA_eccitare_LEMMA_.'),\n",
       " (0.7226426758172944, 'TRI_LEMMA_il_LEMMA_:_LEMMA_Angst'),\n",
       " (0.7229042884341013, 'BI_LEMMA_beta_LEMMA_Narcissa63'),\n",
       " (0.7235241889498263, 'BI_LEMMA_Rit_LEMMA_.'),\n",
       " (0.7235565866471415, 'BI_LEMMA_lingua_LEMMA_lambire'),\n",
       " (0.7236022628141862, 'LEMMA_Hakka'),\n",
       " (0.7240819199596461, 'BI_LEMMA_ondata_LEMMA_piacere'),\n",
       " (0.7253687458791263, 'BI_LEMMA_e_LEMMA_ansiti'),\n",
       " (0.7253775525753106, 'BI_LEMMA_Orientamento_LEMMA_sessuale'),\n",
       " (0.7256452211371799, 'BI_LEMMA_erezione_LEMMA_premere'),\n",
       " (0.7257620645178989, 'TRI_LEMMA_lo_LEMMA_internare_LEMMA_coscia'),\n",
       " (0.7265695160203113, 'TRI_LEMMA_:_LEMMA_Erotico_LEMMA_,'),\n",
       " (0.7265808404720183, 'BI_LEMMA_orgasmo_LEMMA_travolgere'),\n",
       " (0.7266324083665736, 'BI_LEMMA_Tic_LEMMA_...'),\n",
       " (0.7266705381666898, 'TRI_LEMMA_frase_LEMMA_d’_LEMMA_introduzione'),\n",
       " (0.7266893314035503, 'TRI_LEMMA_il_LEMMA_capezzolo_LEMMA_turgido'),\n",
       " (0.7273380903769445, 'LEMMA_orgasmo'),\n",
       " (0.7274118656853417, 'LEMMA_penetrarlo'),\n",
       " (0.7275775128624652, 'TRI_LEMMA_._LEMMA_I_LEMMA_fianco'),\n",
       " (0.7283877886187804, 'BI_LEMMA_PWP_LEMMA_,'),\n",
       " (0.7291999907597697, 'BI_LEMMA_seno_LEMMA_sodo'),\n",
       " (0.7294420657256683, 'BI_LEMMA_gluteo_LEMMA_.'),\n",
       " (0.7297677144570279, 'TRI_LEMMA_*_LEMMA_ViXi_LEMMA_*'),\n",
       " (0.7300801273292915, 'BI_LEMMA_Harry_LEMMA_gemere'),\n",
       " (0.7301106151146745, 'BI_LEMMA_patta_LEMMA_pantalone'),\n",
       " (0.7301609809936261, 'BI_LEMMA_sentire_LEMMA_eccitazione'),\n",
       " (0.730256332086169, 'BI_LEMMA_Hallelujah_LEMMA_.'),\n",
       " (0.7304397521813452, 'BI_LEMMA_L’_LEMMA_orgasmo'),\n",
       " (0.730670101235919, 'BI_LEMMA_,_LEMMA_VII'),\n",
       " (0.7314699931559555, 'BI_LEMMA_Sesso_LEMMA_descrittivo')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_w_classifier_weight[:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
